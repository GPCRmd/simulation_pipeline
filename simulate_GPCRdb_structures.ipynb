{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/miniconda3/lib/python3.6/site-packages/htmd/versionwarnings.py:28: UserWarning: As of HTMD 1.16 the default number of threads HTMD spawns for calculations is set to 1. You can enable parallelism at your own risk using `config(njobs=-2)` in the beginning of your scripts. To disable this warning run once: `from htmd import _disableWarnings; _disableWarnings('1.16');`\n",
      "  , UserWarning)\n",
      "/home/david/miniconda3/lib/python3.6/site-packages/htmd/versionwarnings.py:34: UserWarning: As of HTMD 1.21 support for ACEMD v2 has stopped. Please use ACEMD3 instead as well as the corresponding equilibration and production protocols. To disable this warning run once: `from htmd import _disableWarnings; _disableWarnings('1.21');`\n",
      "  , UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Please cite HTMD: Doerr et al.(2016)JCTC,12,1845. https://dx.doi.org/10.1021/acs.jctc.6b00049\n",
      "\n",
      "HTMD Documentation at: https://www.htmd.org/docs/latest/\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-28 11:20:52,303 - binstar - INFO - Using Anaconda API: https://api.anaconda.org\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New stable HTMD version (1.22.9 python[3.7,<3.8.0a0,3.6,<3.7.0a0]) is available. You are currently on (1.22.1).There are several methods to update:    - Create a new conda env. using `conda create -n htmd1.22.9 htmd=1.22.9 -c acellera -c psi4 -c conda-forge`    - Create a brand new conda installation and run `conda install htmd -c acellera -c psi4 -c conda-forge`    - Run: `conda update htmd -c acellera -c psi4 -c conda-forge` (NOT RECOMMENDED)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import traceback\n",
    "import re\n",
    "import requests\n",
    "import zipfile,io\n",
    "import glob\n",
    "import numpy as np\n",
    "from shutil import copy2,copytree,rmtree\n",
    "import xml.etree.ElementTree as ET\n",
    "from bs4 import BeautifulSoup\n",
    "import openbabel\n",
    "import time\n",
    "import random\n",
    "import sys\n",
    "import tempfile\n",
    "from Bio import pairwise2\n",
    "from Bio.Align import substitution_matrices \n",
    "import tarfile\n",
    "\n",
    "#HTMD things\n",
    "import htmd\n",
    "from htmd.ui import *\n",
    "from moleculekit.tools.sequencestructuralalignment import sequenceStructureAlignment\n",
    "from htmd.protocols.equilibration_v2 import Equilibration\n",
    "from htmd.protocols.production_v6 import Production\n",
    "from htmd.builder.builder import removeLipidsInProtein, tileMembrane, minimalRotation,removeAtomsInHull\n",
    "from moleculekit.util import rotationMatrix, sequenceID, opm\n",
    "from htmd.builder.charmm import _recoverProtonations\n",
    "from htmd.config import config\n",
    "\n",
    "# IMPORTANT!!!! vmd needs to be installed for this pipeline to run properly\n",
    "config(viewer='vmd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-28 11:20:55,827 - moleculekit.readers - WARNING - Element guessing failed for atom with name  DUM as the guessed element \"D\" was not found in the periodic table. Check for incorrect column alignment in the PDB file or report to moleculekit issue tracker.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PATH=/home/david/bin:/home/david/.local/bin:/home/david/miniconda3/bin:/home/david/miniconda3/condabin:/home/david/bin:/home/david/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/home/david/bin:/home/david/bin:/gpcr/users/daranda/doctorat/GPCR_simulations/fake_slurm/\n"
     ]
    }
   ],
   "source": [
    "####################\n",
    "## Initial variables\n",
    "####################\n",
    "\n",
    "# Will this one be a round of apoforms??\n",
    "apo = False\n",
    "\n",
    "# PDB codes of the GPCRs to be simulated. \n",
    "# If no codes are provided, all avalible structures in GPCRdb will be used (except the ones already simulated)\n",
    "noncomplex = {\"6TPK\", \"6S0Q\", \"6V9S\", \"6WJC\", \"6W25\", \"6OBA\", \"6LW5\", \"6KP6\", \"6LUQ\", \"6LI1\", \"6LI0\", \"6LI2\", \"6KPC\", \"6LRY\", \"6KNM\", \"6TOT\", \"6TOS\", \"6TO7\", \"6TP6\", \"6TQ7\", \"6TOD\", \"6TP3\", \"6TQ4\", \"6TQ9\", \"6TP4\", \"6TQ6\", \"6TPN\", \"6TPG\", \"6TPJ\", \"6OL9\", \"6RZ6\", \"6RZ9\", \"6RZ7\", \"6RZ8\", \"6PT2\", \"6PT3\", \"6KUX\", \"6KUY\", \"6KUW\", \"6IQL\", \"6PS7\", \"6PS0\", \"6PS3\", \"6PS5\", \"6PS1\", \"6PS4\", \"6PRZ\", \"6PS2\", \"6PS6\", \"6KK1\", \"6KK7\", \"6KJV\", \"6PS8\", \"6JZH\", \"6RZ4\", \"6RZ5\", \"6KQI\", \"6QZH\", \"6K1Q\", \"6GT3\", \"6MH8\", \"6ME2\", \"6ME3\", \"6ME4\", \"6ME5\", \"6ME6\", \"6ME7\", \"6ME8\", \"6ME9\", \"6J21\", \"6J20\", \"6A94\", \"6A93\", \"5ZTY\", \"6HLP\", \"6HLO\", \"6HLL\", \"6GPX\", \"6GPS\", \"6IIV\", \"6IIU\", \"6E59\", \"6M9T\", \"6AK3\", \"5ZHP\", \"5ZKC\", \"5ZK3\", \"5YC8\", \"5ZK8\", \"5ZKB\", \"6IGK\", \"6IGL\", \"6FJ3\", \"6AKX\", \"6AKY\", \"6D27\", \"6D26\", \"6DRX\", \"6DS0\", \"6DRY\", \"6DRZ\", \"6BD4\", \"5ZKQ\", \"5ZKP\", \"6C1R\", \"6C1Q\", \"6D32\", \"6D35\", \"5KW2\", \"5ZBH\", \"5ZBQ\", \"6FK7\", \"6FKA\", \"6FKD\", \"6FK6\", \"6FK9\", \"6FKC\", \"6FK8\", \"6FKB\", \"6CM4\", \"6FFI\", \"6FFH\", \"5WF5\", \"5WF6\", \"6BQH\", \"6BQG\", \"5V54\", \"5OLH\", \"5OLZ\", \"5OLO\", \"5OM1\", \"5OLG\", \"5OLV\", \"5OM4\", \"5YQZ\", \"6AQF\", \"5O9H\", \"5X33\", \"5VRA\", \"5WS3\", \"5WQC\", \"5WIV\", \"5WIU\", \"5NM4\", \"5NM2\", \"5NLX\", \"5X7D\", \"5X93\", \"5XPR\", \"5XSZ\", \"5N2S\", \"5MZP\", \"5MZJ\", \"5N2R\", \"5XRA\", \"5XR8\", \"5UIW\", \"5NX2\", \"5TZY\", \"5TZR\", \"5JTB\", \"5VBL\", \"5UVI\", \"5VEW\", \"5V56\", \"5V57\", \"5VEX\", \"5NDD\", \"5NDZ\", \"5UNH\", \"5UNF\", \"5UNG\", \"5TE3\", \"5TE5\", \"5UEN\", \"5UIG\", \"5TVN\", \"5T04\", \"5T1A\", \"5LWE\", \"5U09\", \"5TGZ\", \"5K2C\", \"5K2B\", \"5K2A\", \"5K2D\", \"5GLI\", \"5GLH\", \"5D6L\", \"5DYS\", \"5L7D\", \"5L7I\", \"5IU7\", \"5IUB\", \"5IU8\", \"5IU4\", \"5IUA\", \"4Z9G\", \"5EE7\", \"5DSG\", \"5CXV\", \"4ZJ8\", \"4ZJC\", \"5F8U\", \"5DHG\", \"5DHH\", \"4ZUD\", \"5A8E\", \"5CGC\", \"5CGD\", \"4XEE\", \"4XES\", \"4Z35\", \"4Z34\", \"4Z36\", \"4YAY\", \"4UHR\", \"4XNW\", \"4XNV\", \"4XT3\", \"4RWS\", \"4RWD\", \"4S0V\", \"4U15\", \"4U16\", \"4QIM\", \"4QIN\", \"4PHU\", \"4OO9\", \"4PXZ\", \"4PY0\", \"4BVN\", \"4NTJ\", \"4OR2\", \"4O9R\", \"4BUO\", \"4N4W\", \"4N6H\", \"4NC3\", \"4MBS\", \"4L6R\", \"4K5Y\", \"4JKV\", \"3ZPR\", \"3ZPQ\", \"4IAQ\", \"4IAR\", \"4IB4\", \"4GPO\", \"3VW7\", \"4GBR\", \"4GRV\", \"4EIY\", \"4AMJ\", \"4AMI\", \"4EJ4\", \"4EA3\", \"3UZA\", \"3UZC\", \"4DJH\", \"4DKL\", \"3V2Y\", \"3UON\", \"3REY\", \"3RFM\", \"3RZE\", \"2YCZ\", \"2YCW\", \"2YDV\", \"2YDO\", \"3QAK\", \"2Y04\", \"2Y00\", \"2Y03\", \"2Y02\", \"3PDS\", \"3PBL\", \"3ODU\", \"3OE0\", \"3NY9\", \"3NY8\", \"3NYA\", \"3D4S\", \"2Z73\", \"2RH1\", \"1U19\", \"1GZM\"}\n",
    "noncomplex_nonGPCRmd = {'6RZ8', '6FFI', '6KJV', '6TQ6', '6DRY', '5WIV', '5V57', '6LI2', '6MH8', '5MZJ', '5KW2', '5X33', '5LWE', '5ZHP', '6PS6', '6FJ3', '6D35', '4NTJ', '6A94', '6AK3', '5UVI', '6FFH', '5WIU', '6KQI', '5XR8', '6RZ9', '5VEX', '6FKD', '6LW5', '6FKA', '6PS7', '6M9T', '6KNM', '6ME6', '6GPX', '5XSZ', '5K2A', '5YQZ', '6PS0', '5K2C', '6ME7', '2Z73', '6D32', '6RZ4', '5YC8', '5T1A', '6AKY', '4N4W', '5WS3', '6LRY', '6J21', '6BQG', '5TE5', '4O9R', '6FK6', '1GZM', '6DRX', '6TQ7', '5NDZ', '6IGL', '5VRA', '5ZBQ', '6TPN', '5ZTY', '6DS0', '5NLX', '5X93', '6HLP', '5OLG', '5OM4', '5O9H', '5XPR', '6A93', '5GLI', '6OBA', '6D27', '6HLO', '6RZ5', '5TE3', '6IIV', '6KP6', '6TQ4', '6TPJ', '5V56', '5UNG', '6FK9', '6PS8', '2YCZ', '6JZH', '5XRA', '5ZKB', '4JKV', '5MZP', '5K2D', '5OLV', '5X7D', '5T04', '5OLO', '5DYS', '6FK7', '6J20', '6K1Q', '5EE7', '6D26', '6PS1', '6DRZ', '4GBR', '6FKC', '6TP6', '6LUQ', '5ZKQ', '5UNH', '6PRZ', '5UNF', '5NX2', '6LI0', '5NM2', '5D6L', '6AQF', '6KK1', '6C1Q', '4Z9G', '6LI1', '5WF5', '6FKB', '6BQH', '6QZH', '5OLH', '4XT3', '5ZK3', '5VEW', '4XES', '6HLL', '6TOT', '5N2R', '5WF6', '5K2B', '6TPG', '6PS4', '5F8U', '6ME4', '6GT3', '6RZ6', '6ME8', '6ME2', '5VBL', '5N2S', '5ZBH', '6PS3', '6IIU', '4NC3', '5JTB', '5ZKP', '6TQ9', '6GPS', '6TP3', '6RZ7', '6ME3', '5ZK8', '6C1R', '5V54', '5UIG', '5TVN', '5OM1', '6AKX', '5ZKC', '5NM4', '5TZY', '6TOD', '4GPO', '6TO7', '6CM4', '6TOS', '6PS5', '6ME9', '5NDD', '6KPC', '6KK7', '4BUO', '6OL9', '6PS2', '6FK8', '6ME5', '6TP4', '4QIM', '6IGK', '5WQC', '5UIW', '5TZR', '5OLZ', '4EJ4', '6E59'}\n",
    "testset = {'4EJ4', '4A4M', '5TE5', '5WIU', '6MEO'}\n",
    "pdb_set = noncomplex_nonGPCRmd\n",
    "\n",
    "# Get current GPCRdb data into a Json\n",
    "gpcrdb_data = requests.get('http://gpcrdb.org/services/structure/').json()\n",
    "gpcrdb_dict = { entry['pdb_code'] : entry for entry in gpcrdb_data }\n",
    "\n",
    "# Path to slurm queing system binaries\n",
    "# In our case, Ismael designed a bunch of small bash scripts (fake_slurm) which do ssh to Hydra and execute slurm there\n",
    "slurmpath = '/gpcr/users/daranda/doctorat/GPCR_simulations/fake_slurm/'\n",
    "path= os.environ['PATH']\n",
    "%env PATH=$path:$slurmpath\n",
    "\n",
    "#Path to ACEMD in computation node and ACEMD license\n",
    "acemd_path = \"/opt/acellera/miniconda3/bin/acemd3\"\n",
    "acemd_license = \"SG_LICENSE_FILE=28000@tolkien.prib.upf.edu\"\n",
    "\n",
    "# Other Paths\n",
    "basepath = '/gpcr/users/daranda/doctorat/GPCR_simulations/'\n",
    "resultspath = basepath + 'simulation_output/'\n",
    "membranepdb = basepath + 'membrane/popc36_box_renumbered.pdb'\n",
    "topparpath = basepath + 'toppar'#toppar= topology+parameters\n",
    "ligandsdict_path = basepath + 'ligands.json'\n",
    "\n",
    "# Parameters\n",
    "username = 'paramoid'#ameboid\n",
    "password = 'paramoid-123'#ameboid-123\n",
    "new_pdb_chain = 'P'\n",
    "membrane_lipid_segid = 'MEM'\n",
    "coldist = 1.3 # Distance bellow which two atoms are considered to collide\n",
    "buffer = 2.4 # Distance between solvation waters and the rest of the system\n",
    "water_thickness = 20 # Size in Z-axis of the solvation water layers\n",
    "membrane_distance = 20 # Distance between the pbc box and the rest of the system atoms, to be filled with membrane\n",
    "water_margin = 4 # Distance in the Z-axis to be penetrated by the solvation box \n",
    "                 # to avoid the formation of a V O I D between the system and the solvation boxes\n",
    "detergent_blacklist = ['OLA','OLB','PEG','GOL','BOG','OLC','P6G','P33','UNL','UNX','PLM','HTG',\n",
    "                       '12P','LPP','PEF','2CV','SOG','TWT','PGE','SO4','STE','LMT','ACT','ACE',\n",
    "                      'MHA','CIT','1PE','MPG','EPE','PG4','DGA','PO4','DMS','TAR','1WV','EDO',\n",
    "                      'BU1','ACM','PG6','TLA','SCN','TCE','MES','EDT','POV','MLI','SIN','PGO',\n",
    "                      'FLC','HTO','PGW','NO3']\n",
    "glucids_blacklist = ['MAN','NAG','BGC','TRE','9NS','BMA','FUC','A2G']\n",
    "\n",
    "# Simulation parameters\n",
    "timestep = 4 # Simulation timestep (femtoseconds)\n",
    "trajperiod = 50000 # Simulation period (femtoseconds): time after which a frame is written during the simulation\n",
    "repnum = 3 # number of replicates \n",
    "\n",
    "# Dummy pdb: a pdb made of a sinlge non-existant DUM atom.\n",
    "# It is used during removal of aromatic insertions by placing it on the middle of the ring and measuring distances  \n",
    "dummypdb='./dummy.pdb'\n",
    "try:\n",
    "    dummymol = Molecule(dummypdb, validateElements=False)\n",
    "except Exception as e:\n",
    "    dummymol = Molecule(dummypdb)\n",
    "dummy_sel = 'name DUM'\n",
    "\n",
    "# Topologies filenames and paths\n",
    "toposfilenames = ['top_all36_prot.rtf',\n",
    "                  'top_all36_na.rtf',\n",
    "                  'top_all36_lipid.rtf',\n",
    "                  'top_all36_carb.rtf',\n",
    "                  'top_all35_ethers.rtf',\n",
    "                  'top_all36_cgenff.rtf']\n",
    "topostreams = ['toppar_water_ions_1.rtf','toppar_ions_won.rtf']\n",
    "streams_folder='stream_splits'\n",
    "topos = [os.path.join(topparpath,file) for file in toposfilenames] + \\\n",
    "        [os.path.join(os.path.join(topparpath,streams_folder),file) for file in topostreams] \n",
    "\n",
    "# Parameters filenames and paths\n",
    "paramsfilenames = ['par_all36m_prot.prm','par_all36_na.prm','par_all36_lipid.prm','par_all36_carb.prm',\\\n",
    "                  'par_all35_ethers.prm','par_all36_cgenff.prm']\n",
    "paramsstreams = ['toppar_water_ions_1.inp','toppar_water_ions_2.inp']\n",
    "params = [os.path.join(topparpath,file) for file in paramsfilenames] + \\\n",
    "         [os.path.join(os.path.join(topparpath,streams_folder),file) for file in paramsstreams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "## David's functions\n",
    "####################\n",
    "def ligands_by_system(ligandsdict):\n",
    "    \"\"\"\n",
    "    Creates a json with all the systems codes and their ligand molecules \n",
    "    \"\"\"\n",
    "    with open('ligands_by_system_new.json', 'w') as ou:\n",
    "        dasdict = {}\n",
    "        for pdb in ligandsdict:\n",
    "            dasdict[pdb] = list(ligandsdict[pdb].keys())\n",
    "        json.dump(dasdict, ou, indent= 4)\n",
    "\n",
    "def json_dict(path):\n",
    "    \"\"\"\n",
    "    Converts json file to pyhton dict.\n",
    "    \"\"\"\n",
    "    json_file=open(path)\n",
    "    json_str = json_file.read()\n",
    "    json_data = json.loads(json_str)\n",
    "    return json_data\n",
    "\n",
    "def get_GPCRdb_nonsimulated(gpcrdb_dict):\n",
    "    \"\"\"\n",
    "    Returns a list of PDB codes from the GPCRdb refined structures not yet simulated in GPCRmd\n",
    "    \"\"\"\n",
    "    \n",
    "    #Make set with the pdb codes of the structures in GPCRdb\n",
    "    gpcrdb_pdbs = set(gpcrdb_dict.keys())\n",
    "\n",
    "    # Load a random name-to-dyn json from contactmaps\n",
    "    # This Jsons contain a dictionary with the dynIDs and the full names of the GPCR simulated\n",
    "    # This way I can get all the pdb codes of the GPCRs presents in GPCRmd\n",
    "    response = requests.get('http://submission.gpcrmd.org/dynadb/files/Precomputed/get_contacts_files/contmaps_inputs/all/cmpl/lg/name_to_dyn_dict.json')\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    gpcrmd_sims = json.loads(str(soup))\n",
    "\n",
    "    # Take the pdb code from each full name in the json, and store in set\n",
    "    gpcrmd_pdbs = set()\n",
    "    pdb_pat = re.compile('\\((\\w+).*\\) \\(.*\\)$')# Take objects whatever is inside of the first parenthesis\n",
    "    for sim in gpcrmd_sims:\n",
    "        match_pdb = re.search(pdb_pat, sim[1])\n",
    "        if match_pdb:\n",
    "            gpcrmd_pdbs.add(match_pdb.group(1))\n",
    "\n",
    "    # Get to-be-simulated GPCR pdbs. That is the ones that are in GPCRdb but not in GPCRmd\n",
    "    not_simulated = gpcrdb_pdbs - gpcrmd_pdbs\n",
    "\n",
    "    return not_simulated\n",
    "\n",
    "def download_GPCRdb_structures(pdb_set, basepath):\n",
    "    \"\"\"\n",
    "    Download (if they exist) the refined GPCRdb structures for the pdb codes in the pdb_set.\n",
    "    PDB codes without a refined structure will be removed from pdb_set\n",
    "    \"\"\"\n",
    "    pdb_set_nonrefined = set()\n",
    "    set_length = len(pdb_set)\n",
    "    i = 0\n",
    "    for pdbcode in pdb_set:\n",
    "        simdir = basepath+'/data_sim/'+pdbcode+'/'\n",
    "        os.makedirs(simdir, exist_ok = True)\n",
    "        i += 1\n",
    "        \n",
    "        print('Downloading %s structure (%d/%d)' % (pdbcode, i, set_length))\n",
    "        # If files for this simulation already exists\n",
    "        if glob(simdir+'*pdb'):\n",
    "            print('Structure for %s already present. Skipping...' % pdbcode)\n",
    "        else:\n",
    "            # Try two possible GPCRdb repositories to download the refined structure\n",
    "            response = requests.get('https://gpcrdb.org/structure/homology_models/'+pdbcode+'_refined_full/download_pdb', stream=True)\n",
    "            if not response.ok:\n",
    "                response = requests.get('http://build.gpcrdb.org/structure/homology_models/'+pdbcode+'_refined_full/download_pdb', stream=True)\n",
    "            if not response.ok:\n",
    "                pdb_set_nonrefined.add(pdbcode)\n",
    "                print('could not download %s refined structure. Skipping...' % (pdbcode))\n",
    "            else:\n",
    "                #Extract downloaded files\n",
    "                zippy = zipfile.ZipFile(io.BytesIO(response.content))\n",
    "                zippy.extractall(simdir)\n",
    "    \n",
    "    #Remove non-refined structrues\n",
    "    pdb_set = pdb_set - pdb_set_nonrefined\n",
    "    \n",
    "    return pdb_set\n",
    "\n",
    "def ligand_dictionary(pdb_set, ligandsdict_path):\n",
    "    \"\"\"\n",
    "    Create dictionary with ligand names and ligand ResNames of each of the structures we need to simulate,\n",
    "    and store the resutls in a json file\n",
    "    \"\"\"\n",
    "    # Read existing ligands dictionary, or create it if it does not exists yet \n",
    "    if os.path.exists(ligandsdict_path):\n",
    "        ligandsdict = json_dict(ligandsdict_path)\n",
    "    else:\n",
    "        ligandsdict = {}\n",
    "\n",
    "    # Iterate over non-yet-simulated structures, and get their ligand information from rcsb (PDB's web api)    \n",
    "    for pdb_code in pdb_set:\n",
    "        #Do not repeat simulations\n",
    "        if pdb_code in ligandsdict:\n",
    "            continue\n",
    "        else:\n",
    "            ligandsdict[pdb_code] = {}\n",
    "            response = requests.get('http://www.rcsb.org/pdb/rest/customReport.xml?pdbids='+pdb_code+'&customReportColumns=ligandId,ligandName')\n",
    "            ligand_tree = ET.fromstring(response.content)\n",
    "            for ligand in ligand_tree:\n",
    "                ligandResname = ligand.find('dimEntity.ligandId').text\n",
    "                ligandName = ligand.find('dimEntity.ligandName').text\n",
    "                if ligandResname == 'null':\n",
    "                    continue\n",
    "                else:\n",
    "                    ligandsdict[pdb_code][ligandResname] = ligandName\n",
    "\n",
    "    with open(ligandsdict_path, 'w') as jsonfile:\n",
    "        json.dump(ligandsdict, jsonfile, ensure_ascii=False, indent = 4)            \n",
    "    \n",
    "    # Create ligands set from previou dictionary\n",
    "    ligandsset = { ligcode  for pdbcode in ligandsdict for ligcode in ligandsdict[pdbcode] }\n",
    "        \n",
    "    return(ligandsdict, ligandsset)\n",
    "\n",
    "def extract_ligands(ligandsdict, basepath):\n",
    "    \"\"\"\n",
    "    Extract ligands from the refined structure PDB and convert htem to a mol2 file\n",
    "    \"\"\"\n",
    "    \n",
    "    obConversion = openbabel.OBConversion()\n",
    "    obConversion.SetInAndOutFormats(\"pdb\", \"mol2\")\n",
    "\n",
    "    # Iterate over ligands\n",
    "    for system in ligandsdict:\n",
    "    \n",
    "        # Skip if structure of this system is not avalible\n",
    "        syspdb_path_list = glob(str(\"%sdata_sim/%s/*pdb\" % (basepath,system)))\n",
    "        if len(syspdb_path_list) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            syspdb_path = syspdb_path_list[0]\n",
    "        \n",
    "        for ligcode in ligandsdict[system]:\n",
    "        #for ligcode in ['TYS']:\n",
    "            ligpath = basepath+\"Ligands/\"+ligcode+\"/\"\n",
    "            mol2path = ligpath+\"ligand.mol2\"\n",
    "            #Skip if ligand has already been download\n",
    "            if os.path.exists(mol2path):\n",
    "                continue\n",
    "            else:\n",
    "                # Directory for ligands\n",
    "                os.makedirs(ligpath, exist_ok=True)\n",
    "\n",
    "                # Take ligand PDB from inside the GPCR system PDB\n",
    "                syspdb_path = glob(str(\"%sdata_sim/%s/*pdb\" % (basepath,system)))[0]\n",
    "                ligpdb_path = ligpath + \"ligand.pdb\"\n",
    "                ligpdb = open(ligpdb_path, 'w')\n",
    "                atomnames = set()\n",
    "                with open(syspdb_path, 'r') as syspdb:\n",
    "                    for line in syspdb:\n",
    "                        resname = line[17:20]\n",
    "                        if resname == ligcode:\n",
    "                            atomname = line[13:20]\n",
    "                            if atomname not in atomnames:# If there are two or more molecules of one ligand, take only one \n",
    "                                ligpdb.write(line)\n",
    "                                atomnames.add(atomname)\n",
    "                ligpdb.close()\n",
    "\n",
    "                #Convert SDF to mol2, and save mol2 in corresponding folder\n",
    "                ligand_mol2 = openbabel.OBMol()\n",
    "                ligand_mol2.AddHydrogens()\n",
    "                obConversion.ReadFile(ligand_mol2, ligpdb_path)\n",
    "                ligand_mol2.AddHydrogens()\n",
    "                ligandmol_string = obConversion.WriteString(ligand_mol2)\n",
    "                \n",
    "                # Change name of molecule in mol2\n",
    "                with open(mol2path, 'w') as ligandmol_file:\n",
    "                    ligandmol_file.write(ligandmol_string.replace(ligpdb_path, ligcode))\n",
    "                    \n",
    "def get_lig_toppar(ligandsset, basepath, username, password):\n",
    "    \"\"\"\n",
    "    Get the topology-parameters string file from paramchem for the submited ligand PDB codes\n",
    "    ALERT: paramchem only allows 100 submissions by month, so it may be possible that not all \n",
    "    parameters are obtained\n",
    "    \"\"\"\n",
    "    \n",
    "    #Get total number of ligands\n",
    "    i = 0\n",
    "    total_ligs = len(ligandsset)\n",
    "    #Pattern to find non-HTMD-compatible lines\n",
    "    lph_pat = re.compile('^ATOM.*LPH|LONEPAIR')\n",
    "    \n",
    "    # Iterate over ligands\n",
    "    for ligcode in ligandsset:\n",
    "        i += 1\n",
    "        print('Getting toppar file for ligand %s (%d/%d)' % (ligcode, i, total_ligs))\n",
    "\n",
    "        # topology-parametetrs file output\n",
    "        topparfile_path = basepath+\"Ligands/\"+ligcode+\"/toppar.str\"\n",
    "        # Errors and warnings file output\n",
    "        erwar_path = basepath+\"Ligands/\"+ligcode+\"/paramchem_stder.txt\"\n",
    "        #Open ligandfile to upload in paramchem\n",
    "        ligfile = open(basepath+\"Ligands/\"+ligcode+\"/ligand.mol2\")\n",
    "        myfile = {\n",
    "                'filename': ligfile\n",
    "        }\n",
    "        myparam = {\n",
    "                #'param_a': 'a' #Include parameters usually included in newer versions of CGenff (versions that we cant use)\n",
    "                'param_b' : 'b' # Make paramchem determine bond order\n",
    "                #'param_c': 'c'# Use CGenFF legacy v1.0, for HTMD is not yet prepared for newer Charmm versions             \n",
    "        }\n",
    "\n",
    "        # Omit ligand if its toppar file already exists\n",
    "        if os.path.exists(topparfile_path):\n",
    "            print('toppar for ligand %s already exists. Skipping...' % ligcode)\n",
    "            continue\n",
    "        else:\n",
    "            # Define POST variables for login in Paramchem\n",
    "            datalogin = {\n",
    "                'usrName': username,\n",
    "                'curPwd': password,\n",
    "                'rndNo': str(random.randrange(100000000, 999999999)),\n",
    "                'submitBtn': 'Submit',\n",
    "            }\n",
    "            # Open web session\n",
    "            with requests.Session() as s:\n",
    "\n",
    "                # Login into paramchem\n",
    "                response_login = s.post('http://cgenff.umaryland.edu/userAccount/userWelcome.php', \n",
    "                           data=datalogin,\n",
    "                           verify=False)\n",
    "\n",
    "                # Submit our ligand molecule into paramchem\n",
    "                response_upload = s.post('http://cgenff.umaryland.edu/initguess/processdata.php', \n",
    "                           files = myfile,\n",
    "                           data = myparam,\n",
    "                            )\n",
    "\n",
    "                # Download Topology-parameters of our molecule file from paramchem, and store it.\n",
    "                # But remember submissions in paramchem are limited weekly\n",
    "                # Download also stderr, just in case\n",
    "                match = re.search('<path>(\\w+)</path>', response_upload.text)\n",
    "                if match:\n",
    "                    code = match.group(1)\n",
    "                    response_ligfile = s.get('http://cgenff.umaryland.edu/initguess/filedownload.php?file='+code+'/ligand.str')\n",
    "                    response_stder = s.get('https://cgenff.umaryland.edu/initguess/filedownload.php?file='+code+'/ligand.err')\n",
    "                    with open(topparfile_path, 'wb') as topparfile:\n",
    "                            topparfile.write(response_ligfile.content)\n",
    "                    with open(erwar_path, 'wb') as erwar:\n",
    "                            erwar.write(response_stder.content)                            \n",
    "                else:\n",
    "                    print('Your paramchem account has reached its weekly submission limit. Please, intrudce a new account or wait to the next monday to continue')            \n",
    "                    return\n",
    "                \n",
    "                #Delete lines with LPH (new feature from CHARMM not tolerated by HTMD)\n",
    "                with open(topparfile_path, \"r\") as f:\n",
    "                    lines = f.readlines()\n",
    "                with open(topparfile_path, \"w\") as f:\n",
    "                    for line in lines:\n",
    "                        if not re.match(lph_pat, line):\n",
    "                            f.write(line)\n",
    "\n",
    "def hetatm_nucleotides(pdbpath, name):\n",
    "    \"\"\"\n",
    "    Convert all nucleotide residue lines from ATOM into HETATM (they will be excluded \n",
    "    by homolwat otherwise).\n",
    "    \"\"\"\n",
    "    mol = Molecule(pdbpath)\n",
    "    mol.set('record', 'HETATM', sel='resname ADN GDP GTP')\n",
    "    mol.write(pdbpath)\n",
    "    file = open(pdbpath, 'rb')\n",
    "    return file    \n",
    "                            \n",
    "def internal_waters(simdir, pdbcode, gpcrdb_dict, apo=False):\n",
    "    \"\"\"\n",
    "    Place internal waters in GPCR structure using homolwat online tool\n",
    "    \"\"\"\n",
    "    # Guess if molecule is active or not, and make Homolwat place (inactive) or not (active)\n",
    "    # the 2.50 sodium ion\n",
    "    sod = None\n",
    "    agoset = {'Agonist', 'Agonist (partial)'}\n",
    "    ligands = gpcrdb_dict[pdbcode]['ligands']\n",
    "    if (len(ligands) == 0) or (apo): # If apoform\n",
    "        sod = \"sod_yes\"\n",
    "    elif ligands[0]['function'] in agoset: \n",
    "        sod = \"sod_no\"\n",
    "    else:\n",
    "        sod = \"sod_yes\"\n",
    "    \n",
    "    # Check if there is already a watered structure here\n",
    "    if (glob(simdir+'*_HW.pdb') and (not apo)) or (glob(simdir+'*_apoHW.pdb') and apo):\n",
    "        print(\"Structure %s already has a watered version. Skipping...\" % pdbcode)\n",
    "        return (sod == 'sod_yes')\n",
    "    else:\n",
    "        print(\"Adding internal waters to structure\")\n",
    "        \n",
    "    #Load pdb file\n",
    "    pdbpath = glob(simdir+'*GPCRdb.pdb')[0]\n",
    "    name = os.path.basename(os.path.splitext(pdbpath)[0])\n",
    "    pdbfiles = {\"file\" : hetatm_nucleotides(pdbpath, name)} \n",
    "    \n",
    "    # Open web session\n",
    "    with requests.Session() as s:\n",
    "        # Load our desired structure into homolwat, as a PDB file\n",
    "        response_loadfile = s.post(\"https://alf06.uab.es/homolwat/run_HW\",\n",
    "                                   files = pdbfiles\n",
    "        )\n",
    "\n",
    "        # Get name and number of our query. Required for following steps\n",
    "        soup = BeautifulSoup(response_loadfile.text,'html')\n",
    "        query_num = soup.find('input',attrs={'name' : 'query_num'}).get('value')\n",
    "        query_name = soup.find('input',attrs={'name' : 'query_name'}).get('value')\n",
    "        \n",
    "        # Analyze structure and place internal waters\n",
    "        response_solvate = s.post(\"https://alf06.uab.es/homolwat/solvate\",\n",
    "                  data = {\n",
    "                    \"query_name\": query_name,\n",
    "                    \"query_num\": query_num,\n",
    "                    \"ch_rest\": '[]',\n",
    "                    \"option_state\": \"inac\",\n",
    "                    \"option_sodium\": sod,\n",
    "                    \"option_dowser\": \"dow_no\",\n",
    "                    \"p_ident\": \"\"\n",
    "                  }\n",
    "        )\n",
    "        \n",
    "        # Determine name for output file\n",
    "        query_num_noapo = query_num.split(\"'\")[1]\n",
    "        query_name_nofilext = query_name.split(\".\")[0]\n",
    "        if apo:\n",
    "            apofix = '_apo'\n",
    "        else:\n",
    "            apofix = '_'\n",
    "\n",
    "            # Download results in zip            \n",
    "        response_download = s.post(\"https://alf06.uab.es/homolwat/download_file/\",\n",
    "              data = {\n",
    "                    \"query_num\": query_num_noapo,\n",
    "                    \"query_name\": query_name_nofilext\n",
    "              })\n",
    "        \n",
    "        # Unzip and extract watered strucutre file\n",
    "        req = response_download.request\n",
    "        if response_download.ok:\n",
    "            zippy = zipfile.ZipFile(io.BytesIO(response_download.content))\n",
    "            zippy.extract(query_name_nofilext+\"_HW.pdb\", path='./')\n",
    "            # This program sodiums are wrongly formated, so the name of the homolog\n",
    "            # simulation occupies the charge column by error. Here i solve this\n",
    "            in_hw = open('./' + query_name_nofilext+\"_HW.pdb\", 'r')\n",
    "            out_hw = open(simdir + query_name_nofilext+apofix+\"HW.pdb\", 'w')\n",
    "            print(simdir + query_name_nofilext+apofix+\"HW.pdb\")\n",
    "            for line in in_hw:\n",
    "                if (len(line) > 79) and (line[79] != \" \"):\n",
    "                    linelist = list(line)\n",
    "                    linelist[79] = \" \"\n",
    "                    line = \"\".join(linelist)\n",
    "                out_hw.write(line)\n",
    "            os.remove('./' + query_name_nofilext+\"_HW.pdb\")\n",
    "            in_hw.close()\n",
    "            out_hw.close()\n",
    "        else:\n",
    "            print(\"could not add internal waters to %s. Skipping...\" % (pdbpath))\n",
    "    return (sod == 'sod_yes')\n",
    "\n",
    "def get_opm(pdbcode):\n",
    "    \"\"\"\n",
    "    Download and load OPM molecule for this PDB code. \n",
    "    If there is no opm structure for this pdbcode, download the substitute structure OPM seems fit\n",
    "    Return thickness and opm molecule\n",
    "    \"\"\"\n",
    "    \n",
    "    # Search pdb code in OPM database, and take thickness and opm_id\n",
    "    searchlink = 'https://lomize-group-opm.herokuapp.com//primary_structures?search='+pdbcode+'&sort=&pageSize=100'\n",
    "    response_dict=eval(requests.get(searchlink).content.decode('UTF-8')\\\n",
    "                       .replace('true', 'True')\\\n",
    "                       .replace('false','False')\\\n",
    "                       .replace('null','None'))\n",
    "    thickness = response_dict['objects'][0]['thickness']\n",
    "    opm_id = response_dict['objects'][0]['id']\n",
    "\n",
    "    # Throught opm id, get PDB id of the reference structure in OPM for this pdbcode\n",
    "    \n",
    "    opmlink = 'https://lomize-group-opm.herokuapp.com//primary_structures/'+str(opm_id)\n",
    "    response_dict=eval(requests.get(opmlink).content.decode('UTF-8')\\\n",
    "                       .replace('true', 'True')\\\n",
    "                       .replace('false','False')\\\n",
    "                       .replace('null','None'))\n",
    "    new_pdbcode = response_dict['pdbid'].lower()\n",
    "    \n",
    "    # Download OPM pdb file, and save all lines not involving a DUM residue in a temp file \n",
    "    response_pdb = requests.get('https://opm-assets.storage.googleapis.com/pdb/'+new_pdbcode+'.pdb')\n",
    "    line_list = (response_pdb.content.decode('UTF-8').split('\\n'))\n",
    "    tmpout = tempfile.NamedTemporaryFile(mode='w',suffix='.pdb')\n",
    "    for line in line_list:\n",
    "        if ' DUM ' not in line:\n",
    "            tmpout.write(line+'\\n')\n",
    "    name = tmpout.name\n",
    "    mol = Molecule(name)\n",
    "    tmpout.close()\n",
    "    \n",
    "    return (thickness, mol)\n",
    "\n",
    "def remove_artifacts(pdbcode, mol, ligdict, accepted_ligdict):\n",
    "    \"\"\"\n",
    "    Remove any small molecules included in ligdict but not in accepted_ligdict.\n",
    "    The intention is to remove unnecessary small molecules, like detergents \n",
    "    or ligands from removed parts of the protein\n",
    "    \"\"\"\n",
    "    tofilter = \"\"\n",
    "    for smalmol in ligdict[pdbcode]:\n",
    "        if smalmol not in accepted_ligdict[pdbcode]:\n",
    "            print('no '+smalmol)\n",
    "            tofilter += smalmol + \" \"\n",
    "    if tofilter:\n",
    "        gpcrdb_mol.filter('not resname '+tofilter)\n",
    "    return gpcrdb_mol\n",
    "                            \n",
    "#####################\n",
    "## Ismael's Functions\n",
    "#####################\n",
    "\n",
    "def renumber_resid_vmd(mol,sel,by=3,start=1):\n",
    "    tmpin = tempfile.NamedTemporaryFile(suffix='.pdb')\n",
    "    mol.write(tmpin.name)\n",
    "    viewer = getCurrentViewer(dispdev='text')\n",
    "    viewer.send('set molid [mol new {%s}]' % tmpin.name)\n",
    "    tmpin.close()\n",
    "    tmpout = tempfile.NamedTemporaryFile(suffix='.pdb')\n",
    "    \n",
    "    # What a wierd way of deciding if \"by_segid\", \"by_resname\" or by both\n",
    "    option_num = 2\n",
    "    max_value = 2**option_num - 1\n",
    "    if by > max_value:\n",
    "        raise ValueError('Maximum value for \"by\" keyword is %d.' % max_value)\n",
    "    if by < 1:\n",
    "        raise ValueError('Minimum value for \"by\" keyword is \"1\".')\n",
    "    bin_by = format(by,'0'+str(option_num)+'b')\n",
    "    option_array = [bool(int(i)) for i in bin_by]\n",
    "    by_segid = option_array[0]\n",
    "    by_resname = option_array[1]\n",
    "    \n",
    "    if by_segid:\n",
    "        segids = set(mol.get('segid',sel=sel))      \n",
    "        for segid in segids:\n",
    "            if by_resname:\n",
    "                resnames = set(mol.get('resname',sel='(%s) and segid %s' % (sel,segid)))\n",
    "                for resname in resnames:\n",
    "                    lsel = '(%s) and (segid %s) and (resname %s)' % (sel,segid,resname)\n",
    "                    viewer = renumber_resid_by_resid_vmd(lsel,mol,viewer,start=start)\n",
    "            else:\n",
    "                lsel = '(%s) and (segid %s)' % (sel,segid)\n",
    "                viewer = renumber_resid_by_resid_vmd(lsel,mol,viewer,start=start)\n",
    "    else:                      \n",
    "        resnames = set(mol.get('resname',sel=sel))\n",
    "        for resname in resnames:\n",
    "            lsel = '(%s) and (resname %s)' % (sel,resname)\n",
    "            viewer = renumber_resid_by_resid_vmd(lsel,mol,viewer,start=start)       \n",
    "    viewer.send('animate write pdb {%s} waitfor all top;exit' % tmpout.name)\n",
    "    newmol = Molecule(tmpout.name)\n",
    "    tmpout.close()\n",
    "    return newmol\n",
    "\n",
    "def renumber_resid_by_resid_vmd(sel,mol,viewer,start=1):\n",
    "    resids = sorted(list(set(mol.get('resid',sel=sel))))\n",
    "    resids = [str(i) for i in resids]\n",
    "    viewer.send('proc renum_resid {molid} {set newresid %d; set resids {%s};' % (start,' '.join(resids)) + \\\n",
    "                'set asall [atomselect $molid [concat {(%s) and resid } $resids]];' % sel + \\\n",
    "                '$asall set user 1.00;' + \\\n",
    "                'foreach resid $resids {' + \\\n",
    "                'set as [atomselect $molid [concat {user 1.00 and (%s) and resid } $resid]];' % sel + \\\n",
    "                '$as set resid $newresid; $as set user 0.00; incr newresid}};'+'renum_resid $molid')\n",
    "    return viewer\n",
    "\n",
    "def ordered_unique(seq):\n",
    "    seen = set()\n",
    "    return [x for x in seq if not (x in seen or seen.add(x))]\n",
    "\n",
    "def renumber_segments(inputmol,segids,prefix):\n",
    "    sel = 'segid '+' '.join(segids)\n",
    "    segids = ordered_unique(inputmol.get('segid',sel=sel))\n",
    "    if prefix in segids:\n",
    "        raise ValueError('segid %s already exists.' % prefix)\n",
    "    \n",
    "    mol = renumber_resid_vmd(inputmol,sel,by=2)\n",
    "    # change first segid segment as it is properly renumbered already\n",
    "    mol.set('segid',prefix,sel='segid '+segids[0])\n",
    "\n",
    "    if len(segids) > 1:\n",
    "        # initialize variables for second segid\n",
    "        curr_segid = prefix\n",
    "        # get last resid for first segid\n",
    "        idx_curr_segid = mol.atomselect('segid '+curr_segid)\n",
    "        prev_resid = len(set(mol.resid[idx_curr_segid]))\n",
    "        k = 0\n",
    "        for segid in segids[1:]:\n",
    "            \n",
    "            # get last current resid\n",
    "            idx_segid = mol.atomselect('segid '+segid)\n",
    "            curr_resid = len(set(mol.resid[idx_segid])) + prev_resid\n",
    "            if curr_resid <= 9999:\n",
    "                # join segments resuming the previous resid numbering\n",
    "                mol = renumber_resid_vmd(mol,'segid '+segid,start=prev_resid+1,by=2)\n",
    "                mol.segid[idx_segid] = curr_segid\n",
    "                # get last resid of the current segid for the next loop iteration\n",
    "                prev_resid = curr_resid\n",
    "            else:\n",
    "\n",
    "                # join segments resuming the previous resid numbering up to resid 9999\n",
    "                sel1 = 'segid '+segid+' and resid <= '+str(9999-prev_resid)\n",
    "                mol = renumber_resid_vmd(mol,sel1,start=prev_resid+1,by=2)\n",
    "                mol.set('segid',curr_segid,sel=sel1)\n",
    "                # define next new segment with resids > 9999\n",
    "                k +=1\n",
    "                curr_segid = prefix+str(k)\n",
    "                if curr_segid in segids:\n",
    "                    raise ValueError('segid %s already exists.' % curr_segid)\n",
    "                # resid <= 9999 still preserve the old segid\n",
    "                idx_curr_segid = mol.atomselect('segid '+segid)\n",
    "                mol.segid[idx_curr_segid] = curr_segid\n",
    "                # get last resid of the current segid for the next loop iteration\n",
    "                mol = renumber_resid_vmd(mol,'segid '+curr_segid,by=2)\n",
    "                prev_resid = len(set(mol.resid[idx_curr_segid]))\n",
    "            \n",
    "        if k > 0:\n",
    "            if prefix+str(0) in segids:\n",
    "                print('WARNING: segid %s already exists, using %s instead.' % (prefix,prefix+str(0)))\n",
    "            else:\n",
    "                mol.segid[mol.segid == prefix] = prefix+str(0)\n",
    "        \n",
    "    return mol\n",
    "\n",
    "def renumber_resid_by_resid(sel,mol,ordered=False):\n",
    "    resids = list(set(mol.get('resid',sel=sel)))\n",
    "    if ordered:\n",
    "        resids = sort(resids)\n",
    "    newresid = 1\n",
    "    for resid in resids:\n",
    "        mol.set('resid',newresid,sel='(%s) and (resid %s)' % (sel,resid))\n",
    "        newresid += 1\n",
    "    return mol\n",
    "\n",
    "def renumber_resid(mol,sel,by=3):\n",
    "    \n",
    "    # Long story short: by=1 -> by_resname; by=2 -> by_segid; by=3 -> by_segid and by_resname\n",
    "    # WTF!!!!\n",
    "    option_num = 2\n",
    "    max_value = 2**option_num - 1\n",
    "    if by > max_value:\n",
    "        raise ValueError('Maximum value for \"by\" keyword is %d.' % max_value)\n",
    "    if by < 1:\n",
    "        raise ValueError('Minimum value for \"by\" keyword is \"1\".')\n",
    "    bin_by = format(by,'0'+str(option_num)+'b')\n",
    "    option_array = [bool(int(i)) for i in bin_by]\n",
    "    by_segid = option_array[0]\n",
    "    by_resname = option_array[1]\n",
    "    \n",
    "    if by_segid:\n",
    "        segids = set(mol.get('segid',sel=sel))      \n",
    "        for segid in segids:\n",
    "            if by_resname:\n",
    "                resnames = set(mol.get('resname',sel='(%s) and segid %s' % (sel,segid)))\n",
    "                for resname in resnames:\n",
    "                    lsel = '(%s) and (segid %s) and (resname %s)' % (sel,segid,resname)\n",
    "                    mol = renumber_resid_by_resid(lsel,mol)\n",
    "            else:\n",
    "                lsel = '(%s) and (segid %s)' % (sel,segid)\n",
    "                mol = renumber_resid_by_resid(lsel,mol)\n",
    "    else:                      \n",
    "        resnames = set(mol.get('resname',sel=sel))\n",
    "        for resname in resnames:\n",
    "            lsel = '(%s) and (resname %s)' % (sel,resname)\n",
    "            mol = renumber_resid_by_resid(lsel,mol)\n",
    "    return mol\n",
    "\n",
    "def fix_and_prepare_input(inputmol,first='NTER',last='CTER'):\n",
    "    \"\"\"\n",
    "    ISMAEL FUNCTION\n",
    "    Establish homogeneus nomenclature for protein residue names and segments for the system.\n",
    "    \"\"\"\n",
    "    \n",
    "    mol = inputmol.copy()\n",
    "    aa= 'ALA ARG ASN ASP CYS GLU GLN GLY HIS ILE LEU LYS MET PHE PRO SER THR TRP TYR VAL'\n",
    "    mol.set('segid','WAT',sel='water')\n",
    "    mol.set('resname','TIP3',sel='water')\n",
    "    mol.set('chain','X',sel='resname TIP3')\n",
    "    mol.set('name','OH2',sel='resname TIP3 and name OW')\n",
    "    mol.set('name','H1',sel='resname TIP3 and name HW1')\n",
    "    mol.set('name','H2',sel='resname TIP3 and name HW2')\n",
    "    mol.remove('(protein or resname '+aa+') and name O1 O2')\n",
    "    if first == 'NTER':\n",
    "        mol.set('name','HT1',sel='(protein or resname '+aa+')and name H1')\n",
    "        mol.set('name','HT2',sel='(protein or resname '+aa+') and name H2')\n",
    "        mol.set('name','HT3',sel='(protein or resname '+aa+') and name H3')\n",
    "    else:\n",
    "        mol.remove('(protein or resname '+aa+')and name H1 H2 H3')\n",
    "    if last in {'CTER','CNEU','CTP','CT1'}:\n",
    "        mol.set('name','OT1',sel='(protein or resname '+aa+') and name O1')\n",
    "        mol.set('name','OT2',sel='(protein or resname '+aa+') and name O2')\n",
    "        #fix\n",
    "        mol.remove('(protein or resname '+aa+') and name OT2')\n",
    "    else:\n",
    "        mol.set('name','O',sel='(protein or resname '+aa+') and name O1')\n",
    "        mol.remove('(protein or resname '+aa+') and name O2')\n",
    "    mol.set('name','HG1',sel='resname CYS and name HG')\n",
    "    mol.set('name','HN',sel='resname HIS and name H')\n",
    "    \n",
    "    his_he_resids = mol.get('resid',sel='resname HIS and name HE2')\n",
    "    his_he_chains = mol.get('chain',sel='resname HIS and name HE2')\n",
    "    his_he_ids = set([':'.join((chain,str(resid))) for resid,chain in zip(his_he_resids,his_he_chains)])\n",
    "    his_hd_resids = mol.get('resid',sel='resname HIS and name HD1')\n",
    "    his_hd_chains = mol.get('chain',sel='resname HIS and name HD1')\n",
    "    his_hd_ids = set([':'.join((chain,str(resid))) for resid,chain in zip(his_hd_resids,his_hd_chains)])\n",
    "    hsd_ids = his_hd_ids.difference(his_he_ids)\n",
    "    hse_ids = his_he_ids.difference(his_hd_ids)\n",
    "    hsp_ids = his_hd_ids.intersection(his_he_ids)\n",
    "    hsd_dict = dict()\n",
    "    hse_dict = dict()\n",
    "    hsp_dict = dict()\n",
    "    \n",
    "    for chain,resid in [ id1.split(':') for id1 in hsd_ids]:\n",
    "        if chain not in hsd_dict:\n",
    "            hsd_dict[chain] = []\n",
    "        hsd_dict[chain].append(resid)\n",
    "    for chain,resid in [ id1.split(':') for id1 in hse_ids]:\n",
    "        if chain not in hse_dict:\n",
    "            hse_dict[chain] = []\n",
    "        hse_dict[chain].append(resid)\n",
    "    for chain,resid in [ id1.split(':') for id1 in hsp_ids]:\n",
    "        if chain not in hsp_dict:\n",
    "            hsp_dict[chain] = []\n",
    "        hsp_dict[chain].append(resid)\n",
    "    for chain in hsd_dict:\n",
    "        sel1 = 'resname HIS and resid '+' '.join(hsd_dict[chain])\n",
    "        mol.set('resname','HSD',sel=sel1)\n",
    "    for chain in hse_dict:\n",
    "        sel1 = 'resname HIS and resid '+' '.join(hse_dict[chain])\n",
    "        mol.set('resname','HSE',sel=sel1)\n",
    "    for chain in hsp_dict:\n",
    "        sel1 = 'resname HIS and resid '+' '.join(hsp_dict[chain])\n",
    "        mol.set('resname','HSP',sel=sel1)\n",
    "    mol = autoSegment(mol,sel='protein or resname '+aa)\n",
    "    mol.set('segid','LIG',sel='not (protein or resname '+aa+') and not water and not ions')\n",
    "    mol.set('chain','L',sel='segid LIG')\n",
    "    mol.set('segid','ION',sel='ions')\n",
    "    mol.set('chain','N',sel='segid ION')\n",
    "    protsegids = set(mol.get('segid',sel='protein'))\n",
    "    mol = renumber_resid(mol,'water',by=1)\n",
    "    mol = renumber_resid(mol,'ions',by=1)\n",
    "    mol = renumber_resid(mol,'segid LIG',by=2)\n",
    "    return (mol,protsegids)\n",
    "    #    for segid in protsegids:\n",
    "    #        resids = set(mol.get('resid',sel='segid '+segid))\n",
    "    #        for resid in resids:\n",
    "    #            resname = mol.get('resname',sel='resid '+str(resid)+' and segid '+segid)[0]\n",
    "    #            chain = mol.get('chain',sel='resid '+str(resid)+' and segid '+segid)[0]\n",
    "    #            mol.set('segid',segid,sel='resname '+resname+' and chain '+chain+' and resid '+str(segid))\n",
    "\n",
    "def segchain_json(sys_mol_fixed, sysname, resultspath, receptor_segids_sys):\n",
    "    \"\"\"\n",
    "    Write a file to remember to which of the original chains each segment belongs\n",
    "    \"\"\"\n",
    "    segchain = dict()\n",
    "    for seg in receptor_segids_sys:\n",
    "        chain = set(sys_mol_fixed.get('chain', sel='segid '+seg))\n",
    "        segchain[seg] = ' '.join(list(chain))\n",
    "\n",
    "    with open(resultspath+'data_sim/'+sysname+'/segchain.json', 'w') as f:\n",
    "        json.dump(segchain, f, indent = 4)\n",
    "    \n",
    "    \n",
    "def prepare_system(mol_aligned, pdbcode, thickness = None, sod2x50 = False):\n",
    "    \"\"\"\n",
    "    Assign protonation states using \"proteinPrepare\" function from HTMD, and \n",
    "    force protonation of ASP2x50 if required\n",
    "    \"\"\"\n",
    "    \n",
    "    # If required, force protonation of ASP2x50\n",
    "    if not sod2x50:\n",
    "        # Download GPCRdb structure's website, and extract residue table from it\n",
    "        structure_data = requests.get('https://gpcrdb.org/structure/homology_models/'+pdbcode+'_refined').content\n",
    "        soup = BeautifulSoup(structure_data, 'html.parser')\n",
    "        table = soup.find('table', attrs={'id':'rotamers'})\n",
    "        table_body = table.find('tbody')\n",
    "        rows = table_body.find_all('tr')\n",
    "\n",
    "        # Iterate trougth residue table to find 2.50 residue ID in this PDB file\n",
    "        asp2x50 = None\n",
    "        for row in rows:\n",
    "            cols = row.find_all('td')\n",
    "            cols = [ele.text.strip() for ele in cols]\n",
    "            if cols[3] == \"2.50x50\":\n",
    "                asp2x50 = cols[1]\n",
    "\n",
    "        # Force residue protonation\n",
    "        current2x50 = mol_aligned.get('resname', sel='resid '+asp2x50)[0]\n",
    "        if current2x50 in {'ASP','GLU'}:\n",
    "            mol_aligned = proteinPrepare(mol_aligned,\n",
    "                                         pH = 0,\n",
    "                                         holdSelection = 'not resid '+asp2x50\n",
    "                                 )\n",
    "        \n",
    "    # Prepare protein (assign protonation states to residues)\n",
    "    prepared_mol, table = proteinPrepare(mol_aligned,\n",
    "                                  hydrophobicThickness=thickness,\n",
    "                                  returnDetails = True,\n",
    "                                 )\n",
    "\n",
    "    return prepared_mol\n",
    "    \n",
    "def add_membrane(pdbmol,membranemol,protsegids,membrane_distance,coldist=1.3):\n",
    "    # Corrections for rotational difusion\n",
    "    prot = pdbmol.copy()\n",
    "    protsel = 'segid '+' '.join(protsegids)\n",
    "    prot.filter(protsel,_logger=False)\n",
    "    r = minimalRotation(prot)\n",
    "    M = rotationMatrix([0, 0, 1], r)\n",
    "    pdbmol.rotateBy(M)\n",
    "    pcoor = pdbmol.get('coords',sel=protsel)\n",
    "    Mcoor = np.max(pcoor,axis=0)\n",
    "    mcoor = np.min(pcoor,axis=0)\n",
    "    # get the diagonal of XY of the protein if XY is a square \n",
    "    # which side is as long as the largest side (between X and Y) from the protein box  \n",
    "    p_dim = [Mcoor[0] - mcoor[0],Mcoor[1] - mcoor[1]]\n",
    "    maxXY = np.sqrt(p_dim[0]**2+p_dim[1]**2)\n",
    "    minimum_box_size_x = maxXY+2\n",
    "    minimum_box_size_y = minimum_box_size_x\n",
    "    \n",
    "    # get min max coor of the system\n",
    "    minc = np.min(pdbmol.coords, axis=0).flatten()\n",
    "    maxc = np.max(pdbmol.coords, axis=0).flatten()\n",
    "    \n",
    "    system_size_x = maxc[0] - minc[0]\n",
    "    system_size_y = maxc[1] - minc[1]\n",
    "    \n",
    "    center_x = system_size_x/2 + minc[0]\n",
    "    center_y = system_size_y/2 + minc[1]\n",
    "    \n",
    "    system_size = np.max([system_size_x,system_size_y])\n",
    "    corr_system_size_x = np.max([minimum_box_size_x,system_size]) \n",
    "    corr_system_size_y = np.max([minimum_box_size_y,system_size])\n",
    "    \n",
    "    addmembdist = membrane_distance/2.0+np.max([coldist,1.5])+0.0\n",
    "    \n",
    "    xlim = [center_x-corr_system_size_x/2-addmembdist,center_x+corr_system_size_x/2+addmembdist]\n",
    "    ylim = [center_y-corr_system_size_y/2-addmembdist,center_y+corr_system_size_y/2+addmembdist]\n",
    "    \n",
    "    memb = membranemol.copy()\n",
    "    memb.remove('ions',_logger=False)\n",
    "    memb2 = tileMembrane(memb, xlim[0], ylim[0], xlim[1], ylim[1])\n",
    "    \n",
    "    #from tileMembrane\n",
    "    size = np.max(membranemol.get('coords', 'water'), axis=0) - np.min(membranemol.get('coords', 'water'), axis=0)\n",
    "    xreps = int(np.ceil((xlim[1] - xlim[0]) / size[0]))\n",
    "    yreps = int(np.ceil((ylim[1] - ylim[0]) / size[1]))\n",
    "    \n",
    "    membtmp_segids = ordered_unique(memb2.get('segid'))\n",
    "    k=0\n",
    "    for segid in membtmp_segids:\n",
    "    #    memb2.set('segid','M'+str(k),sel='segid '+segid+' and not waters')\n",
    "         memb2.set('segid','W'+str(k),sel='segid '+segid+' and waters')\n",
    "         k += 1\n",
    "            \n",
    "    memb2 = renumber_segments(memb2,set(memb2.get('segid',sel='waters')),'MW')\n",
    "    memb2 = renumber_segments(memb2,set(memb2.get('segid',sel='not waters')),'MEM')\n",
    "    membrane_resnames = set(memb2.get('resname'))\n",
    "    membrane_segids = set(memb2.get('segid'))\n",
    "    \n",
    "    mcenter = np.mean(memb2.get('coords',sel='segid MEM'),axis=0)\n",
    "    memb2.moveBy(-mcenter)\n",
    "\n",
    "    memb2, num = removeLipidsInProtein(pdbmol, memb2,lipidsel='lipids or waters')\n",
    "    \n",
    "    mol = pdbmol.copy()\n",
    "    mol.append(memb2, collisions=True,coldist=coldist)\n",
    "    \n",
    "    return (mol, membrane_resnames,membrane_segids,xreps,yreps)\n",
    "\n",
    "def solvate_pdbmol(mol,membrane_segids,water_thickness,water_margin,buffer=2.4,coldist=1.3,prefix='W'):\n",
    "    waterbox = mol.get('coords','(waters or ions) and segid '+' '.join(membrane_segids))\n",
    "    mwaterbox = np.min(waterbox, axis=0)\n",
    "    Mwaterbox = np.max(waterbox, axis=0)\n",
    "    coo = mol.get('coords','not (waters or ions)')\n",
    "    mcoo = np.min(coo, axis=0)\n",
    "    Mcoo = np.max(coo, axis=0)\n",
    "    cooall = mol.get('coords','all')\n",
    "    mcooall = np.min(coo, axis=0)\n",
    "    Mcooall = np.max(coo, axis=0)\n",
    "    #top layer\n",
    "    M1z = Mcoo[2] + water_thickness/2. + np.max((coldist,buffer)) - buffer\n",
    "    m1z = Mwaterbox[2] - water_margin\n",
    "    M1 = [Mwaterbox[0],Mwaterbox[1],M1z]\n",
    "    m1 = [mwaterbox[0],mwaterbox[1],m1z]\n",
    "    print(\"wataerbox Max and min: \", Mwaterbox, mwaterbox)\n",
    "    \n",
    "    #bottom layer\n",
    "    M2z = mwaterbox[2] + water_margin\n",
    "    m2z = mcoo[2] - water_thickness/2.- np.max((coldist,buffer)) + buffer\n",
    "    M2 = [Mwaterbox[0],Mwaterbox[1],M2z]\n",
    "    m2 = [mwaterbox[0],mwaterbox[1],m2z]\n",
    "\n",
    "    smol = solvate(mol, minmax=np.vstack((m2,M1)),prefix=prefix,buffer=buffer)\n",
    "\n",
    "    smol, num_remove = removeAtomsInHull(smol, smol, 'name CA', 'segid \"'+prefix+'[0-9]+\"')\n",
    "    #wtsegids = set(smol.get('segid',sel='segid \"%s.*\"'% prefix))\n",
    "    #for segid in wtsegids:\n",
    "        #smol.remove('segid %s and same resid as ( z > %g and z < %g)' % (segid,M2[2],m1[2]),_logger=False)\n",
    "\n",
    "    return smol\n",
    "\n",
    "def add_dummy_atom(inputmol,property_dict):\n",
    "    for prop in property_dict:\n",
    "        dummymol.set(prop,property_dict[prop])\n",
    "    inputmol.append(dummymol,coldist=None)\n",
    "    return inputmol\n",
    "def add_center_dummy_atom(inputmol,coords,property_dict):\n",
    "    center = np.mean(coords,axis=0)\n",
    "    property_dict['coords'] = center\n",
    "    mol = add_dummy_atom(inputmol,property_dict)\n",
    "    return mol\n",
    "def remove_aromatic_insertions(inputmol,protsegids,coldist=1.5,outpdb=None):\n",
    "    mol = inputmol.copy()\n",
    "    atoms_data = [['TRP','CG CD1 CE1 NE1 CE2 CD2',5,'1'],\n",
    "                 ['TRP','CD2 CE2 CZ2 CH2 CZ3 CE3',6,'2'],\n",
    "                 ['PRO','N CA CB CG CD',5,''],\n",
    "                 ['HIS HSD HSE HSP HID HIE HIP',\n",
    "                  'CG CD1 CE1 CZ CE2 CD2 ND1 NE2',5,''],\n",
    "                 ['PHE TYR TYM',\n",
    "                  'CG CD1 CE1 CZ CE2 CD2',6,'']]\n",
    "    beta_backup = np.copy(mol.beta)\n",
    "    mol.set('beta',sequenceID((mol.resid, mol.insertion, mol.segid)))    \n",
    "    \n",
    "    for atom_data in atoms_data:\n",
    "        atom_step = atom_data[2]\n",
    "        suffix = atom_data[3]\n",
    "        sel = 'resname %s and name %s' % (atom_data[0],atom_data[1])\n",
    "        idxs = mol.get('index',sel=sel)\n",
    "        resnames = mol.resname[idxs]\n",
    "        resids = mol.resid[idxs]\n",
    "        segids = mol.segid[idxs]\n",
    "        coords = mol.coords[idxs,:,0]\n",
    "        atom_num = len(idxs)\n",
    "        if atom_num % atom_step != 0:\n",
    "            raise ValueError('Missing atoms.')\n",
    "        for i in range(0,atom_num,atom_step):\n",
    "            property_dict = {'resname':resnames[i]+suffix,'resid':resids[i],'segid':segids[i]}\n",
    "            mol = add_center_dummy_atom(mol,coords[i:i+atom_step],property_dict)\n",
    "            \n",
    "    if outpdb:\n",
    "        mol.write(outpdb)\n",
    "    var_list = tuple([coldist]+[dummy_sel for i in range(0,3)])\n",
    "    \n",
    "    dummy_atoms_idxs = mol.get('index',sel=dummy_sel)\n",
    "    dummy_atoms_resid = mol.resid[dummy_atoms_idxs]\n",
    "    dummy_atoms_segid = mol.segid[dummy_atoms_idxs]\n",
    "    removed_indexes = []\n",
    "    for idx,resid,segid in zip(dummy_atoms_idxs,dummy_atoms_resid,dummy_atoms_segid):\n",
    "        r_idx1 = mol.get('index', sel='not (%s) and same beta as ((exwithin %g of (index %d)) and not (resid %d and segid %s))'  % (dummy_sel,coldist,idx,resid,segid))\n",
    "        removed_indexes = removed_indexes + r_idx1.tolist()\n",
    "        \n",
    "    if len(removed_indexes) > 0:\n",
    "        removed_indexes_str = ' '.join(str(x) for x in removed_indexes)\n",
    "        mol.remove('index '+removed_indexes_str)\n",
    "    mol.remove(dummy_sel,_logger=False)\n",
    "    inv_idx1 = np.setdiff1d(np.arange(len(beta_backup)), np.array(removed_indexes), assume_unique=True)\n",
    "    mol.beta = beta_backup[inv_idx1]\n",
    "        \n",
    "    print('WARNING: removed '+str(len(removed_indexes))+' atoms within '+str(coldist)+' of a protein aromatic ring')\n",
    "    \n",
    "    return (mol,removed_indexes)\n",
    "\n",
    "def define_equilibration(const_sel):\n",
    "    simtime = 40\n",
    "    restr = AtomRestraint(const_sel, 2, [(0,\"0\"),(1,\"%dns\" % int(simtime*0.5)),(0,\"%dns\" % int(simtime*0.75))], \"xyz\")\n",
    "    md = Equilibration()\n",
    "    md.runtime = simtime\n",
    "    md.timeunits = 'ns'\n",
    "    md.temperature = 310\n",
    "    md.nvtsteps = 0\n",
    "    md.acemd.barostatconstratio = 'on'\n",
    "    md.acemd.minimize = 5000\n",
    "    #md.acemd.minimize = str(5000)\n",
    "    md.acemd.restart = 'off'\n",
    "    md.acemd.timestep = 2\n",
    "    md.restraints = restr\n",
    "    md._version = 3\n",
    "    return md\n",
    "\n",
    "def define_production(timestep, trajperiod):\n",
    "    md = Production()\n",
    "    md.runtime = 500\n",
    "    md.timeunits = 'ns'\n",
    "    md.temperature = 310\n",
    "    md.acemd.restart = 'off'    \n",
    "    md.acemd.timestep = timestep\n",
    "    md.acemd.barostatconstratio = 'on'\n",
    "    md.acemd.restart = 'off'\n",
    "    md.acemd.trajectoryPeriod = trajperiod\n",
    "    md.acemd.bincoordinates = 'output.coor'\n",
    "    md.acemd.extendedsystem  = 'output.xsc'\n",
    "    md.acemd.binvelocities = 'output.vel'\n",
    "    return md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 6FK9 structure (1/192)\n",
      "Structure for 6FK9 already present. Skipping...\n",
      "Downloading 5MZP structure (2/192)\n",
      "Structure for 5MZP already present. Skipping...\n",
      "Downloading 5K2B structure (3/192)\n",
      "Structure for 5K2B already present. Skipping...\n",
      "Downloading 2YCZ structure (4/192)\n",
      "Structure for 2YCZ already present. Skipping...\n",
      "Downloading 6GPX structure (5/192)\n",
      "Structure for 6GPX already present. Skipping...\n",
      "Downloading 5UNH structure (6/192)\n",
      "Structure for 5UNH already present. Skipping...\n",
      "Downloading 6ME4 structure (7/192)\n",
      "Structure for 6ME4 already present. Skipping...\n",
      "Downloading 5K2C structure (8/192)\n",
      "could not download 5K2C refined structure. Skipping...\n",
      "Downloading 4EJ4 structure (9/192)\n",
      "Structure for 4EJ4 already present. Skipping...\n",
      "Downloading 6AKY structure (10/192)\n",
      "Structure for 6AKY already present. Skipping...\n",
      "Downloading 5WF5 structure (11/192)\n",
      "Structure for 5WF5 already present. Skipping...\n",
      "Downloading 5GLI structure (12/192)\n",
      "Structure for 5GLI already present. Skipping...\n",
      "Downloading 6KK7 structure (13/192)\n",
      "Structure for 6KK7 already present. Skipping...\n",
      "Downloading 6M9T structure (14/192)\n",
      "Structure for 6M9T already present. Skipping...\n",
      "Downloading 5ZKC structure (15/192)\n",
      "Structure for 5ZKC already present. Skipping...\n",
      "Downloading 6DRY structure (16/192)\n",
      "Structure for 6DRY already present. Skipping...\n",
      "Downloading 6J21 structure (17/192)\n",
      "Structure for 6J21 already present. Skipping...\n",
      "Downloading 5OM4 structure (18/192)\n",
      "Structure for 5OM4 already present. Skipping...\n",
      "Downloading 5TZR structure (19/192)\n",
      "Structure for 5TZR already present. Skipping...\n",
      "Downloading 6TOD structure (20/192)\n",
      "could not download 6TOD refined structure. Skipping...\n",
      "Downloading 5OLV structure (21/192)\n",
      "Structure for 5OLV already present. Skipping...\n",
      "Downloading 6E59 structure (22/192)\n",
      "Structure for 6E59 already present. Skipping...\n",
      "Downloading 6FFH structure (23/192)\n",
      "Structure for 6FFH already present. Skipping...\n",
      "Downloading 5TZY structure (24/192)\n",
      "Structure for 5TZY already present. Skipping...\n",
      "Downloading 6FK8 structure (25/192)\n",
      "Structure for 6FK8 already present. Skipping...\n",
      "Downloading 4Z9G structure (26/192)\n",
      "Structure for 4Z9G already present. Skipping...\n",
      "Downloading 6PS3 structure (27/192)\n",
      "Structure for 6PS3 already present. Skipping...\n",
      "Downloading 1GZM structure (28/192)\n",
      "could not download 1GZM refined structure. Skipping...\n",
      "Downloading 4QIM structure (29/192)\n",
      "Structure for 4QIM already present. Skipping...\n",
      "Downloading 6LI2 structure (30/192)\n",
      "Structure for 6LI2 already present. Skipping...\n",
      "Downloading 6OL9 structure (31/192)\n",
      "Structure for 6OL9 already present. Skipping...\n",
      "Downloading 5NLX structure (32/192)\n",
      "Structure for 5NLX already present. Skipping...\n",
      "Downloading 6RZ9 structure (33/192)\n",
      "Structure for 6RZ9 already present. Skipping...\n",
      "Downloading 5F8U structure (34/192)\n",
      "Structure for 5F8U already present. Skipping...\n",
      "Downloading 5ZHP structure (35/192)\n",
      "Structure for 5ZHP already present. Skipping...\n",
      "Downloading 6RZ6 structure (36/192)\n",
      "Structure for 6RZ6 already present. Skipping...\n",
      "Downloading 6ME3 structure (37/192)\n",
      "Structure for 6ME3 already present. Skipping...\n",
      "Downloading 6FKC structure (38/192)\n",
      "Structure for 6FKC already present. Skipping...\n",
      "Downloading 5TVN structure (39/192)\n",
      "Structure for 5TVN already present. Skipping...\n",
      "Downloading 6AKX structure (40/192)\n",
      "Structure for 6AKX already present. Skipping...\n",
      "Downloading 6KPC structure (41/192)\n",
      "Structure for 6KPC already present. Skipping...\n",
      "Downloading 6ME2 structure (42/192)\n",
      "Structure for 6ME2 already present. Skipping...\n",
      "Downloading 6PS1 structure (43/192)\n",
      "Structure for 6PS1 already present. Skipping...\n",
      "Downloading 5YC8 structure (44/192)\n",
      "Structure for 5YC8 already present. Skipping...\n",
      "Downloading 5TE5 structure (45/192)\n",
      "Structure for 5TE5 already present. Skipping...\n",
      "Downloading 6PRZ structure (46/192)\n",
      "Structure for 6PRZ already present. Skipping...\n",
      "Downloading 6KK1 structure (47/192)\n",
      "could not download 6KK1 refined structure. Skipping...\n",
      "Downloading 6BQG structure (48/192)\n",
      "could not download 6BQG refined structure. Skipping...\n",
      "Downloading 6K1Q structure (49/192)\n",
      "Structure for 6K1Q already present. Skipping...\n",
      "Downloading 5NM4 structure (50/192)\n",
      "could not download 5NM4 refined structure. Skipping...\n",
      "Downloading 5UVI structure (51/192)\n",
      "Structure for 5UVI already present. Skipping...\n",
      "Downloading 5V57 structure (52/192)\n",
      "Structure for 5V57 already present. Skipping...\n",
      "Downloading 6PS7 structure (53/192)\n",
      "Structure for 6PS7 already present. Skipping...\n",
      "Downloading 6PS5 structure (54/192)\n",
      "could not download 6PS5 refined structure. Skipping...\n",
      "Downloading 5ZBH structure (55/192)\n",
      "could not download 5ZBH refined structure. Skipping...\n",
      "Downloading 6D32 structure (56/192)\n",
      "Structure for 6D32 already present. Skipping...\n",
      "Downloading 5D6L structure (57/192)\n",
      "Structure for 5D6L already present. Skipping...\n",
      "Downloading 5WQC structure (58/192)\n",
      "Structure for 5WQC already present. Skipping...\n",
      "Downloading 4GBR structure (59/192)\n",
      "Structure for 4GBR already present. Skipping...\n",
      "Downloading 6RZ7 structure (60/192)\n",
      "Structure for 6RZ7 already present. Skipping...\n",
      "Downloading 5WS3 structure (61/192)\n",
      "Structure for 5WS3 already present. Skipping...\n",
      "Downloading 5T1A structure (62/192)\n",
      "Structure for 5T1A already present. Skipping...\n",
      "Downloading 4N4W structure (63/192)\n",
      "Structure for 4N4W already present. Skipping...\n",
      "Downloading 6HLL structure (64/192)\n",
      "Structure for 6HLL already present. Skipping...\n",
      "Downloading 6CM4 structure (65/192)\n",
      "Structure for 6CM4 already present. Skipping...\n",
      "Downloading 6GPS structure (66/192)\n",
      "Structure for 6GPS already present. Skipping...\n",
      "Downloading 6D27 structure (67/192)\n",
      "Structure for 6D27 already present. Skipping...\n",
      "Downloading 6FFI structure (68/192)\n",
      "Structure for 6FFI already present. Skipping...\n",
      "Downloading 5X7D structure (69/192)\n",
      "Structure for 5X7D already present. Skipping...\n",
      "Downloading 6AQF structure (70/192)\n",
      "Structure for 6AQF already present. Skipping...\n",
      "Downloading 6IIU structure (71/192)\n",
      "Structure for 6IIU already present. Skipping...\n",
      "Downloading 5VBL structure (72/192)\n",
      "Structure for 5VBL already present. Skipping...\n",
      "Downloading 6AK3 structure (73/192)\n",
      "Structure for 6AK3 already present. Skipping...\n",
      "Downloading 5XRA structure (74/192)\n",
      "Structure for 5XRA already present. Skipping...\n",
      "Downloading 5OLG structure (75/192)\n",
      "could not download 5OLG refined structure. Skipping...\n",
      "Downloading 5EE7 structure (76/192)\n",
      "Structure for 5EE7 already present. Skipping...\n",
      "Downloading 5UNF structure (77/192)\n",
      "Structure for 5UNF already present. Skipping...\n",
      "Downloading 6FK6 structure (78/192)\n",
      "Structure for 6FK6 already present. Skipping...\n",
      "Downloading 6TQ4 structure (79/192)\n",
      "Structure for 6TQ4 already present. Skipping...\n",
      "Downloading 5VEX structure (80/192)\n",
      "Structure for 5VEX already present. Skipping...\n",
      "Downloading 6DRX structure (81/192)\n",
      "Structure for 6DRX already present. Skipping...\n",
      "Downloading 5VEW structure (82/192)\n",
      "Structure for 5VEW already present. Skipping...\n",
      "Downloading 6ME8 structure (83/192)\n",
      "Structure for 6ME8 already present. Skipping...\n",
      "Downloading 6IGK structure (84/192)\n",
      "Structure for 6IGK already present. Skipping...\n",
      "Downloading 6ME6 structure (85/192)\n",
      "Structure for 6ME6 already present. Skipping...\n",
      "Downloading 4BUO structure (86/192)\n",
      "Structure for 4BUO already present. Skipping...\n",
      "Downloading 6KQI structure (87/192)\n",
      "Structure for 6KQI already present. Skipping...\n",
      "Downloading 6TQ7 structure (88/192)\n",
      "Structure for 6TQ7 already present. Skipping...\n",
      "Downloading 6TQ9 structure (89/192)\n",
      "Structure for 6TQ9 already present. Skipping...\n",
      "Downloading 5LWE structure (90/192)\n",
      "could not download 5LWE refined structure. Skipping...\n",
      "Downloading 6LI1 structure (91/192)\n",
      "Structure for 6LI1 already present. Skipping...\n",
      "Downloading 6TPG structure (92/192)\n",
      "Structure for 6TPG already present. Skipping...\n",
      "Downloading 6QZH structure (93/192)\n",
      "Structure for 6QZH already present. Skipping...\n",
      "Downloading 5K2D structure (94/192)\n",
      "Structure for 5K2D already present. Skipping...\n",
      "Downloading 6D35 structure (95/192)\n",
      "Structure for 6D35 already present. Skipping...\n",
      "Downloading 6A93 structure (96/192)\n",
      "Structure for 6A93 already present. Skipping...\n",
      "Downloading 6ME9 structure (97/192)\n",
      "Structure for 6ME9 already present. Skipping...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 5N2R structure (98/192)\n",
      "Structure for 5N2R already present. Skipping...\n",
      "Downloading 5XSZ structure (99/192)\n",
      "Structure for 5XSZ already present. Skipping...\n",
      "Downloading 6KJV structure (100/192)\n",
      "Structure for 6KJV already present. Skipping...\n",
      "Downloading 5NDZ structure (101/192)\n",
      "Structure for 5NDZ already present. Skipping...\n",
      "Downloading 4NTJ structure (102/192)\n",
      "Structure for 4NTJ already present. Skipping...\n",
      "Downloading 5YQZ structure (103/192)\n",
      "Structure for 5YQZ already present. Skipping...\n",
      "Downloading 6FK7 structure (104/192)\n",
      "Structure for 6FK7 already present. Skipping...\n",
      "Downloading 4XT3 structure (105/192)\n",
      "Structure for 4XT3 already present. Skipping...\n",
      "Downloading 6KP6 structure (106/192)\n",
      "Structure for 6KP6 already present. Skipping...\n",
      "Downloading 6TP3 structure (107/192)\n",
      "could not download 6TP3 refined structure. Skipping...\n",
      "Downloading 5WIV structure (108/192)\n",
      "Structure for 5WIV already present. Skipping...\n",
      "Downloading 5ZKB structure (109/192)\n",
      "Structure for 5ZKB already present. Skipping...\n",
      "Downloading 5UIG structure (110/192)\n",
      "Structure for 5UIG already present. Skipping...\n",
      "Downloading 5UNG structure (111/192)\n",
      "Structure for 5UNG already present. Skipping...\n",
      "Downloading 5KW2 structure (112/192)\n",
      "Structure for 5KW2 already present. Skipping...\n",
      "Downloading 6RZ4 structure (113/192)\n",
      "Structure for 6RZ4 already present. Skipping...\n",
      "Downloading 6C1Q structure (114/192)\n",
      "could not download 6C1Q refined structure. Skipping...\n",
      "Downloading 6PS4 structure (115/192)\n",
      "Structure for 6PS4 already present. Skipping...\n",
      "Downloading 6GT3 structure (116/192)\n",
      "Structure for 6GT3 already present. Skipping...\n",
      "Downloading 6ME5 structure (117/192)\n",
      "Structure for 6ME5 already present. Skipping...\n",
      "Downloading 6LRY structure (118/192)\n",
      "Structure for 6LRY already present. Skipping...\n",
      "Downloading 6TO7 structure (119/192)\n",
      "Structure for 6TO7 already present. Skipping...\n",
      "Downloading 6RZ8 structure (120/192)\n",
      "Structure for 6RZ8 already present. Skipping...\n",
      "Downloading 4JKV structure (121/192)\n",
      "Structure for 4JKV already present. Skipping...\n",
      "Downloading 5OLO structure (122/192)\n",
      "Structure for 5OLO already present. Skipping...\n",
      "Downloading 5ZKP structure (123/192)\n",
      "could not download 5ZKP refined structure. Skipping...\n",
      "Downloading 5WIU structure (124/192)\n",
      "Structure for 5WIU already present. Skipping...\n",
      "Downloading 6FJ3 structure (125/192)\n",
      "Structure for 6FJ3 already present. Skipping...\n",
      "Downloading 5JTB structure (126/192)\n",
      "Structure for 5JTB already present. Skipping...\n",
      "Downloading 5NM2 structure (127/192)\n",
      "could not download 5NM2 refined structure. Skipping...\n",
      "Downloading 5UIW structure (128/192)\n",
      "Structure for 5UIW already present. Skipping...\n",
      "Downloading 6TOS structure (129/192)\n",
      "Structure for 6TOS already present. Skipping...\n",
      "Downloading 6JZH structure (130/192)\n",
      "Structure for 6JZH already present. Skipping...\n",
      "Downloading 6FKA structure (131/192)\n",
      "Structure for 6FKA already present. Skipping...\n",
      "Downloading 5NX2 structure (132/192)\n",
      "Structure for 5NX2 already present. Skipping...\n",
      "Downloading 6PS8 structure (133/192)\n",
      "Structure for 6PS8 already present. Skipping...\n",
      "Downloading 5XPR structure (134/192)\n",
      "Structure for 5XPR already present. Skipping...\n",
      "Downloading 5ZBQ structure (135/192)\n",
      "Structure for 5ZBQ already present. Skipping...\n",
      "Downloading 6TPJ structure (136/192)\n",
      "Structure for 6TPJ already present. Skipping...\n",
      "Downloading 6FKD structure (137/192)\n",
      "Structure for 6FKD already present. Skipping...\n",
      "Downloading 6KNM structure (138/192)\n",
      "Structure for 6KNM already present. Skipping...\n",
      "Downloading 6LW5 structure (139/192)\n",
      "Structure for 6LW5 already present. Skipping...\n",
      "Downloading 4O9R structure (140/192)\n",
      "Structure for 4O9R already present. Skipping...\n",
      "Downloading 6IIV structure (141/192)\n",
      "Structure for 6IIV already present. Skipping...\n",
      "Downloading 6D26 structure (142/192)\n",
      "Structure for 6D26 already present. Skipping...\n",
      "Downloading 6C1R structure (143/192)\n",
      "could not download 6C1R refined structure. Skipping...\n",
      "Downloading 6RZ5 structure (144/192)\n",
      "Structure for 6RZ5 already present. Skipping...\n",
      "Downloading 5K2A structure (145/192)\n",
      "Structure for 5K2A already present. Skipping...\n",
      "Downloading 6MH8 structure (146/192)\n",
      "Structure for 6MH8 already present. Skipping...\n",
      "Downloading 6A94 structure (147/192)\n",
      "Structure for 6A94 already present. Skipping...\n",
      "Downloading 5O9H structure (148/192)\n",
      "could not download 5O9H refined structure. Skipping...\n",
      "Downloading 6TP6 structure (149/192)\n",
      "Structure for 6TP6 already present. Skipping...\n",
      "Downloading 4NC3 structure (150/192)\n",
      "Structure for 4NC3 already present. Skipping...\n",
      "Downloading 6HLO structure (151/192)\n",
      "Structure for 6HLO already present. Skipping...\n",
      "Downloading 5VRA structure (152/192)\n",
      "Structure for 5VRA already present. Skipping...\n",
      "Downloading 6LI0 structure (153/192)\n",
      "Structure for 6LI0 already present. Skipping...\n",
      "Downloading 5OLZ structure (154/192)\n",
      "Structure for 5OLZ already present. Skipping...\n",
      "Downloading 6DRZ structure (155/192)\n",
      "Structure for 6DRZ already present. Skipping...\n",
      "Downloading 4GPO structure (156/192)\n",
      "Structure for 4GPO already present. Skipping...\n",
      "Downloading 6BQH structure (157/192)\n",
      "could not download 6BQH refined structure. Skipping...\n",
      "Downloading 5XR8 structure (158/192)\n",
      "Structure for 5XR8 already present. Skipping...\n",
      "Downloading 6OBA structure (159/192)\n",
      "could not download 6OBA refined structure. Skipping...\n",
      "Downloading 6PS2 structure (160/192)\n",
      "Structure for 6PS2 already present. Skipping...\n",
      "Downloading 5X93 structure (161/192)\n",
      "Structure for 5X93 already present. Skipping...\n",
      "Downloading 6TQ6 structure (162/192)\n",
      "Structure for 6TQ6 already present. Skipping...\n",
      "Downloading 5ZK3 structure (163/192)\n",
      "Structure for 5ZK3 already present. Skipping...\n",
      "Downloading 5ZKQ structure (164/192)\n",
      "Structure for 5ZKQ already present. Skipping...\n",
      "Downloading 5T04 structure (165/192)\n",
      "Structure for 5T04 already present. Skipping...\n",
      "Downloading 6DS0 structure (166/192)\n",
      "Structure for 6DS0 already present. Skipping...\n",
      "Downloading 5NDD structure (167/192)\n",
      "Structure for 5NDD already present. Skipping...\n",
      "Downloading 6PS6 structure (168/192)\n",
      "Structure for 6PS6 already present. Skipping...\n",
      "Downloading 6IGL structure (169/192)\n",
      "Structure for 6IGL already present. Skipping...\n",
      "Downloading 6TP4 structure (170/192)\n",
      "Structure for 6TP4 already present. Skipping...\n",
      "Downloading 6TPN structure (171/192)\n",
      "Structure for 6TPN already present. Skipping...\n",
      "Downloading 6HLP structure (172/192)\n",
      "Structure for 6HLP already present. Skipping...\n",
      "Downloading 6FKB structure (173/192)\n",
      "Structure for 6FKB already present. Skipping...\n",
      "Downloading 5MZJ structure (174/192)\n",
      "Structure for 5MZJ already present. Skipping...\n",
      "Downloading 6PS0 structure (175/192)\n",
      "Structure for 6PS0 already present. Skipping...\n",
      "Downloading 6ME7 structure (176/192)\n",
      "Structure for 6ME7 already present. Skipping...\n",
      "Downloading 5X33 structure (177/192)\n",
      "Structure for 5X33 already present. Skipping...\n",
      "Downloading 6J20 structure (178/192)\n",
      "Structure for 6J20 already present. Skipping...\n",
      "Downloading 5OLH structure (179/192)\n",
      "Structure for 5OLH already present. Skipping...\n",
      "Downloading 6TOT structure (180/192)\n",
      "Structure for 6TOT already present. Skipping...\n",
      "Downloading 5WF6 structure (181/192)\n",
      "Structure for 5WF6 already present. Skipping...\n",
      "Downloading 5ZTY structure (182/192)\n",
      "could not download 5ZTY refined structure. Skipping...\n",
      "Downloading 5N2S structure (183/192)\n",
      "Structure for 5N2S already present. Skipping...\n",
      "Downloading 5V54 structure (184/192)\n",
      "Structure for 5V54 already present. Skipping...\n",
      "Downloading 5ZK8 structure (185/192)\n",
      "Structure for 5ZK8 already present. Skipping...\n",
      "Downloading 4XES structure (186/192)\n",
      "Structure for 4XES already present. Skipping...\n",
      "Downloading 5DYS structure (187/192)\n",
      "Structure for 5DYS already present. Skipping...\n",
      "Downloading 5OM1 structure (188/192)\n",
      "Structure for 5OM1 already present. Skipping...\n",
      "Downloading 2Z73 structure (189/192)\n",
      "Structure for 2Z73 already present. Skipping...\n",
      "Downloading 5TE3 structure (190/192)\n",
      "Structure for 5TE3 already present. Skipping...\n",
      "Downloading 5V56 structure (191/192)\n",
      "Structure for 5V56 already present. Skipping...\n",
      "Downloading 6LUQ structure (192/192)\n",
      "Structure for 6LUQ already present. Skipping...\n",
      "Getting toppar file for ligand 200 (1/252)\n",
      "toppar for ligand 200 already exists. Skipping...\n",
      "Getting toppar file for ligand TCE (2/252)\n",
      "toppar for ligand TCE already exists. Skipping...\n",
      "Getting toppar file for ligand PCA (3/252)\n",
      "toppar for ligand PCA already exists. Skipping...\n",
      "Getting toppar file for ligand 6AT (4/252)\n",
      "toppar for ligand 6AT already exists. Skipping...\n",
      "Getting toppar file for ligand T4E (5/252)\n",
      "toppar for ligand T4E already exists. Skipping...\n",
      "Getting toppar file for ligand 9EC (6/252)\n",
      "toppar for ligand 9EC already exists. Skipping...\n",
      "Getting toppar file for ligand ERC (7/252)\n",
      "toppar for ligand ERC already exists. Skipping...\n",
      "Getting toppar file for ligand MRV (8/252)\n",
      "toppar for ligand MRV already exists. Skipping...\n",
      "Getting toppar file for ligand DU1 (9/252)\n",
      "toppar for ligand DU1 already exists. Skipping...\n",
      "Getting toppar file for ligand GOL (10/252)\n",
      "toppar for ligand GOL already exists. Skipping...\n",
      "Getting toppar file for ligand JEY (11/252)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toppar for ligand JEY already exists. Skipping...\n",
      "Getting toppar file for ligand 8JN (12/252)\n",
      "toppar for ligand 8JN already exists. Skipping...\n",
      "Getting toppar file for ligand UNX (13/252)\n",
      "toppar for ligand UNX already exists. Skipping...\n",
      "Getting toppar file for ligand 836 (14/252)\n",
      "toppar for ligand 836 already exists. Skipping...\n",
      "Getting toppar file for ligand 97Y (15/252)\n",
      "toppar for ligand 97Y already exists. Skipping...\n",
      "Getting toppar file for ligand EJ4 (16/252)\n",
      "toppar for ligand EJ4 already exists. Skipping...\n",
      "Getting toppar file for ligand 7DY (17/252)\n",
      "toppar for ligand 7DY already exists. Skipping...\n",
      "Getting toppar file for ligand AZJ (18/252)\n",
      "toppar for ligand AZJ already exists. Skipping...\n",
      "Getting toppar file for ligand FSY (19/252)\n",
      "toppar for ligand FSY already exists. Skipping...\n",
      "Getting toppar file for ligand NRE (20/252)\n",
      "toppar for ligand NRE already exists. Skipping...\n",
      "Getting toppar file for ligand 6XQ (21/252)\n",
      "toppar for ligand 6XQ already exists. Skipping...\n",
      "Getting toppar file for ligand ADN (22/252)\n",
      "toppar for ligand ADN already exists. Skipping...\n",
      "Getting toppar file for ligand D7V (23/252)\n",
      "toppar for ligand D7V already exists. Skipping...\n",
      "Getting toppar file for ligand K86 (24/252)\n",
      "toppar for ligand K86 already exists. Skipping...\n",
      "Getting toppar file for ligand GBQ (25/252)\n",
      "toppar for ligand GBQ already exists. Skipping...\n",
      "Getting toppar file for ligand 2YB (26/252)\n",
      "toppar for ligand 2YB already exists. Skipping...\n",
      "Getting toppar file for ligand 8D1 (27/252)\n",
      "toppar for ligand 8D1 already exists. Skipping...\n",
      "Getting toppar file for ligand D8B (28/252)\n",
      "toppar for ligand D8B already exists. Skipping...\n",
      "Getting toppar file for ligand MPG (29/252)\n",
      "toppar for ligand MPG already exists. Skipping...\n",
      "Getting toppar file for ligand 2U8 (30/252)\n",
      "toppar for ligand 2U8 already exists. Skipping...\n",
      "Getting toppar file for ligand NRK (31/252)\n",
      "toppar for ligand NRK already exists. Skipping...\n",
      "Getting toppar file for ligand 9DT (32/252)\n",
      "toppar for ligand 9DT already exists. Skipping...\n",
      "Getting toppar file for ligand NRZ (33/252)\n",
      "toppar for ligand NRZ already exists. Skipping...\n",
      "Getting toppar file for ligand A4R (34/252)\n",
      "toppar for ligand A4R already exists. Skipping...\n",
      "Getting toppar file for ligand F9Q (35/252)\n",
      "toppar for ligand F9Q already exists. Skipping...\n",
      "Getting toppar file for ligand 0NN (36/252)\n",
      "toppar for ligand 0NN already exists. Skipping...\n",
      "Getting toppar file for ligand Y00 (37/252)\n",
      "toppar for ligand Y00 already exists. Skipping...\n",
      "Getting toppar file for ligand I32 (38/252)\n",
      "toppar for ligand I32 already exists. Skipping...\n",
      "Getting toppar file for ligand FM9 (39/252)\n",
      "toppar for ligand FM9 already exists. Skipping...\n",
      "Getting toppar file for ligand 8EM (40/252)\n",
      "toppar for ligand 8EM already exists. Skipping...\n",
      "Getting toppar file for ligand TAR (41/252)\n",
      "toppar for ligand TAR already exists. Skipping...\n",
      "Getting toppar file for ligand Y01 (42/252)\n",
      "toppar for ligand Y01 already exists. Skipping...\n",
      "Getting toppar file for ligand D7W (43/252)\n",
      "toppar for ligand D7W already exists. Skipping...\n",
      "Getting toppar file for ligand 1WV (44/252)\n",
      "toppar for ligand 1WV already exists. Skipping...\n",
      "Getting toppar file for ligand AIB (45/252)\n",
      "toppar for ligand AIB already exists. Skipping...\n",
      "Getting toppar file for ligand CY8 (46/252)\n",
      "toppar for ligand CY8 already exists. Skipping...\n",
      "Getting toppar file for ligand 9Y2 (47/252)\n",
      "toppar for ligand 9Y2 already exists. Skipping...\n",
      "Getting toppar file for ligand KNT (48/252)\n",
      "toppar for ligand KNT already exists. Skipping...\n",
      "Getting toppar file for ligand TYS (49/252)\n",
      "toppar for ligand TYS already exists. Skipping...\n",
      "Getting toppar file for ligand FMN (50/252)\n",
      "toppar for ligand FMN already exists. Skipping...\n",
      "Getting toppar file for ligand NA (51/252)\n",
      "toppar for ligand NA already exists. Skipping...\n",
      "Getting toppar file for ligand NU8 (52/252)\n",
      "toppar for ligand NU8 already exists. Skipping...\n",
      "Getting toppar file for ligand SOG (53/252)\n",
      "toppar for ligand SOG already exists. Skipping...\n",
      "Getting toppar file for ligand D2U (54/252)\n",
      "toppar for ligand D2U already exists. Skipping...\n",
      "Getting toppar file for ligand ZMA (55/252)\n",
      "toppar for ligand ZMA already exists. Skipping...\n",
      "Getting toppar file for ligand 4OT (56/252)\n",
      "toppar for ligand 4OT already exists. Skipping...\n",
      "Getting toppar file for ligand DLB (57/252)\n",
      "toppar for ligand DLB already exists. Skipping...\n",
      "Getting toppar file for ligand P33 (58/252)\n",
      "toppar for ligand P33 already exists. Skipping...\n",
      "Getting toppar file for ligand HTG (59/252)\n",
      "toppar for ligand HTG already exists. Skipping...\n",
      "Getting toppar file for ligand QXV (60/252)\n",
      "toppar for ligand QXV already exists. Skipping...\n",
      "Getting toppar file for ligand 8K8 (61/252)\n",
      "toppar for ligand 8K8 already exists. Skipping...\n",
      "Getting toppar file for ligand TIM (62/252)\n",
      "toppar for ligand TIM already exists. Skipping...\n",
      "Getting toppar file for ligand ZDG (63/252)\n",
      "toppar for ligand ZDG already exists. Skipping...\n",
      "Getting toppar file for ligand 8D0 (64/252)\n",
      "toppar for ligand 8D0 already exists. Skipping...\n",
      "Getting toppar file for ligand 0HK (65/252)\n",
      "toppar for ligand 0HK already exists. Skipping...\n",
      "Getting toppar file for ligand 8NU (66/252)\n",
      "toppar for ligand 8NU already exists. Skipping...\n",
      "Getting toppar file for ligand 9DW (67/252)\n",
      "toppar for ligand 9DW already exists. Skipping...\n",
      "Getting toppar file for ligand VPX (68/252)\n",
      "toppar for ligand VPX already exists. Skipping...\n",
      "Getting toppar file for ligand 7MA (69/252)\n",
      "toppar for ligand 7MA already exists. Skipping...\n",
      "Getting toppar file for ligand 7AB (70/252)\n",
      "toppar for ligand 7AB already exists. Skipping...\n",
      "Getting toppar file for ligand PEG (71/252)\n",
      "toppar for ligand PEG already exists. Skipping...\n",
      "Getting toppar file for ligand H8D (72/252)\n",
      "toppar for ligand H8D already exists. Skipping...\n",
      "Getting toppar file for ligand 8D3 (73/252)\n",
      "toppar for ligand 8D3 already exists. Skipping...\n",
      "Getting toppar file for ligand OLC (74/252)\n",
      "toppar for ligand OLC already exists. Skipping...\n",
      "Getting toppar file for ligand 3WC (75/252)\n",
      "toppar for ligand 3WC already exists. Skipping...\n",
      "Getting toppar file for ligand EPE (76/252)\n",
      "toppar for ligand EPE already exists. Skipping...\n",
      "Getting toppar file for ligand ALC (77/252)\n",
      "toppar for ligand ALC already exists. Skipping...\n",
      "Getting toppar file for ligand HTO (78/252)\n",
      "toppar for ligand HTO already exists. Skipping...\n",
      "Getting toppar file for ligand 9GL (79/252)\n",
      "toppar for ligand 9GL already exists. Skipping...\n",
      "Getting toppar file for ligand K87 (80/252)\n",
      "toppar for ligand K87 already exists. Skipping...\n",
      "Getting toppar file for ligand DMS (81/252)\n",
      "toppar for ligand DMS already exists. Skipping...\n",
      "Getting toppar file for ligand GLY (82/252)\n",
      "toppar for ligand GLY already exists. Skipping...\n",
      "Getting toppar file for ligand AC5 (83/252)\n",
      "toppar for ligand AC5 already exists. Skipping...\n",
      "Getting toppar file for ligand M3J (84/252)\n",
      "toppar for ligand M3J already exists. Skipping...\n",
      "Getting toppar file for ligand ZD7 (85/252)\n",
      "toppar for ligand ZD7 already exists. Skipping...\n",
      "Getting toppar file for ligand DLH (86/252)\n",
      "toppar for ligand DLH already exists. Skipping...\n",
      "Getting toppar file for ligand 1KS (87/252)\n",
      "toppar for ligand 1KS already exists. Skipping...\n",
      "Getting toppar file for ligand 2GM (88/252)\n",
      "toppar for ligand 2GM already exists. Skipping...\n",
      "Getting toppar file for ligand H8J (89/252)\n",
      "toppar for ligand H8J already exists. Skipping...\n",
      "Getting toppar file for ligand NH2 (90/252)\n",
      "toppar for ligand NH2 already exists. Skipping...\n",
      "Getting toppar file for ligand ERM (91/252)\n",
      "toppar for ligand ERM already exists. Skipping...\n",
      "Getting toppar file for ligand MAN (92/252)\n",
      "toppar for ligand MAN already exists. Skipping...\n",
      "Getting toppar file for ligand HG (93/252)\n",
      "toppar for ligand HG already exists. Skipping...\n",
      "Getting toppar file for ligand DNZ (94/252)\n",
      "toppar for ligand DNZ already exists. Skipping...\n",
      "Getting toppar file for ligand HRG (95/252)\n",
      "toppar for ligand HRG already exists. Skipping...\n",
      "Getting toppar file for ligand UKA (96/252)\n",
      "toppar for ligand UKA already exists. Skipping...\n",
      "Getting toppar file for ligand NVK (97/252)\n",
      "toppar for ligand NVK already exists. Skipping...\n",
      "Getting toppar file for ligand GBK (98/252)\n",
      "toppar for ligand GBK already exists. Skipping...\n",
      "Getting toppar file for ligand 8UN (99/252)\n",
      "toppar for ligand 8UN already exists. Skipping...\n",
      "Getting toppar file for ligand DI7 (100/252)\n",
      "toppar for ligand DI7 already exists. Skipping...\n",
      "Getting toppar file for ligand CSD (101/252)\n",
      "toppar for ligand CSD already exists. Skipping...\n",
      "Getting toppar file for ligand 9DK (102/252)\n",
      "toppar for ligand 9DK already exists. Skipping...\n",
      "Getting toppar file for ligand KNZ (103/252)\n",
      "toppar for ligand KNZ already exists. Skipping...\n",
      "Getting toppar file for ligand 73R (104/252)\n",
      "toppar for ligand 73R already exists. Skipping...\n",
      "Getting toppar file for ligand JRZ (105/252)\n",
      "toppar for ligand JRZ already exists. Skipping...\n",
      "Getting toppar file for ligand XAC (106/252)\n",
      "toppar for ligand XAC already exists. Skipping...\n",
      "Getting toppar file for ligand ON3 (107/252)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toppar for ligand ON3 already exists. Skipping...\n",
      "Getting toppar file for ligand A8T (108/252)\n",
      "toppar for ligand A8T already exists. Skipping...\n",
      "Getting toppar file for ligand JTZ (109/252)\n",
      "toppar for ligand JTZ already exists. Skipping...\n",
      "Getting toppar file for ligand ACE (110/252)\n",
      "toppar for ligand ACE already exists. Skipping...\n",
      "Getting toppar file for ligand ON9 (111/252)\n",
      "toppar for ligand ON9 already exists. Skipping...\n",
      "Getting toppar file for ligand ON7 (112/252)\n",
      "toppar for ligand ON7 already exists. Skipping...\n",
      "Getting toppar file for ligand 5FW (113/252)\n",
      "toppar for ligand 5FW already exists. Skipping...\n",
      "Getting toppar file for ligand 9EU (114/252)\n",
      "toppar for ligand 9EU already exists. Skipping...\n",
      "Getting toppar file for ligand 7LD (115/252)\n",
      "toppar for ligand 7LD already exists. Skipping...\n",
      "Getting toppar file for ligand DN5 (116/252)\n",
      "toppar for ligand DN5 already exists. Skipping...\n",
      "Getting toppar file for ligand SCN (117/252)\n",
      "toppar for ligand SCN already exists. Skipping...\n",
      "Getting toppar file for ligand L76 (118/252)\n",
      "toppar for ligand L76 already exists. Skipping...\n",
      "Getting toppar file for ligand BOG (119/252)\n",
      "toppar for ligand BOG already exists. Skipping...\n",
      "Getting toppar file for ligand P6G (120/252)\n",
      "toppar for ligand P6G already exists. Skipping...\n",
      "Getting toppar file for ligand 9DQ (121/252)\n",
      "toppar for ligand 9DQ already exists. Skipping...\n",
      "Getting toppar file for ligand A90 (122/252)\n",
      "toppar for ligand A90 already exists. Skipping...\n",
      "Getting toppar file for ligand EDO (123/252)\n",
      "toppar for ligand EDO already exists. Skipping...\n",
      "Getting toppar file for ligand A8X (124/252)\n",
      "toppar for ligand A8X already exists. Skipping...\n",
      "Getting toppar file for ligand MES (125/252)\n",
      "toppar for ligand MES already exists. Skipping...\n",
      "Getting toppar file for ligand PLM (126/252)\n",
      "toppar for ligand PLM already exists. Skipping...\n",
      "Getting toppar file for ligand 9XW (127/252)\n",
      "toppar for ligand 9XW already exists. Skipping...\n",
      "Getting toppar file for ligand GMJ (128/252)\n",
      "toppar for ligand GMJ already exists. Skipping...\n",
      "Getting toppar file for ligand ORN (129/252)\n",
      "toppar for ligand ORN already exists. Skipping...\n",
      "Getting toppar file for ligand EDT (130/252)\n",
      "toppar for ligand EDT already exists. Skipping...\n",
      "Getting toppar file for ligand J9P (131/252)\n",
      "toppar for ligand J9P already exists. Skipping...\n",
      "Getting toppar file for ligand CIT (132/252)\n",
      "toppar for ligand CIT already exists. Skipping...\n",
      "Getting toppar file for ligand CAU (133/252)\n",
      "toppar for ligand CAU already exists. Skipping...\n",
      "Getting toppar file for ligand 9ER (134/252)\n",
      "toppar for ligand 9ER already exists. Skipping...\n",
      "Getting toppar file for ligand ZLK (135/252)\n",
      "toppar for ligand ZLK already exists. Skipping...\n",
      "Getting toppar file for ligand H8M (136/252)\n",
      "toppar for ligand H8M already exists. Skipping...\n",
      "Getting toppar file for ligand 6DY (137/252)\n",
      "toppar for ligand 6DY already exists. Skipping...\n",
      "Getting toppar file for ligand A2G (138/252)\n",
      "toppar for ligand A2G already exists. Skipping...\n",
      "Getting toppar file for ligand PG6 (139/252)\n",
      "toppar for ligand PG6 already exists. Skipping...\n",
      "Getting toppar file for ligand XF5 (140/252)\n",
      "toppar for ligand XF5 already exists. Skipping...\n",
      "Getting toppar file for ligand 7Y9 (141/252)\n",
      "toppar for ligand 7Y9 already exists. Skipping...\n",
      "Getting toppar file for ligand FT4 (142/252)\n",
      "toppar for ligand FT4 already exists. Skipping...\n",
      "Getting toppar file for ligand JDC (143/252)\n",
      "toppar for ligand JDC already exists. Skipping...\n",
      "Getting toppar file for ligand SNP (144/252)\n",
      "toppar for ligand SNP already exists. Skipping...\n",
      "Getting toppar file for ligand P2E (145/252)\n",
      "toppar for ligand P2E already exists. Skipping...\n",
      "Getting toppar file for ligand PG4 (146/252)\n",
      "toppar for ligand PG4 already exists. Skipping...\n",
      "Getting toppar file for ligand TWT (147/252)\n",
      "toppar for ligand TWT already exists. Skipping...\n",
      "Getting toppar file for ligand NS2 (148/252)\n",
      "toppar for ligand NS2 already exists. Skipping...\n",
      "Getting toppar file for ligand NVH (149/252)\n",
      "toppar for ligand NVH already exists. Skipping...\n",
      "Getting toppar file for ligand NAG (150/252)\n",
      "toppar for ligand NAG already exists. Skipping...\n",
      "Getting toppar file for ligand PGW (151/252)\n",
      "toppar for ligand PGW already exists. Skipping...\n",
      "Getting toppar file for ligand ZOT (152/252)\n",
      "toppar for ligand ZOT already exists. Skipping...\n",
      "Getting toppar file for ligand KO5 (153/252)\n",
      "toppar for ligand KO5 already exists. Skipping...\n",
      "Getting toppar file for ligand DI8 (154/252)\n",
      "toppar for ligand DI8 already exists. Skipping...\n",
      "Getting toppar file for ligand ETQ (155/252)\n",
      "toppar for ligand ETQ already exists. Skipping...\n",
      "Getting toppar file for ligand PO4 (156/252)\n",
      "toppar for ligand PO4 already exists. Skipping...\n",
      "Getting toppar file for ligand OLA (157/252)\n",
      "toppar for ligand OLA already exists. Skipping...\n",
      "Getting toppar file for ligand OIC (158/252)\n",
      "toppar for ligand OIC already exists. Skipping...\n",
      "Getting toppar file for ligand QNB (159/252)\n",
      "toppar for ligand QNB already exists. Skipping...\n",
      "Getting toppar file for ligand SG8 (160/252)\n",
      "toppar for ligand SG8 already exists. Skipping...\n",
      "Getting toppar file for ligand PE5 (161/252)\n",
      "toppar for ligand PE5 already exists. Skipping...\n",
      "Getting toppar file for ligand 9JU (162/252)\n",
      "toppar for ligand 9JU already exists. Skipping...\n",
      "Getting toppar file for ligand BGC (163/252)\n",
      "toppar for ligand BGC already exists. Skipping...\n",
      "Getting toppar file for ligand G90 (164/252)\n",
      "toppar for ligand G90 already exists. Skipping...\n",
      "Getting toppar file for ligand EFD (165/252)\n",
      "toppar for ligand EFD already exists. Skipping...\n",
      "Getting toppar file for ligand 68H (166/252)\n",
      "toppar for ligand 68H already exists. Skipping...\n",
      "Getting toppar file for ligand PC1 (167/252)\n",
      "toppar for ligand PC1 already exists. Skipping...\n",
      "Getting toppar file for ligand MLI (168/252)\n",
      "toppar for ligand MLI already exists. Skipping...\n",
      "Getting toppar file for ligand TRS (169/252)\n",
      "toppar for ligand TRS already exists. Skipping...\n",
      "Getting toppar file for ligand AQD (170/252)\n",
      "toppar for ligand AQD already exists. Skipping...\n",
      "Getting toppar file for ligand 8ES (171/252)\n",
      "toppar for ligand 8ES already exists. Skipping...\n",
      "Getting toppar file for ligand ML5 (172/252)\n",
      "toppar for ligand ML5 already exists. Skipping...\n",
      "Getting toppar file for ligand 3C0 (173/252)\n",
      "toppar for ligand 3C0 already exists. Skipping...\n",
      "Getting toppar file for ligand P32 (174/252)\n",
      "toppar for ligand P32 already exists. Skipping...\n",
      "Getting toppar file for ligand 9DZ (175/252)\n",
      "toppar for ligand 9DZ already exists. Skipping...\n",
      "Getting toppar file for ligand PGO (176/252)\n",
      "toppar for ligand PGO already exists. Skipping...\n",
      "Getting toppar file for ligand JEV (177/252)\n",
      "toppar for ligand JEV already exists. Skipping...\n",
      "Getting toppar file for ligand JLW (178/252)\n",
      "toppar for ligand JLW already exists. Skipping...\n",
      "Getting toppar file for ligand 12P (179/252)\n",
      "toppar for ligand 12P already exists. Skipping...\n",
      "Getting toppar file for ligand 1PE (180/252)\n",
      "toppar for ligand 1PE already exists. Skipping...\n",
      "Getting toppar file for ligand TLA (181/252)\n",
      "toppar for ligand TLA already exists. Skipping...\n",
      "Getting toppar file for ligand SNT (182/252)\n",
      "toppar for ligand SNT already exists. Skipping...\n",
      "Getting toppar file for ligand EN6 (183/252)\n",
      "toppar for ligand EN6 already exists. Skipping...\n",
      "Getting toppar file for ligand CVD (184/252)\n",
      "toppar for ligand CVD already exists. Skipping...\n",
      "Getting toppar file for ligand ML2 (185/252)\n",
      "toppar for ligand ML2 already exists. Skipping...\n",
      "Getting toppar file for ligand ZN (186/252)\n",
      "toppar for ligand ZN already exists. Skipping...\n",
      "Getting toppar file for ligand 8VS (187/252)\n",
      "toppar for ligand 8VS already exists. Skipping...\n",
      "Getting toppar file for ligand NH4 (188/252)\n",
      "toppar for ligand NH4 already exists. Skipping...\n",
      "Getting toppar file for ligand A6L (189/252)\n",
      "toppar for ligand A6L already exists. Skipping...\n",
      "Getting toppar file for ligand 9GF (190/252)\n",
      "toppar for ligand 9GF already exists. Skipping...\n",
      "Getting toppar file for ligand BMA (191/252)\n",
      "toppar for ligand BMA already exists. Skipping...\n",
      "Getting toppar file for ligand 89F (192/252)\n",
      "toppar for ligand 89F already exists. Skipping...\n",
      "Getting toppar file for ligand MHA (193/252)\n",
      "toppar for ligand MHA already exists. Skipping...\n",
      "Getting toppar file for ligand SUV (194/252)\n",
      "toppar for ligand SUV already exists. Skipping...\n",
      "Getting toppar file for ligand OLB (195/252)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toppar for ligand OLB already exists. Skipping...\n",
      "Getting toppar file for ligand DGA (196/252)\n",
      "toppar for ligand DGA already exists. Skipping...\n",
      "Getting toppar file for ligand FLC (197/252)\n",
      "toppar for ligand FLC already exists. Skipping...\n",
      "Getting toppar file for ligand ACY (198/252)\n",
      "toppar for ligand ACY already exists. Skipping...\n",
      "Getting toppar file for ligand XTK (199/252)\n",
      "toppar for ligand XTK already exists. Skipping...\n",
      "Getting toppar file for ligand CL (200/252)\n",
      "toppar for ligand CL already exists. Skipping...\n",
      "Getting toppar file for ligand 6DZ (201/252)\n",
      "toppar for ligand 6DZ already exists. Skipping...\n",
      "Getting toppar file for ligand CFF (202/252)\n",
      "toppar for ligand CFF already exists. Skipping...\n",
      "Getting toppar file for ligand NT5 (203/252)\n",
      "toppar for ligand NT5 already exists. Skipping...\n",
      "Getting toppar file for ligand IOD (204/252)\n",
      "toppar for ligand IOD already exists. Skipping...\n",
      "Getting toppar file for ligand YCM (205/252)\n",
      "toppar for ligand YCM already exists. Skipping...\n",
      "Getting toppar file for ligand 82F (206/252)\n",
      "toppar for ligand 82F already exists. Skipping...\n",
      "Getting toppar file for ligand 97V (207/252)\n",
      "toppar for ligand 97V already exists. Skipping...\n",
      "Getting toppar file for ligand AWY (208/252)\n",
      "toppar for ligand AWY already exists. Skipping...\n",
      "Getting toppar file for ligand 1Q5 (209/252)\n",
      "toppar for ligand 1Q5 already exists. Skipping...\n",
      "Getting toppar file for ligand SIN (210/252)\n",
      "toppar for ligand SIN already exists. Skipping...\n",
      "Getting toppar file for ligand ZAL (211/252)\n",
      "toppar for ligand ZAL already exists. Skipping...\n",
      "Getting toppar file for ligand NEC (212/252)\n",
      "toppar for ligand NEC already exists. Skipping...\n",
      "Getting toppar file for ligand WHJ (213/252)\n",
      "toppar for ligand WHJ already exists. Skipping...\n",
      "Getting toppar file for ligand DO5 (214/252)\n",
      "toppar for ligand DO5 already exists. Skipping...\n",
      "Getting toppar file for ligand 5EH (215/252)\n",
      "toppar for ligand 5EH already exists. Skipping...\n",
      "Getting toppar file for ligand KNW (216/252)\n",
      "toppar for ligand KNW already exists. Skipping...\n",
      "Getting toppar file for ligand DL2 (217/252)\n",
      "toppar for ligand DL2 already exists. Skipping...\n",
      "Getting toppar file for ligand A4X (218/252)\n",
      "toppar for ligand A4X already exists. Skipping...\n",
      "Getting toppar file for ligand BU1 (219/252)\n",
      "toppar for ligand BU1 already exists. Skipping...\n",
      "Getting toppar file for ligand 7OS (220/252)\n",
      "toppar for ligand 7OS already exists. Skipping...\n",
      "Getting toppar file for ligand DNK (221/252)\n",
      "toppar for ligand DNK already exists. Skipping...\n",
      "Getting toppar file for ligand 9AF (222/252)\n",
      "toppar for ligand 9AF already exists. Skipping...\n",
      "Getting toppar file for ligand GAW (223/252)\n",
      "toppar for ligand GAW already exists. Skipping...\n",
      "Getting toppar file for ligand 8TZ (224/252)\n",
      "toppar for ligand 8TZ already exists. Skipping...\n",
      "Getting toppar file for ligand NVN (225/252)\n",
      "toppar for ligand NVN already exists. Skipping...\n",
      "Getting toppar file for ligand DOK (226/252)\n",
      "toppar for ligand DOK already exists. Skipping...\n",
      "Getting toppar file for ligand NGI (227/252)\n",
      "toppar for ligand NGI already exists. Skipping...\n",
      "Getting toppar file for ligand TEP (228/252)\n",
      "toppar for ligand TEP already exists. Skipping...\n",
      "Getting toppar file for ligand 2CV (229/252)\n",
      "toppar for ligand 2CV already exists. Skipping...\n",
      "Getting toppar file for ligand ACM (230/252)\n",
      "toppar for ligand ACM already exists. Skipping...\n",
      "Getting toppar file for ligand F7N (231/252)\n",
      "toppar for ligand F7N already exists. Skipping...\n",
      "Getting toppar file for ligand 5MV (232/252)\n",
      "toppar for ligand 5MV already exists. Skipping...\n",
      "Getting toppar file for ligand RET (233/252)\n",
      "toppar for ligand RET already exists. Skipping...\n",
      "Getting toppar file for ligand CLR (234/252)\n",
      "toppar for ligand CLR already exists. Skipping...\n",
      "Getting toppar file for ligand 9P2 (235/252)\n",
      "toppar for ligand 9P2 already exists. Skipping...\n",
      "Getting toppar file for ligand POV (236/252)\n",
      "toppar for ligand POV already exists. Skipping...\n",
      "Getting toppar file for ligand PGE (237/252)\n",
      "toppar for ligand PGE already exists. Skipping...\n",
      "Getting toppar file for ligand DGV (238/252)\n",
      "toppar for ligand DGV already exists. Skipping...\n",
      "Getting toppar file for ligand 9AO (239/252)\n",
      "toppar for ligand 9AO already exists. Skipping...\n",
      "Getting toppar file for ligand SO4 (240/252)\n",
      "toppar for ligand SO4 already exists. Skipping...\n",
      "Getting toppar file for ligand VT5 (241/252)\n",
      "toppar for ligand VT5 already exists. Skipping...\n",
      "Getting toppar file for ligand 9XT (242/252)\n",
      "toppar for ligand 9XT already exists. Skipping...\n",
      "Getting toppar file for ligand H8G (243/252)\n",
      "toppar for ligand H8G already exists. Skipping...\n",
      "Getting toppar file for ligand BF0 (244/252)\n",
      "toppar for ligand BF0 already exists. Skipping...\n",
      "Getting toppar file for ligand NLE (245/252)\n",
      "toppar for ligand NLE already exists. Skipping...\n",
      "Getting toppar file for ligand OLM (246/252)\n",
      "toppar for ligand OLM already exists. Skipping...\n",
      "Getting toppar file for ligand NV8 (247/252)\n",
      "toppar for ligand NV8 already exists. Skipping...\n",
      "Getting toppar file for ligand ACT (248/252)\n",
      "toppar for ligand ACT already exists. Skipping...\n",
      "Getting toppar file for ligand DGW (249/252)\n",
      "toppar for ligand DGW already exists. Skipping...\n",
      "Getting toppar file for ligand UNL (250/252)\n",
      "toppar for ligand UNL already exists. Skipping...\n",
      "Getting toppar file for ligand MK6 (251/252)\n",
      "toppar for ligand MK6 already exists. Skipping...\n",
      "Getting toppar file for ligand NO3 (252/252)\n",
      "toppar for ligand NO3 already exists. Skipping...\n"
     ]
    }
   ],
   "source": [
    "#################################################\n",
    "## Part 1: Download data and prepare dictionaries\n",
    "#################################################\n",
    "\n",
    "if not bool(pdb_set):\n",
    "    #Get not yet simulated PDB codes from GPCRdb\n",
    "    pdb_set = get_GPCRdb_nonsimulated(gpcrdb_dict)\n",
    "\n",
    "# Download and store structures from GPCRdb\n",
    "pdb_set = download_GPCRdb_structures(pdb_set, basepath)\n",
    "\n",
    "#Create or moidfy the ligands dictionary\n",
    "(ligandsdict, ligandsset) = ligand_dictionary(pdb_set, ligandsdict_path)\n",
    "\n",
    "# Extract ligand structures from system\n",
    "extract_ligands(ligandsdict, basepath)\n",
    "\n",
    "# Get topology-parameter files for ligandsf\n",
    "get_lig_toppar(ligandsset, basepath, username, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "start building model for receptor 4EJ4 (1/1)\n",
      "Build model for 4EJ4 already exists. Skipping...\n",
      "Structure 4EJ4 already has a watered version. Skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-22 16:20:05,336 - moleculekit.molecule - INFO - Removed 0 atoms. 2493 atoms remaining in the molecule.\n",
      "2020-10-22 16:20:05,354 - moleculekit.molecule - INFO - Removed 0 atoms. 2493 atoms remaining in the molecule.\n",
      "2020-10-22 16:20:05,492 - moleculekit.molecule - INFO - Removed 0 atoms. 2493 atoms remaining in the molecule.\n",
      "2020-10-22 16:20:05,600 - moleculekit.molecule - INFO - Removed 0 atoms. 2493 atoms remaining in the molecule.\n",
      "2020-10-22 16:20:07,602 - moleculekit.molecule - INFO - Removed 0 atoms. 2137 atoms remaining in the molecule.\n",
      "2020-10-22 16:20:07,693 - moleculekit.molecule - INFO - Removed 0 atoms. 2137 atoms remaining in the molecule.\n",
      "2020-10-22 16:20:07,821 - moleculekit.tools.autosegment - INFO - Created segment P0 between resid 41 and 244.\n",
      "2020-10-22 16:20:07,822 - moleculekit.tools.autosegment - INFO - Created segment P1 between resid 251 and 327.\n",
      "2020-10-22 16:20:08,066 - moleculekit.tools.sequencestructuralalignment - INFO - No segment was specified by the user for `mol`. Alignment will be done on all protein segments.\n",
      "2020-10-22 16:20:08,088 - moleculekit.tools.sequencestructuralalignment - INFO - No segment was specified by the user for `ref` and multiple segments (['P0', 'P1']) were detected. Alignment will be done on all protein segments.\n",
      "2020-10-22 16:20:08,352 - moleculekit.tools.sequencestructuralalignment - INFO - Alignment #0 was done on 204 residues: mol segid P0 resid 41-244\n",
      "/home/david/miniconda3/lib/python3.6/site-packages/moleculekit/align.py:16: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (array(float32, 2d, A), array(float32, 2d, A))\n",
      "  covariance = np.dot(P.T, Q)\n",
      "/home/david/miniconda3/lib/python3.6/site-packages/moleculekit/align.py:54: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (array(float32, 2d, C), array(float32, 2d, A))\n",
      "  all1 = np.dot(all1, rot.T)\n",
      "2020-10-22 16:20:12,282 - propka - INFO - No pdbfile provided\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Molecule chain report ----\n",
      "Chain L:\n",
      "    First residue: EJ4:1:\n",
      "    Final residue: EJ4:1:\n",
      "Chain P:\n",
      "    First residue: GLY:36:\n",
      "    Final residue: GLN:340:\n",
      "Chain X:\n",
      "    First residue: TIP3:1:\n",
      "    Final residue: TIP3:87:\n",
      "---- End of chain report ----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-22 16:20:13,880 - moleculekit.tools.preparation - WARNING - The following residue has not been optimized: EJ4\n",
      "2020-10-22 16:20:13,881 - moleculekit.tools.preparation - WARNING - The following residue has not been optimized: TIP\n",
      "2020-10-22 16:20:20,561 - moleculekit.tools.preparationdata - INFO - The following residues are in a non-standard state: CYS   121  P (CYX), HIS   152  P (HIE), CYS   198  P (CYX), HIS   278  P (HID), HIS   301  P (HID)\n",
      "2020-10-22 16:20:20,841 - numexpr.utils - INFO - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2020-10-22 16:20:20,841 - numexpr.utils - INFO - NumExpr defaulting to 8 threads.\n",
      "2020-10-22 16:20:20,884 - moleculekit.tools.preparationdata - WARNING - Predictions for 15 residues may be incorrect because they are exposed to the membrane (-17.2<z<17.20 and buried<75.0%).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding membrane...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-22 16:20:21,850 - htmd.builder.builder - INFO - Replicating Membrane 3x3\n",
      "Replicating Membrane:  44%|     | 4/9 [00:01<00:02,  2.45it/s]\n",
      "2020-10-22 16:21:32,039 - moleculekit.molecule - INFO - Removed 2568 atoms. 39652 atoms remaining in the molecule.\n",
      "2020-10-22 16:21:32,714 - moleculekit.molecule - INFO - Removed 92 residues from appended Molecule due to collisions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solvating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-22 16:21:33,436 - htmd.builder.solvate - INFO - Using water pdb file at: /home/david/miniconda3/lib/python3.6/site-packages/htmd/share/solvate/wat.pdb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wataerbox Max and min:  [49.05757  46.874603 28.142359] [-45.39843  -45.647396 -27.652641]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-22 16:21:34,232 - htmd.builder.solvate - INFO - Replicating 8 water segments, 2 by 2 by 2\n",
      "Solvating: 100%|| 8/8 [00:08<00:00,  1.07s/it]\n",
      "2020-10-22 16:21:44,373 - htmd.builder.solvate - INFO - 10161 water molecules were added to the system.\n",
      "2020-10-22 16:21:49,603 - moleculekit.molecule - INFO - Removed 1104 atoms. 67056 atoms remaining in the molecule.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'4EJ4'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-b3136ab6da71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;31m# Make list of Ligand stringfiles (Parameters and topology)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mstreams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mligcode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mligandsdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpdbcode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m             \u001b[0mstreams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasepath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'Ligands/'\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mligcode\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0;34m'/toppar.str'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '4EJ4'"
     ]
    }
   ],
   "source": [
    "###########################\n",
    "## Part 2: Build the models \n",
    "###########################\n",
    "  \n",
    "# Iterate by GPCRdb structures to simulate\n",
    "pdbs_number = len(pdb_set)\n",
    "i = 0\n",
    "pdb_set = {'4EJ4'}\n",
    "for pdbcode in pdb_set:\n",
    "    #try:\n",
    "        #Starting simulation\n",
    "        start_time = time.time()        \n",
    "        i += 1\n",
    "        if apo:\n",
    "            sysname = pdbcode+'_apo'            \n",
    "        else:\n",
    "            sysname = pdbcode\n",
    "        print('\\nstart building model for receptor %s (%d/%d)' % (sysname, i, pdbs_number))\n",
    "        # Skip if there is already a model build for this\n",
    "        if os.path.exists(resultspath+'build/'+sysname+'/structure.pdb'):\n",
    "            print('Build model for '+sysname+' already exists. Skipping...')\n",
    "            #continue\n",
    "\n",
    "        # Add internal waters to GPCRdb structures, using HomolWat\n",
    "        simdir = basepath + 'data_sim/'+pdbcode+'/'\n",
    "        sod2x50 = internal_waters(simdir, pdbcode, gpcrdb_dict, apo)\n",
    "\n",
    "        # Load watered-GPCRdb and OPM versions of GPCR with pdbcode\n",
    "        if apo:\n",
    "            gpcrdb_mol = Molecule(glob(simdir + '*_apoHW.pdb'))\n",
    "        else:\n",
    "            gpcrdb_mol = Molecule(glob(simdir + '*_HW.pdb'))\n",
    "        thickness,opm_mol = get_opm(pdbcode)\n",
    "        \n",
    "        # Remove unnecessary ligand molecules: mostly crystalization detergents, quelants, buffers,\n",
    "        # or post-traductional glicosilations\n",
    "        gpcrdb_mol.remove('resname '+' '.join(detergent_blacklist))\n",
    "        gpcrdb_mol.remove('resname '+' '.join(glucids_blacklist))\n",
    "        \n",
    "        # If the pipeline is running in 'apoform mode', remove any non-protein, non-ion, non-water thing on the system\n",
    "        \n",
    "        if apo:\n",
    "            gpcrdb_mol.remove('not (protein or water or ion)')\n",
    "        \n",
    "        # Ismael's function to add labels (segid) for 'ligand' and 'protein' parts of the system\n",
    "        #And many things more I do not really understand\n",
    "        gpcrdb_mol_fixed,receptor_segids_gpcrdb = fix_and_prepare_input(gpcrdb_mol)\n",
    "        opm_mol_fixed,receptor_segids_opm = fix_and_prepare_input(opm_mol)\n",
    "\n",
    "        # write file to remember to which chain in the original structure belongs each segment\n",
    "        segchain_json(gpcrdb_mol_fixed, pdbcode, basepath, receptor_segids_gpcrdb)\n",
    "        \n",
    "        # Paths and previous variables\n",
    "        modelname = sysname # Example name\n",
    "        opm_modelname = pdbcode + '_opm'\n",
    "        \n",
    "        # Assigning new chain to protein segment of the protein to align (opm and gpcrdb)\n",
    "        opm_receptorsel = 'segid '+' '.join(receptor_segids_opm)\n",
    "        opm_mol_fixed.set('chain',new_pdb_chain,sel=opm_receptorsel)\n",
    "        gpcrdb_receptorsel = 'segid '+' '.join(receptor_segids_gpcrdb)\n",
    "        gpcrdb_mol_fixed.set('chain',new_pdb_chain,sel=gpcrdb_receptorsel)\n",
    "\n",
    "        # Align structrues using sequences, and take first one\n",
    "        alignment_results = sequenceStructureAlignment(gpcrdb_mol_fixed, opm_mol_fixed, maxalignments = 1)\n",
    "        mol_aligned = alignment_results[0] \n",
    "\n",
    "        #Center to receptor XY\n",
    "        center = np.mean(mol_aligned.get('coords',sel=gpcrdb_receptorsel),axis=0)\n",
    "        mol_aligned.moveBy([-center[0],-center[1],0])\n",
    "\n",
    "        # Prepare protein: asign titration states, flipping side chains of HIS, ASN and GLN; rotate some sidechains, optimize waters, etc.\n",
    "        # Most of this is done with a HTMD function called proteinPrepare()\n",
    "        prepared_mol = prepare_system(mol_aligned, pdbcode, thickness, sod2x50)\n",
    "        \n",
    "        #Add membrane\n",
    "        print('Adding membrane...')\n",
    "        membranemol = Molecule(membranepdb)\n",
    "        mol_membraned, membrane_resnames, membrane_segids, xreps, yreps = add_membrane(prepared_mol, membranemol,receptor_segids_gpcrdb,membrane_distance)\n",
    "\n",
    "        # Needed later for equilibration\n",
    "        with open(simdir+\"const_sel.txt\",'w') as out: \n",
    "            const_sel = 'segid '+' '.join(receptor_segids_gpcrdb)+' and name C CA N O or not (segid ' + \\\n",
    "              ' '.join(receptor_segids_gpcrdb)+' or resname '+' '.join(membrane_resnames) + \\\n",
    "              ' or water or ions ) and noh or segid ION WAT and noh'\n",
    "            out.write(const_sel)\n",
    "            \n",
    "        #Solvate\n",
    "        print('Solvating...')\n",
    "        mol_solvated = solvate_pdbmol(mol_membraned,membrane_segids,water_thickness,water_margin,buffer=buffer,coldist=coldist,prefix='WT')\n",
    "\n",
    "        # Make list of Ligand stringfiles (Parameters and topology)\n",
    "        streams = []\n",
    "        for ligcode in ligandsdict[pdbcode]:\n",
    "            streams.append(basepath + 'Ligands/'+ ligcode+ '/toppar.str')\n",
    "\n",
    "        # Assignign terminology for cap atoms of protein chain, depending if it is the receptor protein or not\n",
    "        caps_receptor = ['first ACE', 'last CT3']\n",
    "        caps_not_receptor_protein = ['first NTER', 'last CTER']\n",
    "        caps = { segid : caps_receptor for segid in receptor_segids_gpcrdb }\n",
    "\n",
    "        #Pre-build model\n",
    "        print('Pre-build...')\n",
    "        prebuildmol = charmm.build(mol_solvated, \n",
    "                                   topo=topos, \n",
    "                                   param=params,\n",
    "                                   stream=streams,\n",
    "                                   caps=caps,\n",
    "                                   outdir=resultspath+'/pre-build/'+modelname,\n",
    "                                   ionize=False)\n",
    "\n",
    "        # Save prebuild model topologies in files, and  store prebuild model in molecule object\n",
    "        prebuild_psffile = prebuildmol.topoloc\n",
    "        prebuild_pdbfile = os.path.splitext(prebuildmol.topoloc)[0]+'.pdb'\n",
    "        prebuildmol = Molecule(prebuild_pdbfile)\n",
    "        _recoverProtonations(prebuildmol)\n",
    "\n",
    "        # Checking of aromatic insertions (takes quite a lot fo time)\n",
    "        print('Checking aromatic insertions...')\n",
    "        mol_removed,removed_indexes = remove_aromatic_insertions(mol_solvated,receptor_segids_gpcrdb, outpdb=resultspath+'/pre-build/'+modelname+'/aromatic_check.pdb')\n",
    "\n",
    "        # Checking of water/lipid ratio\n",
    "        lipid_num = len(set(mol_removed.get('resid',sel='segid '+membrane_lipid_segid)))\n",
    "        solv_num = len(mol_removed.get('index',sel='resname TIP3 and name OH2'))\n",
    "        if float(solv_num) / lipid_num < 35:\n",
    "            raise ValueError('Water/lipid ratio lower than 35.')\n",
    "\n",
    "        #Renumber residues\n",
    "        print('Renumbering...')\n",
    "        mol_renumbered = renumber_resid_vmd(mol_removed,'segid '+' '.join(membrane_segids),by=2)\n",
    "        \n",
    "        # Ionizing system\n",
    "        print('Ionizing...')\n",
    "        molbuilt = charmm.build(mol_removed,\n",
    "                                topo=topos,\n",
    "                                stream=streams,                        \n",
    "                                param=params,\n",
    "                                outdir=resultspath+'/ionize/'+modelname,\n",
    "                                saltconc=0.15,\n",
    "                                caps=caps)\n",
    "        build_psffile = molbuilt.topoloc\n",
    "        build_pdbfile = os.path.splitext(molbuilt.topoloc)[0]+'.pdb'\n",
    "        molbuilt = Molecule(build_pdbfile)\n",
    "        _recoverProtonations(molbuilt)\n",
    "\n",
    "        #Building system\n",
    "        print('Building...')\n",
    "        molbuilt = renumber_resid_vmd(molbuilt,'segid \"WT.*\" or segid I',by=2)\n",
    "        molbuilt = charmm.build(molbuilt, \n",
    "                                topo=topos, \n",
    "                                stream=streams,                        \n",
    "                                param=params,\n",
    "                                outdir=resultspath+'/build/'+modelname,\n",
    "                                caps=caps,ionize=False)\n",
    "\n",
    "        print('End of %s after %s seconds\\n' % (modelname, time.time() - start_time))\n",
    "        \n",
    "        #Creating link for build structure in separate folder\n",
    "        os.makedirs(resultspath+'drive_structures/', exist_ok = True)\n",
    "        if apo:\n",
    "            os.symlink(resultspath+'build/'+pdbcode+'_apo/structure.pdb', resultspath+'drive_structures/'+pdbcode+'_apo.pdb')\n",
    "        else:\n",
    "            os.symlink(resultspath+'build/'+pdbcode+'/structure.pdb',resultspath+'drive_structures/'+pdbcode+'_complex.pdb')\n",
    "        \n",
    "    #except Exception as e:\n",
    "     #   print(\"model \"+pdbcode+\" could not be build because \",e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-25 13:54:04,659 - htmd.builder.builder - WARNING - Found cis peptide bond in 1 frames: [0] in the omega diheral \"Angle of (SER 204 CA P0 P) (SER 204 C P0 P) (PRO 205 N P0 P) (PRO 205 CA P0 P) \" with indexes [2602, 2609, 2611, 2615]\n",
      "2020-09-25 13:54:04,660 - htmd.builder.builder - WARNING - Found cis peptide bond in 1 frames: [0] in the omega diheral \"Angle of (THR 335 CA P0 P) (THR 335 C P0 P) (PRO 336 N P0 P) (PRO 336 CA P0 P) \" with indexes [4790, 4800, 4802, 4806]\n",
      "2020-09-25 13:54:05,069 - htmd.protocols.equilibration_v2 - WARNING - Lipids detected in input structure. We highly recommend setting useconstantratio=True for membrane simulations.\n",
      "2020-09-25 13:54:05,069 - htmd.protocols.equilibration_v2 - INFO - Using user-provided restraints and ignoring constraints and fb_potential\n",
      "2020-09-25 13:54:08,334 - jobqueues.slurmqueue - INFO - Queueing /gpcr/users/daranda/doctorat/GPCR_simulations/simulation_output//equil/4EJ4/\n",
      "2020-09-25 13:54:26,980 - htmd.protocols.equilibration_v2 - WARNING - Lipids detected in input structure. We highly recommend setting useconstantratio=True for membrane simulations.\n",
      "2020-09-25 13:54:26,980 - htmd.protocols.equilibration_v2 - INFO - Using user-provided restraints and ignoring constraints and fb_potential\n",
      "2020-09-25 13:54:33,691 - jobqueues.slurmqueue - INFO - Queueing /gpcr/users/daranda/doctorat/GPCR_simulations/simulation_output//equil/5WIU/\n",
      "2020-09-25 13:54:49,100 - htmd.protocols.equilibration_v2 - WARNING - Lipids detected in input structure. We highly recommend setting useconstantratio=True for membrane simulations.\n",
      "2020-09-25 13:54:49,100 - htmd.protocols.equilibration_v2 - INFO - Using user-provided restraints and ignoring constraints and fb_potential\n",
      "2020-09-25 13:54:52,481 - jobqueues.slurmqueue - INFO - Queueing /gpcr/users/daranda/doctorat/GPCR_simulations/simulation_output//equil/6MEO/\n",
      "2020-09-25 13:55:12,620 - htmd.protocols.equilibration_v2 - WARNING - Lipids detected in input structure. We highly recommend setting useconstantratio=True for membrane simulations.\n",
      "2020-09-25 13:55:12,620 - htmd.protocols.equilibration_v2 - INFO - Using user-provided restraints and ignoring constraints and fb_potential\n",
      "2020-09-25 13:55:18,144 - jobqueues.slurmqueue - INFO - Queueing /gpcr/users/daranda/doctorat/GPCR_simulations/simulation_output//equil/5TE5/\n",
      "2020-09-25 13:55:35,971 - htmd.protocols.equilibration_v2 - WARNING - Lipids detected in input structure. We highly recommend setting useconstantratio=True for membrane simulations.\n",
      "2020-09-25 13:55:35,972 - htmd.protocols.equilibration_v2 - INFO - Using user-provided restraints and ignoring constraints and fb_potential\n",
      "2020-09-25 13:55:42,085 - jobqueues.slurmqueue - INFO - Queueing /gpcr/users/daranda/doctorat/GPCR_simulations/simulation_output//equil/4A4M/\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "## Part 3: Equillibration\n",
    "#########################\n",
    "\n",
    "def define_equilibration(const_sel):\n",
    "    simtime = 40\n",
    "    restr = AtomRestraint(const_sel, 2, [(0,\"0\"),(1,\"%dns\" % int(simtime*0.5)),(0,\"%dns\" % int(simtime*0.75))], \"xyz\")\n",
    "    md = Equilibration()\n",
    "    md.runtime = simtime\n",
    "    md.timeunits = 'ns'\n",
    "    md.temperature = 310\n",
    "    md.nvtsteps = 0\n",
    "    md.acemd.barostatconstratio = 'on'\n",
    "    md.acemd.minimize = 5000\n",
    "    #md.acemd.minimize = str(5000)\n",
    "    md.acemd.restart = 'off'\n",
    "    md.acemd.timestep = 2\n",
    "    md.restraints = restr\n",
    "    md._version = 3\n",
    "    return md\n",
    "\n",
    "acemd_path = \"/opt/acellera/miniconda3/bin/acemd3\"\n",
    "acemd_license = \"SG_LICENSE_FILE=28000@tolkien.prib.upf.edu\"\n",
    "\n",
    "#for pdbcode in pdb_set:\n",
    "for pdbcode in pdb_set:\n",
    "    modelname = pdbcode\n",
    "    pdbfile = '%s/build/%s/structure.pdb' % (resultspath, pdbcode)\n",
    "    if modelname in sqs:\n",
    "        print('Skipping '+modelname+': it has already been submitted.')\n",
    "        #continue\n",
    "\n",
    "    # Preparing scripts to run equillibration\n",
    "    equildir = resultspath+'/equil/'+modelname+'/'\n",
    "    if not os.path.exists(equildir):\n",
    "        os.makedirs(equildir)\n",
    "\n",
    "    # Taking vmd selection line\n",
    "    with open(basepath+'data_sim/'+pdbcode+'/const_sel.txt', 'r') as outfile:\n",
    "        const_sel = outfile.readlines()[0]\n",
    "    \n",
    "    md = define_equilibration(const_sel)\n",
    "    md.write(resultspath+'build/'+modelname,equildir)\n",
    "\n",
    "    #Substitute run.sh generated by HTMD by a different one, adapted to the specified path of ACEMD\n",
    "    with open(equildir + 'run.sh', 'w') as f:\n",
    "        f.write('#!/bin/bash\\n%s >log.txt 2>&1' % acemd_path)\n",
    "        \n",
    "    sq = SlurmQueue()\n",
    "    sq.envvars = acemd_license\n",
    "    sq.jobname = 'eql_'+pdbcode\n",
    "    sq.datadir = None\n",
    "    sq.partition = 'gpcr_gpu'\n",
    "    sq.ngpu = 1\n",
    "    sq.ncpu = 1\n",
    "    \n",
    "    #sq.exclude = 'excluded_node'\n",
    "    \n",
    "    # directory to copy input and store output of equilibration (initial working directory for run_equil.sh).\n",
    "    # equildir directory has to be in the computation server, or in a shared folder for the computation folder.\n",
    "    equildir = resultspath + '/equil/'+modelname+'/'\n",
    "    # copy equil folder in build to equildir\n",
    "    #copytree(resultspath+'/build/'+modelname+'/equil',equildir)\n",
    "    sq.submit(equildir)\n",
    "    sqs[modelname] = sq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset tracking for all\n",
    "sqs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING!!!: run me to KILL simulations that are still running\n",
    "for modelname in sqs:\n",
    "    sqs[modelname].stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Equilibration commands and parameters\n",
    "\n",
    "#run me to check how many simulations are still running\n",
    "sum([sqs[modelname].inprogress() for modelname in sqs])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submitting replicate 1 of 5WIU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-27 13:57:27,819 - htmd.protocols.production_v6 - WARNING - Lipids detected in input structure. We highly recommend setting useconstantratio=True for membrane simulations.\n",
      "2020-10-27 13:57:45,441 - jobqueues.slurmqueue - INFO - Queueing /gpcr/users/daranda/doctorat/GPCR_simulations/simulation_output/production/5WIU/rep_1/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submitting replicate 2 of 5WIU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-27 13:58:03,809 - htmd.protocols.production_v6 - WARNING - Lipids detected in input structure. We highly recommend setting useconstantratio=True for membrane simulations.\n",
      "2020-10-27 13:58:07,590 - jobqueues.slurmqueue - INFO - Queueing /gpcr/users/daranda/doctorat/GPCR_simulations/simulation_output/production/5WIU/rep_2/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submitting replicate 3 of 5WIU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-27 13:58:25,673 - htmd.protocols.production_v6 - WARNING - Lipids detected in input structure. We highly recommend setting useconstantratio=True for membrane simulations.\n",
      "2020-10-27 13:58:29,896 - jobqueues.slurmqueue - INFO - Queueing /gpcr/users/daranda/doctorat/GPCR_simulations/simulation_output/production/5WIU/rep_3/\n"
     ]
    }
   ],
   "source": [
    "#####################\n",
    "## Part 4: Production\n",
    "#####################\n",
    "\n",
    "def define_production(timestep,trajperiod):\n",
    "    md = Production()\n",
    "    md.runtime = 5\n",
    "    md.timeunits = 'ns'\n",
    "    md.temperature = 310\n",
    "    md.acemd.restart = 'off'        \n",
    "    md.acemd.timestep = timestep\n",
    "    md.acemd.barostatconstratio = 'on'\n",
    "    md.acemd.trajectoryperiod = trajperiod\n",
    "    md.acemd.restart = 'off'\n",
    "    md.acemd.bincoordinates = 'output.coor'\n",
    "    md.acemd.extendedsystem  = 'output.xsc'\n",
    "    md.acemd.binvelocities = 'output.vel'\n",
    "    return md\n",
    "\n",
    "# Production protocol\n",
    "md = define_production(timestep, trajperiod)\n",
    "\n",
    "# If some model should be skipped, put its name here\n",
    "modelname_skip = {}\n",
    "\n",
    "# For each PDB \n",
    "for pdbcode in ['5WIU']:\n",
    "#for pdbcode in pdb_set:\n",
    "    \n",
    "    # must match with equildir in equilibration launcher code and contain input and output of equilibration.\n",
    "    modelname = pdbcode\n",
    "    equildir = '%s/equil/%s/' % (resultspath, modelname)\n",
    "    for rep in range(1,repnum+1):\n",
    "        print('submitting replicate %d of %s' % (rep, pdbcode))\n",
    "        # If simulation for this PDB has already been run\n",
    "        if os.path.exists(resultspath+'production/rep_'+str(rep)+'/output.xtc'):\n",
    "            print(\"replicate %d of structure %s already has been simulated\" %(rep, pdbcode))\n",
    "            continue\n",
    "        # If this pdbcode is mean to be excluded for some reason\n",
    "        if modelname in modelname_skip:\n",
    "            print('Skipping '+modelname+'_'+str(rep)+'.')\n",
    "            continue\n",
    "\n",
    "        # directory copy output of equilibration to production input (initial working directory for run_prod.sh).\n",
    "        proddir='%sproduction/%s/rep_%d/' % (resultspath, modelname, rep)\n",
    "        md.write(equildir,proddir)\n",
    "\n",
    "        sq = SlurmQueue()\n",
    "        sq.envvars = acemd_license\n",
    "        sq.jobname = modelname+'_pr'+str(rep)\n",
    "        sq.datadir = None\n",
    "        sq.partition = 'gpcr_gpu'\n",
    "        sq.ngpu = 1\n",
    "        sq.ncpu = 2\n",
    "        \n",
    "        #Substitute run.sh generated by HTMD by a different one, adapted to the specified path of ACEMD\n",
    "        with open(proddir + 'run.sh', 'w') as f:\n",
    "            f.write('#!/bin/bash\\n%s >log.txt 2>&1' % acemd_path)\n",
    "        \n",
    "        sq.submit(proddir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING!!!: run me to KILL simulations that are still running\n",
    "for modelname_rep in sqs_p:\n",
    "    sqs_p[modelname_rep].stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset tracking for all\n",
    "sqs_p = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrapping replicate 3 of 4EJ4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-700e427f2ee9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pbc wrap -center com -centersel \"protein and chain P\" -compound residue -all;'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pbc wrap -center com -centersel \"protein\" -compound residue -all;'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'animate write dcd {%s} waitfor all top; exit'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moutname_dcd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# Convert dcd to xtc file using mdconvert, and delete dcd file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/moleculekit/vmdviewer.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mloadMol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##########################\n",
    "## Part 5: Wrap Structures\n",
    "##########################\n",
    "#Use VMD to wrap-up trajectories obtained in production\n",
    "#for pdbcode in pdb_set:\n",
    "for pdbcode in ['4EJ4']:\n",
    "    \n",
    "    #for rep in range(1,repnum+1):\n",
    "    for rep in [3]:\n",
    "        print('wrapping replicate %d of %s' % (rep, pdbcode))\n",
    "        proddir='%sproduction/%s/rep_%d/' % (resultspath, pdbcode, rep)\n",
    "        rep = str(rep)\n",
    "        \n",
    "        # To avoid repeating wrapping in Trajectories already wrapped, check the existance of this file\n",
    "        outname_xtc = proddir+pdbcode+'_'+rep+'.xtc'\n",
    "        outname_dcd = proddir+pdbcode+'_'+rep+'.dcd'\n",
    "        if os.path.exists(outname_xtc):\n",
    "            print('replicate already wrapped. Skipping...')\n",
    "            continue\n",
    "        \n",
    "        # Open a vmd viewer, and load molecule inside \n",
    "        viewer = getCurrentViewer(dispdev='text')\n",
    "        viewer.send('set molid [mol new {%sstructure.psf}] waitfor all' % proddir)\n",
    "        viewer.send('mol addfile %soutput.xtc waitfor all' % proddir)\n",
    "        \n",
    "        # Wrap structure and save trajectory\n",
    "        viewer.send('package require pbctools')\n",
    "        viewer.send('pbc wrap -center com -centersel \"protein and chain P\" -compound residue -all;')\n",
    "        viewer.send('pbc wrap -center com -centersel \"protein\" -compound residue -all;')\n",
    "        viewer.send('animate write dcd {%s} waitfor all top; exit' % (outname_dcd))\n",
    "\n",
    "        # Convert dcd to xtc file using mdconvert, and delete dcd file\n",
    "        !mdconvert {outtraj}.dcd -o {outtraj}.xtc \n",
    "        os.remove(outtraj+'.dcd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "## Part 5: Upload results to GPCRmd\n",
    "###################################\n",
    "\n",
    "mainurl = 'http://localhost:8000' \n",
    "#mainurl = 'https://submission.gpcrmd.org'\n",
    "\n",
    "def resp_to_dict(resp):\n",
    "    # Convert a json reponse into a dictionary\n",
    "    return eval(resp.content.decode('UTF-8').replace('true', 'True').replace('false','False'))\n",
    "\n",
    "def check_chains(pdbcode, mymol):\n",
    "    \"\"\"\n",
    "    Check how many chains from the original PDB structure remain in mymol structure\n",
    "    And to which Segments of our structure they correspond\n",
    "    \"\"\"\n",
    "    # Load blosum score matrix to align proteins\n",
    "    blosum62 = substitution_matrices.load(\"BLOSUM62\")\n",
    "\n",
    "    # Obtain sequences for original PDB file chains, and classifying them by chainID\n",
    "    # Also check which segment corresponds to what chain\n",
    "    pdbmol = Molecule(pdbcode)\n",
    "    chainseg = {}\n",
    "    chainset = set(pdbmol.get('chain', sel='protein'))\n",
    "    pdbmol_segseqs = pdbmol.sequence()\n",
    "    pdbmol_chainseqs = {}\n",
    "    for chain in chainset:\n",
    "        segid = np.unique(pdbmol.get('segid', sel='chain '+chain))[0]\n",
    "        pdbmol_chainseqs[chain] = pdbmol_segseqs[segid]\n",
    "\n",
    "    # Merging all protein chains in our systems into a single megachain\n",
    "    mymol_megachain = ''\n",
    "    for seg,chain in mymol.sequence().items():\n",
    "        mymol_megachain = mymol_megachain + chain\n",
    "\n",
    "    # Aligning sequences from original PDB to simulated PDB megasequence\n",
    "    # To know which chains from the original PDB are preserved\n",
    "    chain_present = {}\n",
    "    segtochain = {}\n",
    "    # For each chain in the original PDB file\n",
    "    for chain,seq in pdbmol_chainseqs.items():\n",
    "        chain_present[chain] = False\n",
    "        # For each segment in our molecule\n",
    "        for seg,myseq in mymol.sequence().items():\n",
    "            alig = pairwise2.align.localds(seq, myseq, blosum62, -10, -1)\n",
    "            is_present = alig[0].score > 200 # Check if top alignment has more than 200 score (perfect alignment threshold)\n",
    "            if is_present:\n",
    "                chain_present[chain] = is_present\n",
    "                segtochain[seg] = chain\n",
    "\n",
    "    return (chain_present, segtochain)\n",
    "\n",
    "def get_pdb_info(pdbcode, mymol):\n",
    "    \"\"\"\n",
    "    Get informarion of the system specified in the pdbcode from the RCSB-PDB webpage.\n",
    "    Mainly uniprot sequences, chainIDs and uniprot codes for the chains\n",
    "    \"\"\"\n",
    "    \n",
    "    #Check which chains from the original PDB structure are preserved in mymol structure\n",
    "    (chain_present, segtochain) = check_chains(pdbcode, mymol)\n",
    "    \n",
    "    # Get ligand molecules present in our system (basically anything that is not a protein)\n",
    "    ligset = set(mymol.get('resname', sel='not protein'))\n",
    "    \n",
    "    # Extract information from pdb webpage using api\n",
    "    ligdict = dict()\n",
    "    protdict = dict()\n",
    "    datadict = dict()\n",
    "    response = requests.get('http://www.rcsb.org/pdb/rest/customReport.xml?pdbids='+pdbcode+'&customReportColumns=ligandId,ligandName,uniprotAcc,experimentalTechnique,InChIKey,uniprotRecommendedName')\n",
    "    tree = ET.fromstring(response.content)\n",
    "    \n",
    "    # From returned XML Tree, extract the specified data for each (protein)chain in the system\n",
    "    for entry in tree:\n",
    "        ligandInchi = entry.find('dimEntity.InChIKey').text\n",
    "        ligandResname = entry.find('dimEntity.ligandId').text\n",
    "        ligandName = entry.find('dimEntity.ligandName').text\n",
    "        uniprot = entry.find('dimEntity.uniprotAcc').text\n",
    "        chainId = entry.find('dimEntity.chainId').text\n",
    "        uniname = entry.find('dimEntity.uniprotRecommendedName').text.lower()\n",
    "        method = entry.find('dimStructure.experimentalTechnique').text.lower()\n",
    "        \n",
    "        # Determine experimental method used, and use the corresponding id in GPCRmd database\n",
    "        if 'x-ray' in method: \n",
    "            method_id = 0\n",
    "        elif 'nmr' in method:\n",
    "            method_id = 1\n",
    "        elif 'electron microscopy' == method:\n",
    "            method_id = 4\n",
    "        else:\n",
    "            method_id = 5 # Other method\n",
    "\n",
    "        # If this chain is present in our mymol structure\n",
    "        if chain_present[chainId]:\n",
    "\n",
    "            # If this chain matches more than one uniprot, select one at random (not the best solution...)\n",
    "            if (uniprot) and ('#' in uniprot):\n",
    "                uniprot = uniprot.split('#')[1]\n",
    "\n",
    "            # If the uniprot recomended name contains the word 'receptor', then this is the GPCR chain (not the best solution either)\n",
    "            if 'receptor' in uniname:\n",
    "                isgpcr = True\n",
    "            else:\n",
    "                isgpcr = False\n",
    "\n",
    "            # Exclude ligands not present in our simulated system\n",
    "            if ligandResname and (ligandResname != 'null') and (ligandResname in ligset):\n",
    "                ligdict[ligandResname] = (ligandName,ligandInchi)\n",
    "                \n",
    "            # Get which segment(s) this chain is assigned to \n",
    "            segs = [ seg for seg,chain in segtochain.items() if chain == 'A' ]\n",
    "            protdict[chainId] = (uniprot, isgpcr, segs)\n",
    "\n",
    "    return (protdict,ligdict,segtochain,method_id)\n",
    "\n",
    "def login(s):\n",
    "    headers = {\n",
    "        'Cookie': 'csrftoken=cuGA6CSGmXfMbLwqlPoGjLLN7QkO6rZ7',\n",
    "        'Referer': mainurl+'/accounts/login/',\n",
    "    }\n",
    "    datalogin = {\n",
    "        'username': 'david',\n",
    "        'password': 'Ameboid',\n",
    "        'next' : '/accounts/memberpage/',\n",
    "        'csrfmiddlewaretoken' : 'cuGA6CSGmXfMbLwqlPoGjLLN7QkO6rZ7'\n",
    "    }\n",
    "    logo = s.post(mainurl+'/accounts/login/', \n",
    "               data=datalogin,\n",
    "               headers=headers)\n",
    "    return s\n",
    "    \n",
    "    \n",
    "def submission_step1(subm_id,s,protdict,mymol):\n",
    "    \"\"\"\n",
    "    Do step 1 of GPCRmd submission protocol\n",
    "    That is, submit information about the protein chains contained in the system\n",
    "    \"\"\"\n",
    "    \n",
    "    sessionid = str(s.cookies['sessionid'])\n",
    "    csrftoken = str(s.cookies['csrftoken'])\n",
    "\n",
    "    headers = {\n",
    "        'Referer' : mainurl+'/dynadb/protein/'+subm_id+'/',\n",
    "        'Cookie' : 'csrftoken=%s; sessionid=%s' %(csrftoken,sessionid),\n",
    "        'X-CSRFToken' : csrftoken\n",
    "    }\n",
    "    print('initiating step 1: protein data')\n",
    "    i = 0\n",
    "    protdict_2 = dict()\n",
    "    step1_data = {'csrfmiddlewaretoken': csrftoken}\n",
    "    # For each chain in this system (using the chainids of the original PDB)\n",
    "    for chainid,(uniprot,isgpcr,seglist) in protdict.items():\n",
    "        h = str(i)\n",
    "        \n",
    "        # Retrieve uniprot data\n",
    "        data = {'uniprotkbac': uniprot}\n",
    "        resp = s.post(mainurl+'/dynadb/protein/get_data_upkb/',\n",
    "              data = data,\n",
    "              headers = headers)\n",
    "        unidict = resp_to_dict(resp)\n",
    "        \n",
    "        # Align wild type chain and the chan of our molecule\n",
    "        myseq = ''\n",
    "        for seg in seglist:\n",
    "            myseq += mymol.sequence()[seg]\n",
    "        wtseq = unidict['Sequence']\n",
    "        resp = s.post(mainurl+'/dynadb/protein/'+subm_id+'/alignment/',\n",
    "                      data = {'wtseq' : wtseq, 'mutant': myseq},\n",
    "                      headers = headers\n",
    "        )\n",
    "        alignment = resp_to_dict(resp)['alignment']\n",
    "\n",
    "        # Get mutations from alignment\n",
    "        resp = s.post(mainurl+'/dynadb/protein/get_mutations/',\n",
    "                      data = {'alignment' : alignment, 'sequence': wtseq},\n",
    "                      headers = headers\n",
    "        )\n",
    "        mutations = resp_to_dict(resp)['mutations']\n",
    "        # Filter mutations (to avoid taking as mutations the cut of the N and C terminal loops)\n",
    "        realmutations = [ mut for mut in mutations if (mut['from'] != '-') and (mut['to'] != '-') ]\n",
    "\n",
    "        # Store mutations into post data\n",
    "        if len(realmutations):\n",
    "            print('oh yes')\n",
    "            step1_data['form-'+h+'-msequence'] = myseq\n",
    "            step1_data['form-'+h+'-is_mutated'] = 0\n",
    "            step1_data['form-'+h+'-alignment'] = alignment\n",
    "            u = 0\n",
    "            for mut in realmutations:\n",
    "                v = str(u)\n",
    "                step1_data['form-'+h+'-resid-'+v] = mut['resid']\n",
    "                step1_data['form-'+h+'-resletter_from-'+v] = mut['from']\n",
    "                step1_data['form-'+h+'-resletter_to-'+v] = mut['to']\n",
    "        \n",
    "        # Store retrieved data into post data dictionary\n",
    "        rec_name = None\n",
    "        step1_data['form-'+h+'-sequence'] = wtseq\n",
    "        step1_data['form-'+h+'-uniprotkbac'] = unidict['Entry']\n",
    "        step1_data['form-'+h+'-isoform'] = unidict['Isoform']\n",
    "        step1_data['form-'+h+'-name'] = unidict['Name']\n",
    "        step1_data['form-'+h+'-id_species_autocomplete'] = unidict['Organism']\n",
    "        step1_data['form-'+h+'-other_names'] = unidict['Aliases']\n",
    "        step1_data['form-'+h+'-sequence'] = unidict['Sequence']\n",
    "        if isgpcr:\n",
    "            rec_name = unidict['Name']\n",
    "            print(rec_name+' identified as GPCR')\n",
    "            step1_data['form-'+h+'-receptor'] = 0\n",
    "        else:\n",
    "            step1_data['form-'+h+'-receptor'] = 1\n",
    "        i+=1\n",
    "\n",
    "        # Sent step 1 data\n",
    "        step1_response = s.post(mainurl+'/dynadb/protein/'+subm_id+'/',\n",
    "                         data = step1_data,\n",
    "                         headers = headers)\n",
    "        \n",
    "        # Put uniprot code in list\n",
    "        protdict_2[chainid] = {'uniprot': unidict['Entry'],\n",
    "                                 'position' : i,\n",
    "                                 'name' : unidict['Name']\n",
    "                                }\n",
    "        \n",
    "    # We'll need to remember the order in which the system's chains have been submited\n",
    "    # Also the name of the receptor for step3\n",
    "    return (protdict_2, rec_name)\n",
    "\n",
    "def smol_submission(s, i, subm_id, sdfpath, smol, smol_key, smol_dict, mol):\n",
    "    \n",
    "    # Prepare headers, data and files\n",
    "    h = str(i)\n",
    "    sessionid = str(s.cookies['sessionid'])\n",
    "    csrftoken = str(s.cookies['csrftoken'])\n",
    "    print('submitting small molecule '+smol)\n",
    "    data = {\n",
    "        'csrfmiddlewaretoken': csrftoken,\n",
    "        'molpostkey': 'form-'+h+'-molsdf',\n",
    "    }\n",
    "    headers = {\n",
    "        'Referer' : mainurl+'/dynadb/molecule/'+subm_id+'/',\n",
    "        'Cookie' : 'csrftoken=%s; sessionid=%s' %(csrftoken,sessionid),\n",
    "        'Origin': 'http://localhost:8000',\n",
    "        'X-CSRFToken' : csrftoken\n",
    "    }\n",
    "    files = { 'form-'+h+'-molsdf' : open(sdfpath, 'r') }\n",
    "\n",
    "    # UPLOAD sdf\n",
    "    data_upload = {\n",
    "        'csrfmiddlewaretoken': csrftoken,\n",
    "        'form-'+h+'-is_present': 'on',\n",
    "        'form-'+h+'-description': 'Standard form',\n",
    "        'form-'+h+'-search_by_pubchem': 'sinchi',\n",
    "        'form-'+h+'-retrieve_type_pubchem': 'parent',\n",
    "        'form-'+h+'-neutralize_pubchem': '1',\n",
    "        'form-'+h+'-search_by_chembl': 'smiles',\n",
    "        'form-'+h+'-similarity': '100',\n",
    "        'form-'+h+'-retrieve_type_chembl': 'parent',\n",
    "        'form-'+h+'-neutralize_chembl': '1',\n",
    "        'molpostkey': 'form-'+h+'-molsdf',\n",
    "        'pngsize': '300'\n",
    "    }\n",
    "    resp = s.post(mainurl+'/dynadb/molecule/'+subm_id+'/generate_properties/',\n",
    "                 headers = headers,\n",
    "                 files = files,\n",
    "                 data = data_upload)\n",
    "    \n",
    "    # Get pubchem info of compound\n",
    "    resp = requests.get('https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/inchikey/'+smol_key+'/property/CanonicalSMILES,Charge,InChI,IUPACName,/JSON')\n",
    "    pub_dict = eval(resp.content.decode('UTF-8').replace('null', 'None'))['PropertyTable']['Properties'][0]\n",
    "\n",
    "    # Get names of compound\n",
    "    resp = requests.get('https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/inchikey/'+smol_key+'/synonyms/TXT')\n",
    "    synonyms = resp.text.replace(\"\\n\", '; ')\n",
    "\n",
    "    # Get official name of compound\n",
    "    resp = requests.get('https://pubchem.ncbi.nlm.nih.gov/compound/'+str(pub_dict['CID']))\n",
    "    soup = BeautifulSoup(resp.text,'html')\n",
    "    smol_name = soup.find('meta',attrs={'property' : 'og:title'}).get('content')\n",
    "    \n",
    "    # Get chemblid\n",
    "    try:\n",
    "        resp = requests.get('https://www.ebi.ac.uk/chembl/api/data/molecule/'+smol_key)\n",
    "        tree = ET.fromstring(resp.text)\n",
    "        chemblid = tree.find('molecule_chembl_id').text.replace('CHEMBL','')\n",
    "    except Exception as e:\n",
    "        print(\"Chemblid not avalible for molecule \"+smol_name)\n",
    "        chemblid = \"\"\n",
    "    \n",
    "    # Use obtained data to submit small molecule\n",
    "    submit_data = {\n",
    "        'csrfmiddlewaretoken': csrftoken,\n",
    "        'form-'+h+'-molsdf': '',\n",
    "        'form-'+h+'-upload_button': '', \n",
    "        'form-'+h+'-is_present': 'on',\n",
    "        'form-'+h+'-inchi': pub_dict['InChI'],\n",
    "        'form-'+h+'-sinchikey': smol_key,\n",
    "        'form-'+h+'-net_charge': str(pub_dict['Charge']),\n",
    "        'form-'+h+'-inchikey': smol_key,\n",
    "        'form-'+h+'-smiles': pub_dict['CanonicalSMILES'],\n",
    "        'form-'+h+'-description': '', \n",
    "        'form-'+h+'-get_mol_info': '',\n",
    "        'form-'+h+'-is_not_in_databases': 'on',\n",
    "        'form-'+h+'-search_by_pubchem': 'sinchi',\n",
    "        'form-'+h+'-retrieve_type_pubchem': 'original',\n",
    "        'form-'+h+'-neutralize_pubchem': '1',\n",
    "        'form-'+h+'-search_by_chembl': 'smiles',\n",
    "        'form-'+h+'-similarity': '100',\n",
    "        'form-'+h+'-retrieve_type_chembl': 'original',\n",
    "        'form-'+h+'-neutralize_chembl': '1',\n",
    "        'form-'+h+'-name': smol_name,\n",
    "        'form-'+h+'-iupac_name': pub_dict['IUPACName'],\n",
    "        'form-'+h+'-pubchem_cid': str(pub_dict['CID']),\n",
    "        'form-'+h+'-update_from_pubchem': '', \n",
    "        'form-'+h+'-chemblid': chemblid,\n",
    "        'form-'+h+'-update_from_chembl': '',\n",
    "        'form-'+h+'-other_names': synonyms,\n",
    "        'form-'+h+'-passMoleculePOST': 'passMoleculePOST',\n",
    "        'form-'+h+'-add_molecule': '+ Add molecule',\n",
    "        'form-'+h+'-del_molecule': '- Remove molecule',\n",
    "        'form-'+h+'-reset': '',\n",
    "    }\n",
    "\n",
    "    # Dictionary of crystalized components (useful in the future)\n",
    "    smol_dict[smol] = {\n",
    "                      'name' : smol_name,\n",
    "                      'num_mol' : len(np.unique(mol.get('resid', sel='resname '+smol))),\n",
    "                      'order_mol' : str(i+1)\n",
    "    }  \n",
    "\n",
    "    # Add bulk or co-crystalized properties\n",
    "    ligname = None\n",
    "    if smol == 'TIP3':\n",
    "        submit_data['form-'+h+'-bulk_type'] = '0'\n",
    "        submit_data['form-'+h+'-type'] = '6'\n",
    "        smol_dict[smol]['crystalized'] = 0\n",
    "        smol_dict[smol]['type'] = 'Water'\n",
    "    elif smol == 'POPC':\n",
    "        submit_data['form-'+h+'-bulk_type'] = '0'\n",
    "        submit_data['form-'+h+'-type'] = '7'\n",
    "        smol_dict[smol]['crystalized'] = 0\n",
    "        smol_dict[smol]['type'] = 'Lipid'\n",
    "    elif (smol == 'CLA') or (smol == 'SOD'):\n",
    "        submit_data['form-'+h+'-bulk_type'] = '0'\n",
    "        submit_data['form-'+h+'-type'] = '8'\n",
    "        smol_dict[smol]['crystalized'] = 0\n",
    "        smol_dict[smol]['type'] = 'Ions'        \n",
    "    else:#Else make it co-cristalized orthosteric ligand. TODO: recognize orthosteric ligand\n",
    "        submit_data['form-'+h+'-type'] = '0'\n",
    "        smol_dict[smol]['crystalized'] = 1\n",
    "        smol_dict[smol]['type'] = 'Ligand'\n",
    "        ligname = smol_name\n",
    "        \n",
    "    #Send small molecule\n",
    "    resp = s.post(mainurl+'/dynadb/molecule/'+subm_id+'/',\n",
    "                  data = submit_data,\n",
    "                  headers = headers)\n",
    "    \n",
    "    # Return smol_dict with a new entry, new molecule marker (i) and the small molecule name if it is the ligand\n",
    "    i += 1\n",
    "    if ligname:\n",
    "        return (i, smol_dict, smol_name)\n",
    "    else:\n",
    "        return (i, smol_dict)\n",
    "\n",
    "def submission_step3(s, subm_id, pdbpath, recname, ligname, protdict, smol_dict, segtochain, method_id):\n",
    "    \"\"\"\n",
    "    Perform step3 of GPCRmd submission for specified system\n",
    "    \"\"\"\n",
    "    \n",
    "    # Data needed for the submission\n",
    "    sessionid = str(s.cookies['sessionid'])\n",
    "    csrftoken = str(s.cookies['csrftoken'])\n",
    "    headers = {\n",
    "        'Referer' : mainurl+'/dynadb/model/'+subm_id+'/',\n",
    "        'Cookie' : 'csrftoken=%s; sessionid=%s' %(csrftoken,sessionid)\n",
    "    }\n",
    "    data_submit = {\n",
    "        'csrfmiddlewaretoken' : csrftoken,\n",
    "        'prtnam' : [],\n",
    "        'prtnum' : [],\n",
    "        'uniprot' : []\n",
    "    }\n",
    "    print('initiating step 3: crystalized components')\n",
    "\n",
    "    # Determine name of the complex\n",
    "    sysname = recname + ' in complex with ' +ligname if ligname else recname\n",
    "    #Cut excessively large names\n",
    "    if len(sysname) > 100:\n",
    "        sysname = sysname[0:99]\n",
    "    \n",
    "    # Part A: General information\n",
    "    data_submit['name'] = sysname\n",
    "    data_submit['type'] = 1 # TODO: check which number corresponds to apoform and which to complex\n",
    "    data_submit['pdbid'] = pdbcode\n",
    "    data_submit['description'] = \"\" # No description. Sorry\n",
    "    data_submit['source_type'] = method_id\n",
    "\n",
    "    # Part B1: Submitted proteins summary\n",
    "    for chain in protdict:\n",
    "        data_submit['prtnam'].append(protdict[chain]['name'])\n",
    "        data_submit['prtnum'].append(protdict[chain]['position'])\n",
    "        data_submit['uniprot'].append(protdict[chain]['uniprot'])\n",
    "\n",
    "    # Part B2: Curated protein data: protein segments\n",
    "    prot_segs = set(mymol.get('segid', sel=\"protein\"))\n",
    "    iprot = 0\n",
    "    for segid in prot_segs:\n",
    "        # Get segment information (uniprot code, chainid, and starting-ending residues)\n",
    "        auldchain = segtochain[segid]\n",
    "        prot_num = protdict[auldchain]['position']\n",
    "        chainid = np.unique(mymol.get('chain', sel='segid '+segid))[0]\n",
    "        segres = set(mymol.get('resid', sel='segid '+segid))\n",
    "        from_res = min(segres)\n",
    "        to_res = max(segres)\n",
    "        iprot_s = str(iprot)\n",
    "\n",
    "        # Add obtained info to data submit\n",
    "        data_submit['formps-'+iprot_s+'-prot'] = prot_num\n",
    "        data_submit['formps-'+iprot_s+'-chain'] = chainid\n",
    "        data_submit['formps-'+iprot_s+'-segid'] = segid\n",
    "        data_submit['formps-'+iprot_s+'-resid_from'] = from_res\n",
    "        data_submit['formps-'+iprot_s+'-resid_to'] = to_res\n",
    "        data_submit['formps-'+iprot_s+'-seq_resid_from'] = from_res # Are you sure they are always equivalents?\n",
    "        data_submit['formps-'+iprot_s+'-seq_resid_to'] = to_res\n",
    "        data_submit['formps-'+iprot_s+'-pdbidps'] = pdbcode\n",
    "        data_submit['formps-'+iprot_s+'-source_typeps'] = 1 # I dont care about this part. Is meant to be removed anyways\n",
    "        data_submit['formps-'+iprot_s+'-bonded_to_id_modeled_residues'] = None\n",
    "        iprot += 1\n",
    "    \n",
    "    # Part C: Cocrystalized small molecules\n",
    "    typesid={# This data submit uses numerical values for small_molecule types\n",
    "        'Ions' : '0',\n",
    "        'Ligand' : '1',\n",
    "        'Lipid' : '2',\n",
    "        'Water' : '3',\n",
    "        'Other' : '4'\n",
    "    }\n",
    "    # Get submission form page, and extract required information from there\n",
    "    rep = s.get(mainurl+'/dynadb/model/'+subm_id+'/', headers = headers)\n",
    "    soup = BeautifulSoup(rep.text, 'html.parser')\n",
    "    # For every crystalized small molecule, add an entry in data_submit\n",
    "    # Many things are wrong here, but since this part is not going to be used anywhere nobody cares.\n",
    "    for lig in smol_dict:\n",
    "        if smol_dict[lig]['crystalized']:\n",
    "            ordmol = smol_dict[lig]['order_mol']\n",
    "            id_i = soup.find('input', attrs = {'id': re.compile(r'id_formmc-\\d+-molecule'), 'value':ordmol}).get('id')\n",
    "            i = re.findall(\"\\d+\", id_i)[0]\n",
    "            data_submit['formmc-'+i+'-resname'] = lig\n",
    "            data_submit['formmc-'+i+'-numberofmol'] = smol_dict[lig]['num_mol']\n",
    "            data_submit['formmc-'+i+'-molecule'] = smol_dict[lig]['order_mol']\n",
    "            data_submit['formmc-'+i+'-id_molecule'] = soup.find('input',attrs = {'id': 'id_formmc-'+i+'-id_molecule'}).get('value')\n",
    "            data_submit['formmc-'+i+'-namemc'] = smol_dict[lig]['name']\n",
    "            data_submit['formmc-'+i+'-typemc'] = typesid[smol_dict[lig]['type']]\n",
    "            \n",
    "    # Upload model file\n",
    "    upl_resp = s.post(mainurl+'/dynadb/model/'+subm_id+'/upload_model_pdb/',\n",
    "          headers = headers,\n",
    "          data = data_submit,\n",
    "          files = {'file_source' : open(pdbpath)})\n",
    "\n",
    "    # Submit step3\n",
    "    resp = s.post(mainurl+'/dynadb/model/'+subm_id+'/',\n",
    "          headers = headers,\n",
    "          data = data_submit)\n",
    "\n",
    "def submission_step4(s, subm_id, modelname, protdict, smol_dict, timestep, trajperiod):\n",
    "    buildpath = resultspath+'build/'+modelname+'/'\n",
    "    sessionid = str(s.cookies['sessionid'])\n",
    "    csrftoken = str(s.cookies['csrftoken'])\n",
    "    data_submit = {\n",
    "        'csrfmiddlewaretoken' : csrftoken,\n",
    "        'prtnam' : [],\n",
    "        'prtnum' : [],\n",
    "        'uniprot' : []\n",
    "    }\n",
    "    headers_submit = {\n",
    "        'Referer' : mainurl+'/dynadb/dynamics/'+subm_id,\n",
    "        'Cookie' : 'csrftoken=%s; sessionid=%s' %(csrftoken,sessionid),\n",
    "        'X-CSRFToken' : csrftoken,\n",
    "    }\n",
    "    print('initiating step 4: simulation information')\n",
    "\n",
    "    # Part A: Upload simulation files\n",
    "    referer_path = mainurl+'/dynadb/dynamics/'+subm_id+'/upload_files/?file_type='\n",
    "    \n",
    "    # Coordinate file\n",
    "    headers = {\n",
    "        'Referer' : referer_path+'coor',\n",
    "        'Cookie' : 'csrftoken=%s; sessionid=%s' %(csrftoken,sessionid),\n",
    "        'X-CSRFToken' : csrftoken,\n",
    "        'Connection' : 'keep-alive',\n",
    "    }\n",
    "    data = {\n",
    "        'csrfmiddlewaretoken' : csrftoken,\n",
    "        'file_type' : 'coor',\n",
    "        'filekey' : 'coor',\n",
    "    }\n",
    "    files = {\n",
    "        'coor' : open(buildpath+'structure.pdb')\n",
    "    }\n",
    "\n",
    "    resp = s.post(mainurl+'/dynadb/dynamics/'+subm_id+'/upload_files/',\n",
    "          data = data,\n",
    "          files = files,\n",
    "          headers = headers)\n",
    "    \n",
    "    # Topology file\n",
    "    headers['Referer'] = referer_path+'top'\n",
    "    data['file_type'] = 'top'\n",
    "    data['filekey'] = 'top'\n",
    "    files = { 'top' : open(buildpath+'structure.psf')}\n",
    "    resp = s.post(mainurl+'/dynadb/dynamics/'+subm_id+'/upload_files/',\n",
    "          data = data,\n",
    "          files = files,\n",
    "          headers = headers)\n",
    "    \n",
    "    # Trajectory files\n",
    "    headers['Referer'] = referer_path+'traj'\n",
    "    data['file_type'] = 'traj'\n",
    "    data['filekey'] = 'traj'\n",
    "    files = [('traj', open(resultspath+'production/'+modelname+'/rep_1/output.xtc', 'rb')),\n",
    "              ('traj', open(resultspath+'production/'+modelname+'/rep_2/output.xtc', 'rb')),\n",
    "              ('traj', open(resultspath+'production/'+modelname+'/rep_3/output.xtc', 'rb'))]\n",
    "    \n",
    "    resp = s.post(mainurl+'/dynadb/dynamics/'+subm_id+'/upload_files/traj/',\n",
    "          data = data,\n",
    "          files = files,\n",
    "          headers = headers)\n",
    "    \n",
    "    # Parameters files (compress and upload)\n",
    "    with tarfile.open(buildpath+'parameters.tar.gz', \"w:gz\") as tar:\n",
    "        tar.add(buildpath+'parameters', arcname='parameters')\n",
    "    headers['Referer'] = referer_path+'parm'\n",
    "    data['file_type'] = 'parm'\n",
    "    data['filekey'] = 'parm'\n",
    "    files = { 'parm' : open(buildpath+'parameters.tar.gz','rb')}\n",
    "    resp = s.post(mainurl+'/dynadb/dynamics/'+subm_id+'/upload_files/',\n",
    "          data = data,\n",
    "          files = files,\n",
    "          headers = headers)\n",
    "    \n",
    "    # Part B1: Submitted proteins summary\n",
    "    for chain in protdict:\n",
    "        data_submit['prtnam'].append(protdict[chain]['name'])\n",
    "        data_submit['prtnum'].append(protdict[chain]['position'])\n",
    "        data_submit['uniprot'].append(protdict[chain]['uniprot'])\n",
    "\n",
    "    # Part B2: Resubmit (third time...) the ligand elements\n",
    "    # Take page 4 of form to extract smalmol info\n",
    "    rep = s.get(mainurl+'/dynadb/dynamics/'+subm_id+'/', headers = headers)\n",
    "    soup = BeautifulSoup(rep.text, 'html.parser')\n",
    "    for smol in smol_dict:\n",
    "\n",
    "        # Take the 'h' (number assigned to the ids of the inputs of this molecule in the web)\n",
    "        idmol = smol_dict[smol]['order_mol']\n",
    "        id_obj = soup.find('input', {'name' : re.compile(r\"formc-\\d+-molecule\"), \"value\" : [idmol,' '+idmol+' ']}).get('id')\n",
    "        h = re.search('-(\\d+)-', id_obj).group(1)\n",
    "\n",
    "        # Molecule data to submit \n",
    "        data_submit['formc-'+h+'-resname'] = smol\n",
    "        data_submit['formc-'+h+'-molecule'] = smol_dict[smol]['order_mol']\n",
    "        data_submit['formc-'+h+'-id_molecule'] = soup.find('input',attrs = {'id': 'id_formc-'+h+'-id_molecule'}).get('value')\n",
    "        data_submit['formc-'+h+'-name'] = smol_dict[smol]['name']\n",
    "        data_submit['formc-'+h+'-numberofmol'] = smol_dict[smol]['num_mol']\n",
    "        data_submit['formc-'+h+'-typemc'] = smol_dict[smol]['type']\n",
    "        data_submit['formc-'+h+'-type_int'] = soup.find('input',attrs = {'id': 'id_formc-'+h+'-type_int'}).get('value')\n",
    "\n",
    "    # Part C: Simulation specs\n",
    "    data_submit['id_dynamics_methods']= '1' #Molecular mechanics\n",
    "    data_submit['software']= 'ACEMD3'\n",
    "    data_submit['sversion']= 'GPUGRID' # TODO: Is that correct??\n",
    "    data_submit['ff']= 'CHARMM'\n",
    "    data_submit['ffversion']= '36m Feb 2016'\n",
    "    data_submit['id_assay_types']= 1 # Orthosteric (un)/binding\n",
    "    data_submit['id_dynamics_membrane_types']= 2 # Homogeneus membrane\n",
    "    data_submit['id_dynamics_solvent_types']= 2 # TIP3P solvent\n",
    "    data_submit['solvent_num']= len(mymol.get('resid', sel='resname TIP3'))\n",
    "    data_submit['atom_num']= len(mymol.get('name'))\n",
    "    data_submit['timestep']= timestep\n",
    "    data_submit['delta'] = (trajperiod*timestep)/10e6\n",
    "    data_submit['description'] = 'autosubmission' # time/frames\n",
    "\n",
    "    # Submit step 4\n",
    "    rep = s.post(mainurl+'/dynadb/dynamics/'+subm_id+'/',\n",
    "            headers = headers,\n",
    "            data = data_submit)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-26 14:22:06,121 - moleculekit.readers - INFO - Attempting PDB query for 5UIW\n",
      "2020-10-26 14:22:07,569 - moleculekit.molecule - WARNING - Alternative atom locations detected. Only altloc A was kept. If you prefer to keep all use the keepaltloc=\"all\" option when reading the file.\n",
      "2020-10-26 14:22:07,572 - moleculekit.molecule - INFO - Removed 6 atoms. 3437 atoms remaining in the molecule.\n",
      "2020-10-26 14:22:07,722 - moleculekit.molecule - WARNING - Cannot provide one-letter code for non-standard residue PCA\n",
      "2020-10-26 14:22:07,726 - moleculekit.tools.sequencestructuralalignment - INFO - No segment was specified by the user for `mol`. Alignment will be done on all protein segments.\n",
      "2020-10-26 14:22:07,791 - moleculekit.tools.sequencestructuralalignment - INFO - No segment was specified by the user for `ref` and multiple segments (['0', '1']) were detected. Alignment will be done on all protein segments.\n",
      "2020-10-26 14:22:07,873 - moleculekit.molecule - WARNING - Cannot provide one-letter code for non-standard residue PCA\n",
      "2020-10-26 14:22:08,443 - moleculekit.tools.sequencestructuralalignment - WARNING - 4 alignments found. Limiting to 1 as specified in the `maxalignments` argument.\n",
      "2020-10-26 14:22:08,447 - moleculekit.tools.sequencestructuralalignment - INFO - Alignment #0 was done on 104 residues: mol segid 0 resid 59-162\n",
      "2020-10-26 14:22:08,987 - moleculekit.molecule - INFO - Removed 2910 atoms. 527 atoms remaining in the molecule.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B\n",
      "yes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def add_peplig(mymol, pdbcode):\n",
    "    pdbmol = Molecule(pdbcode)\n",
    "\n",
    "    # Align in-preparation molecule system with its original PDB counterpart\n",
    "    alignment_results = sequenceStructureAlignment(mymol, pdbmol, maxalignments = 1)\n",
    "    mol_aligned = alignment_results[0]\n",
    "\n",
    "    # Extract chain names and length from PDB\n",
    "    response = requests.get('http://www.rcsb.org/pdb/rest/customReport.xml?pdbids='+pdbcode+'&customReportColumns=uniprotRecommendedName,chainLength')\n",
    "    tree = ET.fromstring(response.content)\n",
    "    \n",
    "    # Check which one of this chains corresponds to the ligand protein chain\n",
    "    ligchain = None\n",
    "    min_seqlen = 100000000000\n",
    "    for entry in tree:\n",
    "        uniname = entry.find('dimEntity.uniprotRecommendedName').text.lower()\n",
    "        seqlen = int(entry.find('dimEntity.chainLength').text)\n",
    "        chainId = entry.find('dimEntity.chainId').text\n",
    "        \n",
    "        # Check if this entity is a protein one\n",
    "        if len(pdbmol.get('chain', sel='protein and chain '+chainId)) == 0:\n",
    "            continue\n",
    "\n",
    "        # If uniprot names of the chain contain 'receptor' or 'G-protein', then for sure this is is not the ligand chain\n",
    "        if any(word in uniname for word in ['receptor','Guanine nucleotide-binding protein']):\n",
    "            continue\n",
    "\n",
    "        # Compare lengths and take shortest\n",
    "        print(chainId)\n",
    "        if seqlen < min_seqlen:\n",
    "            min_seqlen = seqlen\n",
    "            ligchain = chainId\n",
    "\n",
    "    # Take ligand chain from the original pdb and insert it in our mol\n",
    "    pdbmol.filter(\"chain \"+ligchain)\n",
    "    mymol.append(pdbmol)\n",
    "    return mymol\n",
    "\n",
    "molo = add_peplig(Molecule(basepath+'data_sim/5UIW/ClassA_ccr5_human_5UIW_refined_Inactive_2020-10-08_GPCRdb.pdb'),'5UIW')\n",
    "molo.write('krosis.pdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-22 15:37:50,095 - moleculekit.readers - INFO - Attempting PDB query for 5WIU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitting 5WIU simulation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-22 15:37:51,449 - moleculekit.molecule - WARNING - Alternative atom locations detected. Only altloc A was kept. If you prefer to keep all use the keepaltloc=\"all\" option when reading the file.\n",
      "2020-10-22 15:37:51,450 - moleculekit.molecule - INFO - Removed 38 atoms. 3109 atoms remaining in the molecule.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 'GAAALVGGVLLIGAVLAGNSLVCVSVATERALQTPTNSFIVSLAAADLLLALLVLPLFVYSEVQGGAWLLSPRLCDALMAMDVMLCTASIFNLCAISVDRFVAVAVPLRYNRQGGSRRQLLLIGATWLLSAAVAAPVLCGLNDPAVCRLEDRDYVVYSSVCSFFLPCPLMLLLYWATFRGLQRWEVARRADLEDNWETLNDNLKVIEKADNAAQVKDALTKMRAAALDAQKATPPKLEDKSPPEMKDFRHGFDILVGQIDDALKLANEGKVKEAQAAAEQLKTTRNAYIQKYLAKITGRERKAMRVLPVVVGAFLLCWTPFFVVHITQALCPACSVPPRLVSAVTWLGYVNSALNPVIYTVFNAEFRNVFRKA'}\n",
      "[Alignment(seqA='--------GAAALVGGVLLIGAVLAGNSLVCVSVATERALQTPTNSFIVSLAAADLLLALLVLPLFVYSEVQGGAWLLSPRLCDALMAMDVMLCTASIFNLCAISVDRFVAVAVPLRYNRQGGSRRQLLLIGATWLLSAAVAAPVLCGLN-----DPAVCRLEDRDYVVYSSVCSFFLPCPLMLLLYWATFRGLQRWEVARRADLEDNWETLNDNLKVIEKADNAAQVKDALTKMRAAALDAQKATPPKLEDKSPPEMKDFRHGFDILVGQIDDALKLANEGKVKEAQAAAEQLKTTRNAYIQKYLAKITGRERKAMRVLPVVVGAFLLCWTPFFVVHITQALCPACSVPPRLVSAVTWLGYVNSALNPVIYTVFNAEFRNVFRKA', seqB='ASAGLAGQGAAALVGGVLLIGAVLAGNSLVCVSVATERALQTPTNSFIVSLAAADLLLALLVLPLFVYSEVQGGAWLLSPRLCDALMAMDVMLCTASIFNLCAISVDRFVAVAVPLRYNRQGGSRRQLLLIGATWLLSAAVAAPVLCGLNDVRGRDPAVCRLEDRDYVVYSSVCSFFLPCPLMLLLYWATFRGLQRWEVARRAKLHGRA---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------', score=950.0, start=8, end=205), Alignment(seqA='--------GAAALVGGVLLIGAVLAGNSLVCVSVATERALQTPTNSFIVSLAAADLLLALLVLPLFVYSEVQGGAWLLSPRLCDALMAMDVMLCTASIFNLCAISVDRFVAVAVPLRYNRQGGSRRQLLLIGATWLLSAAVAAPVLCGLND-----PAVCRLEDRDYVVYSSVCSFFLPCPLMLLLYWATFRGLQRWEVARRADLEDNWETLNDNLKVIEKADNAAQVKDALTKMRAAALDAQKATPPKLEDKSPPEMKDFRHGFDILVGQIDDALKLANEGKVKEAQAAAEQLKTTRNAYIQKYLAKITGRERKAMRVLPVVVGAFLLCWTPFFVVHITQALCPACSVPPRLVSAVTWLGYVNSALNPVIYTVFNAEFRNVFRKA', seqB='ASAGLAGQGAAALVGGVLLIGAVLAGNSLVCVSVATERALQTPTNSFIVSLAAADLLLALLVLPLFVYSEVQGGAWLLSPRLCDALMAMDVMLCTASIFNLCAISVDRFVAVAVPLRYNRQGGSRRQLLLIGATWLLSAAVAAPVLCGLNDVRGRDPAVCRLEDRDYVVYSSVCSFFLPCPLMLLLYWATFRGLQRWEVARRAKLHGRA---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------', score=950.0, start=8, end=205)]\n",
      "[Alignment(seqA='GAAALVGGVLLIGAVLAGNSLVCVSVATERALQTPTNSFIVSLAAADLLLALLVLPLFVYSEVQGGAWLLSPRLCDALMAMDVMLCTASIFNLCAISVDRFVAVAVPLRYNRQGGSRRQLLLIGATWLLSAAVAAPVLCGLNDPAVCRLEDRDYVVYSSVCSFFLPCPLMLLLYWATFRGLQRWEVARRADLEDNWETLNDNLKVIEKADNAAQVKDALTKMRAAALDAQKATPPKLEDKSPPEMKDFRHGFDILVGQIDDALKLANEGKVKEAQAAAEQLKTTRNAYIQKYLAKITGRERKAMRVLPVVVGAFLLCWTPFFVVHITQALCPACSVPPRLVSAVTWLGYVNSALNPVIYTVFNAEFRNVFRKA-----', seqB='------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------RRRRRAKITGRERKAMRVLPVVVGAFLLCWTPFFVVHITQALCPACSVPPRLVSAVTWLGYVNSALNPVIYTVFNAEFRNVFRKALRACC', score=421.0, start=293, end=373)]\n",
      "{'A': True}\n",
      "initiating step 1: protein data\n",
      "{'A': ('P21917', True, ['P0', 'P1'])}\n",
      "0\n",
      "D(4) dopamine receptor identified as GPCR\n"
     ]
    }
   ],
   "source": [
    "#### Simulation submission\n",
    "\n",
    "# For each of the currently-working-with systems defined in Part 1\n",
    "#for pdbcode in pdb_set:\n",
    "for pdbcode in testset:   \n",
    "    pdbcode = '5WIU'\n",
    "    pdbpath = resultspath+'build/'+pdbcode+'/structure.pdb'\n",
    "    \n",
    "    # Load molecule\n",
    "    modelname = os.path.basename(os.path.splitext(pdbpath)[0])\n",
    "    modelname = pdbcode\n",
    "    mymol = Molecule(pdbpath)\n",
    "    print('Submitting '+modelname+' simulation...')\n",
    "    \n",
    "    ## Step -2: Get information of protein chains and ligand molecules from PDB web\n",
    "    (protdict,ligandsdict,segtochain,method_id) = get_pdb_info(pdbcode, mymol)\n",
    "    \n",
    "    ## Step -1: Login into GPCRmd\n",
    "    with requests.Session() as s:\n",
    "        login(s)\n",
    "        \n",
    "    ## Step 0: New submission (temporaly commented to avoid saturating GPCRmd with trashy new submissions)\n",
    "    \"\"\"\n",
    "    response_new = s.get(mainurl + '/dynadb/db_inputform/')\n",
    "    soup = BeautifulSoup(response_new.text, 'html.parser')\n",
    "    step1_link = soup.find('a',attrs={'id' : 'selection-button'}).get('href')\n",
    "    subm_id = step1_link.split('/')[-2]\n",
    "    print(subm_id)\n",
    "    \"\"\"\n",
    "    subm_id = '103'\n",
    "    #subm_id = '299'\n",
    "    \n",
    "    ## Step 1: Protein information\n",
    "    (newprotdict,recname) = submission_step1(subm_id,s,protdict, mymol)\n",
    "    break\n",
    "    ## Step 2: Introduce small molecules \n",
    "    print('initiating step 2: small molecule data')\n",
    "    # Introduce common small molecules (waters, lipids and ions)\n",
    "    i = 0\n",
    "    smol_dict = dict()\n",
    "    common_mols = [\n",
    "        ('TIP3', 'XLYOFNOQVPJJNP-UHFFFAOYSA-N'),\n",
    "        ('POPC', 'WTJKGGKOPKCXLL-VYOBOKEXSA-N'),\n",
    "        ('SOD', 'FKNQFGJONOIPTF-UHFFFAOYSA-N'),\n",
    "        ('CLA', 'VEXZGXHMUGYJMC-UHFFFAOYSA-M')\n",
    "    ]\n",
    "    for smol,smol_key in common_mols:\n",
    "        sdfpath = basepath+'smalmol_sdfs/'+smol+'.sdf'\n",
    "        (i, smol_dict) = smol_submission(s, i, subm_id, sdfpath, smol, smol_key, smol_dict, mymol)\n",
    "\n",
    "    # Introduce ligands: all will be defined as orthosteric ligands\n",
    "    ligname = None\n",
    "    for lig in ligandsdict:\n",
    "        # Avoid blacklisted molecules or cholesterol or ion\n",
    "        if (lig in detergent_blacklist) or (lig in glucids_blacklist) or (lig == \"CLR\") or (len(lig) == 2):\n",
    "            continue\n",
    "        # Download ligand, store it into temporary file\n",
    "        response = requests.get('https://files.rcsb.org/ligands/view/'+lig+'_ideal.sdf')\n",
    "        with open('tmpfile.sdf','wb') as tmpout:\n",
    "            tmpout.write(response.content)\n",
    "\n",
    "        # Send molecule\n",
    "        smol_key = ligandsdict[lig][1]\n",
    "        (i, smol_dict, ligname) = smol_submission(s, i, subm_id, 'tmpfile.sdf', lig, smol_key, smol_dict, mymol)\n",
    "        os.remove('tmpfile.sdf')\n",
    "\n",
    "    ## Step 3: Crystalized components information\n",
    "    submission_step3(s, subm_id, pdbpath, recname, ligname, newprotdict, smol_dict, segtochain, method_id)\n",
    "\n",
    "    ## Step 4: Dynamics information\n",
    "    submission_step4(s, subm_id, modelname, newprotdict, smol_dict, timestep, trajperiod)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
