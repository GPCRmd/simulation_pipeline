{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vitus/miniconda3/lib/python3.6/site-packages/htmd/versionwarnings.py:28: UserWarning: As of HTMD 1.16 the default number of threads HTMD spawns for calculations is set to 1. You can enable parallelism at your own risk using `config(njobs=-2)` in the beginning of your scripts. To disable this warning run once: `from htmd import _disableWarnings; _disableWarnings('1.16');`\n",
      "  , UserWarning)\n",
      "/home/vitus/miniconda3/lib/python3.6/site-packages/htmd/versionwarnings.py:34: UserWarning: As of HTMD 1.21 support for ACEMD v2 has stopped. Please use ACEMD3 instead as well as the corresponding equilibration and production protocols. To disable this warning run once: `from htmd import _disableWarnings; _disableWarnings('1.21');`\n",
      "  , UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Please cite HTMD: Doerr et al.(2016)JCTC,12,1845. https://dx.doi.org/10.1021/acs.jctc.6b00049\n",
      "\n",
      "HTMD Documentation at: https://www.htmd.org/docs/latest/\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-03 12:00:11,241 - binstar - INFO - Using Anaconda API: https://api.anaconda.org\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New devel HTMD version (1.22.0 python[3.7,<3.8.0a0,3.6,<3.7.0a0]) is available. You are currently on (1.21.2).There are several methods to update:    - Create a new conda env. using `conda create -n htmd1.22.0 htmd=1.22.0 -c acellera -c psi4 -c conda-forge`    - Create a brand new conda installation and run `conda install htmd -c acellera -c psi4 -c conda-forge`    - Run: `conda update htmd -c acellera -c psi4 -c conda-forge` (NOT RECOMMENDED)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import traceback\n",
    "import re\n",
    "import requests\n",
    "import zipfile,io\n",
    "import glob\n",
    "import numpy as np\n",
    "from shutil import copy2,copytree,rmtree\n",
    "import xml.etree.ElementTree as ET\n",
    "from bs4 import BeautifulSoup\n",
    "import openbabel\n",
    "import time\n",
    "import random\n",
    "import sys\n",
    "\n",
    "#HTMD things\n",
    "import htmd\n",
    "from htmd.ui import *\n",
    "from moleculekit.tools.sequencestructuralalignment import sequenceStructureAlignment\n",
    "from htmd.protocols.equilibration_v2 import Equilibration\n",
    "from htmd.protocols.production_v4 import Production\n",
    "from htmd.builder.builder import removeLipidsInProtein, tileMembrane, minimalRotation,removeAtomsInHull\n",
    "from moleculekit.util import rotationMatrix, sequenceID, opm\n",
    "from htmd.builder.charmm import _recoverProtonations\n",
    "from htmd.config import config\n",
    "config(viewer='vmd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-03 12:22:34,670 - moleculekit.readers - WARNING - Element guessing failed for atom with name  DUM as the guessed element \"D\" was not found in the periodic table. Check for incorrect column alignment in the PDB file or report to moleculekit issue tracker.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PATH=/home/vitus/miniconda3/bin:/home/vitus/miniconda3/condabin:/home/vitus/bin:/home/vitus/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/home/vitus/bin:/gpcr/users/daranda/doctorat/GPCR_simulations/fake_slurm/:/gpcr/users/daranda/doctorat/GPCR_simulations/fake_slurm/\n"
     ]
    }
   ],
   "source": [
    "####################\n",
    "## Initial variables\n",
    "####################\n",
    "\n",
    "# PDB codes of the GPCRs to be simulated. \n",
    "# If no codes are provided, all avalible structures in GPCRdb will be used (except the ones already simulated)\n",
    "pdb_set = {'6IIU'}\n",
    "\n",
    "# Path to slurm queing system binaries\n",
    "# In our case, Ismael designed a bunch of small bash scripts (fake_slurm) which do ssh to Hydra and execute slurm there\n",
    "slurmpath = '/gpcr/users/daranda/doctorat/GPCR_simulations/fake_slurm/'\n",
    "path= os.environ['PATH']\n",
    "%env PATH=$path:$slurmpath\n",
    "\n",
    "#Path to ACEMD in computation node\n",
    "acemd_path = \"/opt/acellera/miniconda3/bin/acemd3\"\n",
    "    \n",
    "#Paths\n",
    "basepath = '/gpcr/users/daranda/doctorat/GPCR_simulations/'\n",
    "resultspath = basepath + 'simulation_output/'\n",
    "membranepdb = basepath + 'membrane/popc36_box_renumbered.pdb'\n",
    "topparpath = basepath + 'toppar'#toppar= topology+parameters\n",
    "ligandsdict_path = basepath + 'ligands.json'\n",
    "username = 'ameboid'#ameboid\n",
    "password = 'ameboid-123'#ameboid-123\n",
    "\n",
    "# Parameters\n",
    "new_pdb_chain = 'P'\n",
    "membrane_lipid_segid = 'MEM'\n",
    "coldist = 1.3 # Distance bellow which two atoms are considered to collide\n",
    "buffer = 2.4 # Distance between solvation waters and the rest of the system\n",
    "water_thickness = 20 # Size in Z-axis of the solvation water layers\n",
    "membrane_distance = 20 # Distance between the pbc box and the rest of the system atoms, to be filled with membrane\n",
    "water_margin = 4 # Distance in the Z-axis to be penetrated by the solvation box \n",
    "                 # to avoid the formation of a V O I D between the system and the solvation boxes\n",
    "\n",
    "# Dummy pdb: a pdb made of a sinlge non-existant DUM atom.\n",
    "# It is used during removal of aromatic insertions by placing it on the middle of the ring and measuring distances  \n",
    "dummypdb='./dummy.pdb'\n",
    "dummymol = Molecule(dummypdb, validateElements=False)\n",
    "dummy_sel = 'name DUM'\n",
    "\n",
    "# Topologies filenames and paths\n",
    "toposfilenames = ['top_all36_prot.rtf','top_all36_na.rtf','top_all36_lipid.rtf','top_all36_carb.rtf',\\\n",
    "                  'top_all35_ethers.rtf','top_all36_cgenff.rtf']\n",
    "topostreams = ['toppar_water_ions_1.rtf','toppar_ions_won.rtf']\n",
    "streams_folder='stream_splits'\n",
    "topos = [os.path.join(topparpath,file) for file in toposfilenames] + \\\n",
    "        [os.path.join(os.path.join(topparpath,streams_folder),file) for file in topostreams] \n",
    "\n",
    "# Parameters filenames and paths\n",
    "paramsfilenames = ['par_all36m_prot.prm','par_all36_na.prm','par_all36_lipid.prm','par_all36_carb.prm',\\\n",
    "                  'par_all35_ethers.prm','par_all36_cgenff.prm']\n",
    "paramsstreams = ['toppar_water_ions_1.inp','toppar_water_ions_2.inp']\n",
    "params = [os.path.join(topparpath,file) for file in paramsfilenames] + \\\n",
    "         [os.path.join(os.path.join(topparpath,streams_folder),file) for file in paramsstreams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "## David's functions\n",
    "####################\n",
    "def ligands_by_system(ligandsdict):\n",
    "    \"\"\"\n",
    "    Creates a json with all the systems codes and their ligand molecules \n",
    "    \"\"\"\n",
    "    with open('ligands_by_system_new.json', 'w') as ou:\n",
    "        dasdict = {}\n",
    "        for pdb in ligandsdict:\n",
    "            dasdict[pdb] = list(ligandsdict[pdb].keys())\n",
    "        json.dump(dasdict, ou, indent= 4)\n",
    "\n",
    "def json_dict(path):\n",
    "    \"\"\"\n",
    "    Converts json file to pyhton dict.\n",
    "    \"\"\"\n",
    "    json_file=open(path)\n",
    "    json_str = json_file.read()\n",
    "    json_data = json.loads(json_str)\n",
    "    return json_data\n",
    "\n",
    "def get_GPCRdb_nonsimulated():\n",
    "    \"\"\"\n",
    "    Returns a list of PDB codes from the GPCRdb refined structures not yet simulated in GPCRmd\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get current GPCRdb data into a Json\n",
    "    gpcrdb_data = requests.get('http://gpcrdb.org/services/structure/').json()\n",
    "\n",
    "    #Make set with the pdb codes of the structures in GPCRdb\n",
    "    gpcrdb_pdbs = { struc['pdb_code'] for struc in gpcrdb_data }\n",
    "\n",
    "    # Load a random name-to-dyn json from contactmaps\n",
    "    # This Jsons contain a dictionary with the dynIDs and the full names of the GPCR simulated\n",
    "    # This way I can get all the pdb codes of the GPCRs presents in GPCRmd\n",
    "    response = requests.get('http://submission.gpcrmd.org/dynadb/files/Precomputed/get_contacts_files/contmaps_inputs/all/cmpl/lg/name_to_dyn_dict.json')\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    gpcrmd_sims = json.loads(str(soup))\n",
    "\n",
    "    # Take the pdb code from each full name in the json, and store in set\n",
    "    gpcrmd_pdbs = set()\n",
    "    pdb_pat = re.compile('\\((\\w+).*\\) \\(.*\\)$')# Take objects whatever is inside of the first parenthesis\n",
    "    for sim in gpcrmd_sims:\n",
    "        match_pdb = re.search(pdb_pat, sim[1])\n",
    "        if match_pdb:\n",
    "            gpcrmd_pdbs.add(match_pdb.group(1))\n",
    "\n",
    "    # Get to-be-simulated GPCR pdbs. That is the ones that are in GPCRdb but not in GPCRmd\n",
    "    not_simulated = gpcrdb_pdbs - gpcrmd_pdbs\n",
    "\n",
    "    return not_simulated\n",
    "\n",
    "def download_GPCRdb_structures(pdb_set, basepath):\n",
    "    \"\"\"\n",
    "    Download (if they exist) the refined GPCRdb structures for the pdb codes in the pdb_set.\n",
    "    PDB codes without a refined structure will be removed from pdb_set\n",
    "    \"\"\"\n",
    "    pdb_set_nonrefined = set()\n",
    "    set_length = len(pdb_set)\n",
    "    i = 0\n",
    "    for pdbcode in pdb_set:\n",
    "        simdir = basepath+'/data_sim/'+pdbcode+'/'\n",
    "        os.makedirs(simdir, exist_ok = True)\n",
    "        i += 1\n",
    "        \n",
    "        print('Downloading %s structure (%d/%d)' % (pdbcode, i, set_length))\n",
    "        # If files for this simulation already exists\n",
    "        if glob(simdir+'*pdb'):\n",
    "            print('Structure for %s already present. Skipping...' % pdbcode)\n",
    "        else:\n",
    "            response = requests.get('https://gpcrdb.org/structure/homology_models/'+pdbcode+'_refined/download_pdb', stream=True)\n",
    "            if response.ok:\n",
    "                zippy = zipfile.ZipFile(io.BytesIO(response.content))\n",
    "                zippy.extractall(simdir)\n",
    "            else:\n",
    "                pdb_set_nonrefined.add(pdbcode)\n",
    "                print('could not download %s refined structure. Skipping...' % (pdbcode))\n",
    "    \n",
    "    #Remove non-refined structrues\n",
    "    pdb_set = pdb_set - pdb_set_nonrefined\n",
    "    \n",
    "    return pdb_set\n",
    "\n",
    "def ligand_dictionary(pdb_set, ligandsdict_path):\n",
    "    \"\"\"\n",
    "    Create dictionary with ligand names and ligand ResNames of each of the structures we need to simulate,\n",
    "    and store the resutls in a json file\n",
    "    \"\"\"\n",
    "    # Read existing ligands dictionary, or create it if it does not exists yet \n",
    "    if os.path.exists(ligandsdict_path):\n",
    "        ligandsdict = json_dict(ligandsdict_path)\n",
    "    else:\n",
    "        ligandsdict = {}\n",
    "\n",
    "    # Iterate over non-yet-simulated structures, and get their ligand information from rcsb (PDB's web api)    \n",
    "    for pdb_code in pdb_set:\n",
    "        #Do not repeat simulations\n",
    "        if pdb_code in ligandsdict:\n",
    "            continue\n",
    "        else:\n",
    "            ligandsdict[pdb_code] = {}\n",
    "            response = requests.get('https://www.rcsb.org/pdb/rest/customReport.xml?pdbids='+pdb_code+'&customReportColumns=ligandId,ligandName')\n",
    "            ligand_tree = ET.fromstring(response.content)\n",
    "            for ligand in ligand_tree:\n",
    "                ligandResname = ligand.find('dimEntity.ligandId').text\n",
    "                ligandName = ligand.find('dimEntity.ligandName').text\n",
    "                if ligandResname == 'null':\n",
    "                    continue\n",
    "                else:\n",
    "                    ligandsdict[pdb_code][ligandResname] = ligandName\n",
    "\n",
    "    with open(ligandsdict_path, 'w') as jsonfile:\n",
    "        json.dump(ligandsdict, jsonfile, ensure_ascii=False, indent = 4)            \n",
    "    \n",
    "    # Create ligands set from previou dictionary\n",
    "    ligandsset = { ligcode  for pdbcode in ligandsdict for ligcode in ligandsdict[pdbcode] }\n",
    "        \n",
    "    return(ligandsdict, ligandsset)\n",
    "\n",
    "def extract_ligands(ligandsdict, basepath):\n",
    "    \"\"\"\n",
    "    Extract ligands from the refined structure PDB and convert htem to a mol2 file\n",
    "    \"\"\"\n",
    "    \n",
    "    obConversion = openbabel.OBConversion()\n",
    "    obConversion.SetInAndOutFormats(\"pdb\", \"mol2\")\n",
    "\n",
    "    # Iterate over ligands\n",
    "    for system in ligandsdict:\n",
    "    #for system in ['6MEO']:\n",
    "    \n",
    "        # Skip if structure of this system is not avalible\n",
    "        syspdb_path_list = glob(str(\"%sdata_sim/%s/*pdb\" % (basepath,system)))\n",
    "        if len(syspdb_path_list) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            syspdb_path = syspdb_path_list[0]\n",
    "            \n",
    "        for ligcode in ligandsdict[system]:\n",
    "        #for ligcode in ['TYS']:\n",
    "            ligpath = basepath+\"Ligands/\"+ligcode+\"/\"\n",
    "            #Skip if ligand has already been download\n",
    "            if os.path.exists(ligpath):\n",
    "                continue\n",
    "            else:\n",
    "                # Directory for ligands\n",
    "                os.makedirs(ligpath, exist_ok=True)\n",
    "\n",
    "                # Take ligand PDB from inside the GPCR system PDB\n",
    "                syspdb_path = glob(str(\"%sdata_sim/%s/*pdb\" % (basepath,system)))[0]\n",
    "                ligpdb_path = ligpath + \"ligand.pdb\"\n",
    "                ligpdb = open(ligpdb_path, 'w')\n",
    "                atomnames = set()\n",
    "                with open(syspdb_path, 'r') as syspdb:\n",
    "                    for line in syspdb:\n",
    "                        resname = line[17:20]\n",
    "                        if resname == ligcode:\n",
    "                            atomname = line[13:20]\n",
    "                            if atomname not in atomnames:# If there are two or more molecules of one ligand, take only one \n",
    "                                ligpdb.write(line)\n",
    "                                atomnames.add(atomname)\n",
    "                ligpdb.close()\n",
    "\n",
    "                #Convert SDF to mol2, and save mol2 in corresponding folder\n",
    "                ligand_mol2 = openbabel.OBMol()\n",
    "                ligand_mol2.AddHydrogens()\n",
    "                obConversion.ReadFile(ligand_mol2, ligpdb_path)\n",
    "                ligand_mol2.AddHydrogens()\n",
    "                ligandmol_string = obConversion.WriteString(ligand_mol2)\n",
    "                \n",
    "                # Change name of molecule in mol2\n",
    "                with open(ligpath+\"ligand.mol2\", 'w') as ligandmol_file:\n",
    "                    ligandmol_file.write(ligandmol_string.replace(ligpdb_path, ligcode))\n",
    "                    \n",
    "def get_lig_toppar(ligandsset, basepath, username, password):\n",
    "    \"\"\"\n",
    "    Get the topology-parameters string file from paramchem for the submited ligand PDB codes\n",
    "    ALERT: paramchem only allows 100 submissions by month, so it may be possible that not all \n",
    "    parameters are obtained\n",
    "    \"\"\"\n",
    "    \n",
    "    #Get total number of ligands\n",
    "    i = 0\n",
    "    total_ligs = len(ligandsset)\n",
    "    #Pattern to find non-HTMD-compatible lines\n",
    "    lph_pat = re.compile('^ATOM.*LPH|LONEPAIR')\n",
    "    \n",
    "    # Iterate over ligands\n",
    "    for ligcode in ligandsset:\n",
    "        i += 1\n",
    "        print('Getting toppar file for ligand %s (%d/%d)' % (ligcode, i, total_ligs))\n",
    "\n",
    "        # topology-parametetrs file output\n",
    "        topparfile_path = basepath+\"Ligands/\"+ligcode+\"/toppar.str\"\n",
    "        # Errors and warnings file output\n",
    "        erwar_path = basepath+\"Ligands/\"+ligcode+\"/paramchem_stder.txt\"\n",
    "        #Open ligandfile to upload in paramchem\n",
    "        ligfile = open(basepath+\"Ligands/\"+ligcode+\"/ligand.mol2\")\n",
    "        myfile = {\n",
    "                'filename': ligfile\n",
    "        }\n",
    "        myparam = {\n",
    "                #'param_a': 'a' #Include parameters usually included in newer versions of CGenff (versions that we cant use)\n",
    "                #'param_c': 'c'# Use CGenFF legacy v1.0, for HTMD is not yet prepared for newer Charmm versions             \n",
    "        }\n",
    "\n",
    "        # Omit ligand if its toppar file already exists\n",
    "        if os.path.exists(topparfile_path):\n",
    "            print('toppar for ligand %s already exists. Skipping...' % ligcode)\n",
    "            continue\n",
    "        else:\n",
    "            # Define POST variables for login in Paramchem\n",
    "            datalogin = {\n",
    "                'usrName': username,\n",
    "                'curPwd': password,\n",
    "                'rndNo': str(random.randrange(100000000, 999999999)),\n",
    "                'submitBtn': 'Submit',\n",
    "            }\n",
    "            # Open web session\n",
    "            with requests.Session() as s:\n",
    "\n",
    "                # Login into paramchem\n",
    "                response_login = s.post('http://cgenff.umaryland.edu/userAccount/userWelcome.php', \n",
    "                           data=datalogin,\n",
    "                           verify=False)\n",
    "\n",
    "                # Submit our ligand molecule into paramchem\n",
    "                response_upload = s.post('http://cgenff.umaryland.edu/initguess/processdata.php', \n",
    "                           files = myfile,\n",
    "                           data = myparam,\n",
    "                            )\n",
    "\n",
    "                # Download Topology-parameters of our molecule file from paramchem, and store it.\n",
    "                # But remember submissions in paramchem are limited weekly\n",
    "                # Download also stderr, just in case\n",
    "                match = re.search('<path>(\\w+)</path>', response_upload.text)\n",
    "                if match:\n",
    "                    code = match.group(1)\n",
    "                    response_ligfile = s.get('http://cgenff.umaryland.edu/initguess/filedownload.php?file='+code+'/ligand.str')\n",
    "                    response_stder = s.get('https://cgenff.umaryland.edu/initguess/filedownload.php?file='+code+'/ligand.err')\n",
    "                    with open(topparfile_path, 'wb') as topparfile:\n",
    "                            topparfile.write(response_ligfile.content)\n",
    "                    with open(erwar_path, 'wb') as erwar:\n",
    "                            erwar.write(response_stder.content)                            \n",
    "                else:\n",
    "                    print('Your paramchem account has reached its weekly submission limit. Please, intrudce a new account or wait to the next monday to continue')            \n",
    "                    return\n",
    "                \n",
    "                #Delete lines with LPH (new feature from CHARMM not tolerated by HTMD)\n",
    "                with open(topparfile_path, \"r\") as f:\n",
    "                    lines = f.readlines()\n",
    "                with open(topparfile_path, \"w\") as f:\n",
    "                    for line in lines:\n",
    "                        if not re.match(lph_pat, line):\n",
    "                            f.write(line)\n",
    "\n",
    "def remove_artifacts(pdbcode, mol, ligdict, accepted_ligdict):\n",
    "    \"\"\"\n",
    "    Remove any small molecules included in ligdict but not in ligdict.\n",
    "    The intention is to remove unnecessary small molecules, like detergents \n",
    "    or ligands from removed parts of the protein\n",
    "    \"\"\"\n",
    "    tofilter = \"\"\n",
    "    for smalmol in ligdict[pdbcode]:\n",
    "        print(smalmol)\n",
    "        if smalmol not in accepted_ligdict[pdbcode]:\n",
    "            print('no '+smalmol)\n",
    "            tofilter += smalmol + \" \"\n",
    "    gpcrdb_mol.filter('not resname '+tofilter)\n",
    "    return gpcrdb_mol\n",
    "                            \n",
    "#####################\n",
    "## Ismael's Functions\n",
    "#####################\n",
    "\n",
    "def renumber_resid_vmd(mol,sel,by=3,start=1):\n",
    "    import tempfile\n",
    "    tmpin = tempfile.NamedTemporaryFile(suffix='.pdb')\n",
    "    mol.write(tmpin.name)\n",
    "    viewer = getCurrentViewer(dispdev='text')\n",
    "    viewer.send('set molid [mol new {%s}]' % tmpin.name)\n",
    "    tmpin.close()\n",
    "    tmpout = tempfile.NamedTemporaryFile(suffix='.pdb')\n",
    "    option_num = 2\n",
    "    max_value = 2**option_num - 1\n",
    "    if by > max_value:\n",
    "        raise ValueError('Maximum value for \"by\" keyword is %d.' % max_value)\n",
    "    if by < 1:\n",
    "        raise ValueError('Minimum value for \"by\" keyword is \"1\".')\n",
    "    bin_by = format(by,'0'+str(option_num)+'b')\n",
    "    option_array = [bool(int(i)) for i in bin_by]\n",
    "    by_segid = option_array[0]\n",
    "    by_resname = option_array[1]\n",
    "   \n",
    "    \n",
    "    if by_segid:\n",
    "        segids = set(mol.get('segid',sel=sel))      \n",
    "        for segid in segids:\n",
    "            if by_resname:\n",
    "                resnames = set(mol.get('resname',sel='(%s) and segid %s' % (sel,segid)))\n",
    "                for resname in resnames:\n",
    "                    lsel = '(%s) and (segid %s) and (resname %s)' % (sel,segid,resname)\n",
    "                    viewer = renumber_resid_by_resid_vmd(lsel,mol,viewer,start=start)\n",
    "            else:\n",
    "                lsel = '(%s) and (segid %s)' % (sel,segid)\n",
    "                viewer = renumber_resid_by_resid_vmd(lsel,mol,viewer,start=start)\n",
    "    else:                      \n",
    "        resnames = set(mol.get('resname',sel=sel))\n",
    "        for resname in resnames:\n",
    "            lsel = '(%s) and (resname %s)' % (sel,resname)\n",
    "            viewer = renumber_resid_by_resid_vmd(lsel,mol,viewer,start=start)       \n",
    "    viewer.send('animate write pdb {%s} waitfor all top;exit' % tmpout.name)\n",
    "    newmol = Molecule(tmpout.name)\n",
    "    tmpout.close()\n",
    "    return newmol\n",
    "\n",
    "def renumber_resid_by_resid_vmd(sel,mol,viewer,start=1):\n",
    "    resids = sorted(list(set(mol.get('resid',sel=sel))))\n",
    "    resids = [str(i) for i in resids]\n",
    "    viewer.send('proc renum_resid {molid} {set newresid %d; set resids {%s};' % (start,' '.join(resids)) + \\\n",
    "                'set asall [atomselect $molid [concat {(%s) and resid } $resids]];' % sel + \\\n",
    "                '$asall set user 1.00;' + \\\n",
    "                'foreach resid $resids {' + \\\n",
    "                'set as [atomselect $molid [concat {user 1.00 and (%s) and resid } $resid]];' % sel + \\\n",
    "                '$as set resid $newresid; $as set user 0.00; incr newresid}};'+'renum_resid $molid')\n",
    "    return viewer\n",
    "\n",
    "def ordered_unique(seq):\n",
    "    seen = set()\n",
    "    return [x for x in seq if not (x in seen or seen.add(x))]\n",
    "\n",
    "def renumber_segments(inputmol,segids,prefix):\n",
    "    sel = 'segid '+' '.join(segids)\n",
    "    segids = ordered_unique(inputmol.get('segid',sel=sel))\n",
    "    if prefix in segids:\n",
    "        raise ValueError('segid %s already exists.' % prefix)\n",
    "        \n",
    "    mol = renumber_resid_vmd(inputmol,sel,by=2)\n",
    "    # change first segid segment as it is properly renumbered already\n",
    "    mol.set('segid',prefix,sel='segid '+segids[0])\n",
    "\n",
    "    if len(segids) > 1:\n",
    "        # initialize variables for second segid\n",
    "        curr_segid = prefix\n",
    "        # get last resid for first segid\n",
    "        idx_curr_segid = mol.atomselect('segid '+curr_segid)\n",
    "        prev_resid = len(set(mol.resid[idx_curr_segid]))\n",
    "        k = 0\n",
    "        for segid in segids[1:]:\n",
    "            \n",
    "            # get last current resid\n",
    "            idx_segid = mol.atomselect('segid '+segid)\n",
    "            curr_resid = len(set(mol.resid[idx_segid])) + prev_resid\n",
    "            if curr_resid <= 9999:\n",
    "                # join segments resuming the previous resid numbering\n",
    "                mol = renumber_resid_vmd(mol,'segid '+segid,start=prev_resid+1,by=2)\n",
    "                mol.segid[idx_segid] = curr_segid\n",
    "                # get last resid of the current segid for the next loop iteration\n",
    "                prev_resid = curr_resid\n",
    "            else:\n",
    "\n",
    "                # join segments resuming the previous resid numbering up to resid 9999\n",
    "                sel1 = 'segid '+segid+' and resid <= '+str(9999-prev_resid)\n",
    "                mol = renumber_resid_vmd(mol,sel1,start=prev_resid+1,by=2)\n",
    "                mol.set('segid',curr_segid,sel=sel1)\n",
    "                # define next new segment with resids > 9999\n",
    "                k +=1\n",
    "                curr_segid = prefix+str(k)\n",
    "                if curr_segid in segids:\n",
    "                    raise ValueError('segid %s already exists.' % curr_segid)\n",
    "                # resid <= 9999 still preserve the old segid\n",
    "                idx_curr_segid = mol.atomselect('segid '+segid)\n",
    "                mol.segid[idx_curr_segid] = curr_segid\n",
    "                # get last resid of the current segid for the next loop iteration\n",
    "                mol = renumber_resid_vmd(mol,'segid '+curr_segid,by=2)\n",
    "                prev_resid = len(set(mol.resid[idx_curr_segid]))\n",
    "            \n",
    "        if k > 0:\n",
    "            if prefix+str(0) in segids:\n",
    "                print('WARNING: segid %s already exists, using %s instead.' % (prefix,prefix+str(0)))\n",
    "            else:\n",
    "                mol.segid[mol.segid == prefix] = prefix+str(0)\n",
    "        \n",
    "    return mol\n",
    "\n",
    "def renumber_resid_by_resid(sel,inputmol,ordered=False):\n",
    "    mol = inputmol.copy()\n",
    "    resids = list(set(mol.get('resid',sel=sel)))\n",
    "    if ordered:\n",
    "        resids = sort(resids)\n",
    "    newresid = 1\n",
    "    for resid in resids:\n",
    "        mol.set('resid',newresid,sel='(%s) and (resid %s)' % (sel,resid))\n",
    "        newresid += 1\n",
    "    return mol\n",
    "\n",
    "def renumber_resid(inputmol,sel,by=3):\n",
    "    \n",
    "    # Long story short: by=1 -> by_resname; by=2 -> by_segid; by=3 -> by_segid and by_resname\n",
    "    # WTF!!!!\n",
    "    mol = inputmol.copy()\n",
    "    option_num = 2\n",
    "    max_value = 2**option_num - 1\n",
    "    if by > max_value:\n",
    "        raise ValueError('Maximum value for \"by\" keyword is %d.' % max_value)\n",
    "    if by < 1:\n",
    "        raise ValueError('Minimum value for \"by\" keyword is \"1\".')\n",
    "    bin_by = format(by,'0'+str(option_num)+'b')\n",
    "    option_array = [bool(int(i)) for i in bin_by]\n",
    "    by_segid = option_array[0]\n",
    "    by_resname = option_array[1]\n",
    "    \n",
    "    if by_segid:\n",
    "        segids = set(mol.get('segid',sel=sel))      \n",
    "        for segid in segids:\n",
    "            if by_resname:\n",
    "                resnames = set(mol.get('resname',sel='(%s) and segid %s' % (sel,segid)))\n",
    "                for resname in resnames:\n",
    "                    lsel = '(%s) and (segid %s) and (resname %s)' % (sel,segid,resname)\n",
    "                    mol = renumber_resid_by_resid(lsel,mol)\n",
    "            else:\n",
    "                lsel = '(%s) and (segid %s)' % (sel,segid)\n",
    "                mol = renumber_resid_by_resid(lsel,mol)\n",
    "    else:                      \n",
    "        resnames = set(mol.get('resname',sel=sel))\n",
    "        for resname in resnames:\n",
    "            lsel = '(%s) and (resname %s)' % (sel,resname)\n",
    "            mol = renumber_resid_by_resid(lsel,mol)\n",
    "    return mol\n",
    "\n",
    "def fix_and_prepare_input(inputmol,first='NTER',last='CTER'):\n",
    "    \"\"\"\n",
    "    ISMAEL FUNCTION\n",
    "    Establish homogeneus nomenclature for protein residue names and segments for the system.\n",
    "    \"\"\"\n",
    "    \n",
    "    mol = inputmol.copy()\n",
    "    aa= 'ALA ARG ASN ASP CYS GLU GLN GLY HIS ILE LEU LYS MET PHE PRO SER THR TRP TYR VAL'\n",
    "    mol.set('segid','WAT',sel='water')\n",
    "    mol.set('resname','TIP3',sel='water')\n",
    "    mol.set('chain','X',sel='resname TIP3')\n",
    "    mol.set('name','OH2',sel='resname TIP3 and name OW')\n",
    "    mol.set('name','H1',sel='resname TIP3 and name HW1')\n",
    "    mol.set('name','H2',sel='resname TIP3 and name HW2')\n",
    "    mol.remove('(protein or resname '+aa+') and name O1 O2')\n",
    "    if first == 'NTER':\n",
    "        mol.set('name','HT1',sel='(protein or resname '+aa+')and name H1')\n",
    "        mol.set('name','HT2',sel='(protein or resname '+aa+') and name H2')\n",
    "        mol.set('name','HT3',sel='(protein or resname '+aa+') and name H3')\n",
    "    else:\n",
    "        mol.remove('(protein or resname '+aa+')and name H1 H2 H3')\n",
    "    if last in {'CTER','CNEU','CTP','CT1'}:\n",
    "        mol.set('name','OT1',sel='(protein or resname '+aa+') and name O1')\n",
    "        mol.set('name','OT2',sel='(protein or resname '+aa+') and name O2')\n",
    "        #fix\n",
    "        mol.remove('(protein or resname '+aa+') and name OT2')\n",
    "    else:\n",
    "        mol.set('name','O',sel='(protein or resname '+aa+') and name O1')\n",
    "        mol.remove('(protein or resname '+aa+') and name O2')\n",
    "    mol.set('name','HG1',sel='resname CYS and name HG')\n",
    "    mol.set('name','HN',sel='resname HIS and name H')\n",
    "    \n",
    "    his_he_resids = mol.get('resid',sel='resname HIS and name HE2')\n",
    "    his_he_chains = mol.get('chain',sel='resname HIS and name HE2')\n",
    "    his_he_ids = set([':'.join((chain,str(resid))) for resid,chain in zip(his_he_resids,his_he_chains)])\n",
    "    his_hd_resids = mol.get('resid',sel='resname HIS and name HD1')\n",
    "    his_hd_chains = mol.get('chain',sel='resname HIS and name HD1')\n",
    "    his_hd_ids = set([':'.join((chain,str(resid))) for resid,chain in zip(his_hd_resids,his_hd_chains)])\n",
    "    hsd_ids = his_hd_ids.difference(his_he_ids)\n",
    "    hse_ids = his_he_ids.difference(his_hd_ids)\n",
    "    hsp_ids = his_hd_ids.intersection(his_he_ids)\n",
    "    \n",
    "    hsd_dict = dict()\n",
    "    hse_dict = dict()\n",
    "    hsp_dict = dict()\n",
    "    \n",
    "    for chain,resid in [ id1.split(':') for id1 in hsd_ids]:\n",
    "        if chain not in hsd_dict:\n",
    "            hsd_dict[chain] = []\n",
    "        hsd_dict[chain].append(resid)\n",
    "    for chain,resid in [ id1.split(':') for id1 in hse_ids]:\n",
    "        if chain not in hse_dict:\n",
    "            hse_dict[chain] = []\n",
    "        hse_dict[chain].append(resid)\n",
    "    for chain,resid in [ id1.split(':') for id1 in hsp_ids]:\n",
    "        if chain not in hsp_dict:\n",
    "            hsp_dict[chain] = []\n",
    "        hsp_dict[chain].append(resid)\n",
    "        \n",
    "    for chain in hsd_dict:\n",
    "        sel1 = 'resname HIS and chain '+chain+' and resid '+' '.join(hsd_dict[chain])\n",
    "        mol.set('resname','HSD',sel=sel1)\n",
    "    for chain in hse_dict:\n",
    "        sel1 = 'resname HIS and chain '+chain+' and resid '+' '.join(hse_dict[chain])\n",
    "        mol.set('resname','HSE',sel=sel1)\n",
    "    for chain in hsp_dict:\n",
    "        sel1 = 'resname HIS and chain '+chain+' and resid '+' '.join(hsp_dict[chain])\n",
    "        mol.set('resname','HSP',sel=sel1)\n",
    "    mol = autoSegment(mol,sel='protein or resname '+aa)\n",
    "    mol.set('segid','LIG',sel='not (protein or resname '+aa+') and not water and not ions')\n",
    "    mol.set('chain','L',sel='segid LIG')\n",
    "    mol.set('segid','ION',sel='ions')\n",
    "    mol.set('chain','N',sel='segid ION')\n",
    "    protsegids = set(mol.get('segid',sel='protein'))\n",
    "    mol = renumber_resid(mol,'water',by=1)\n",
    "    mol = renumber_resid(mol,'ions',by=1)\n",
    "    mol = renumber_resid(mol,'segid LIG',by=2)\n",
    "    return (mol,protsegids)\n",
    "    #    for segid in protsegids:\n",
    "    #        resids = set(mol.get('resid',sel='segid '+segid))\n",
    "    #        for resid in resids:\n",
    "    #            resname = mol.get('resname',sel='resid '+str(resid)+' and segid '+segid)[0]\n",
    "    #            chain = mol.get('chain',sel='resid '+str(resid)+' and segid '+segid)[0]\n",
    "    #            mol.set('segid',segid,sel='resname '+resname+' and chain '+chain+' and resid '+str(segid))\n",
    "\n",
    "def add_membrane(pdbmol,membranemol,protsegids,membrane_distance,coldist=1.3):\n",
    "    # Corrections for rotational difusion\n",
    "    prot = pdbmol.copy()\n",
    "    protsel = 'segid '+' '.join(protsegids)\n",
    "    prot.filter(protsel,_logger=False)\n",
    "    r = minimalRotation(prot)\n",
    "    M = rotationMatrix([0, 0, 1], r)\n",
    "    pdbmol.rotateBy(M)\n",
    "    pcoor = pdbmol.get('coords',sel=protsel)\n",
    "    Mcoor = np.max(pcoor,axis=0)\n",
    "    mcoor = np.min(pcoor,axis=0)\n",
    "    # get the diagonal of XY of the protein if XY is a square \n",
    "    # which side is as long as the largest side (between X and Y) from the protein box  \n",
    "    p_dim = [Mcoor[0] - mcoor[0],Mcoor[1] - mcoor[1]]\n",
    "    maxXY = np.sqrt(p_dim[0]**2+p_dim[1]**2)\n",
    "    minimum_box_size_x = maxXY+2\n",
    "    minimum_box_size_y = minimum_box_size_x\n",
    "    \n",
    "    \n",
    "    # get min max coor of the system\n",
    "    minc = np.min(pdbmol.coords, axis=0).flatten()\n",
    "    maxc = np.max(pdbmol.coords, axis=0).flatten()\n",
    "    \n",
    "    system_size_x = maxc[0] - minc[0]\n",
    "    system_size_y = maxc[1] - minc[1]\n",
    "    \n",
    "    center_x = system_size_x/2 + minc[0]\n",
    "    center_y = system_size_y/2 + minc[1]\n",
    "    \n",
    "    system_size = np.max([system_size_x,system_size_y])\n",
    "    print(str(minimum_box_size_x),str(system_size))\n",
    "    corr_system_size_x = np.max([minimum_box_size_x,system_size]) \n",
    "    corr_system_size_y = np.max([minimum_box_size_y,system_size])\n",
    "    \n",
    "    addmembdist = membrane_distance/2.0+np.max([coldist,1.5])+0.0\n",
    "    \n",
    "    xlim = [center_x-corr_system_size_x/2-addmembdist,center_x+corr_system_size_x/2+addmembdist]\n",
    "    ylim = [center_y-corr_system_size_y/2-addmembdist,center_y+corr_system_size_y/2+addmembdist]\n",
    "    \n",
    "    memb = membranemol.copy()\n",
    "    memb.remove('ions',_logger=False)\n",
    "    memb2 = tileMembrane(memb, xlim[0], ylim[0], xlim[1], ylim[1])\n",
    "    \n",
    "    #from tileMembrane\n",
    "    size = np.max(membranemol.get('coords', 'water'), axis=0) - np.min(membranemol.get('coords', 'water'), axis=0)\n",
    "    xreps = int(np.ceil((xlim[1] - xlim[0]) / size[0]))\n",
    "    yreps = int(np.ceil((ylim[1] - ylim[0]) / size[1]))\n",
    "    \n",
    "    membtmp_segids = ordered_unique(memb2.get('segid'))\n",
    "    k=0\n",
    "    for segid in membtmp_segids:\n",
    "    #    memb2.set('segid','M'+str(k),sel='segid '+segid+' and not waters')\n",
    "         memb2.set('segid','W'+str(k),sel='segid '+segid+' and waters')\n",
    "         k += 1\n",
    "            \n",
    "    memb2 = renumber_segments(memb2,set(memb2.get('segid',sel='waters')),'MW')\n",
    "    memb2 = renumber_segments(memb2,set(memb2.get('segid',sel='not waters')),'MEM')\n",
    "    membrane_resnames = set(memb2.get('resname'))\n",
    "    membrane_segids = set(memb2.get('segid'))\n",
    "    \n",
    "    mcenter = np.mean(memb2.get('coords',sel='segid MEM'),axis=0)\n",
    "    memb2.moveBy(-mcenter)\n",
    "\n",
    "    memb2, num = removeLipidsInProtein(pdbmol, memb2,lipidsel='lipids or waters')\n",
    "    \n",
    "    mol = pdbmol.copy()\n",
    "    mol.append(memb2, collisions=True,coldist=coldist)\n",
    "    \n",
    "    return (mol, membrane_resnames,membrane_segids,xreps,yreps)\n",
    "\n",
    "def solvate_pdbmol(mol,membrane_segids,water_thickness,water_margin,buffer=2.4,coldist=1.3,prefix='W'):\n",
    "    waterbox = mol.get('coords','(waters or ions) and segid '+' '.join(membrane_segids))\n",
    "    mwaterbox = np.min(waterbox, axis=0)\n",
    "    Mwaterbox = np.max(waterbox, axis=0)\n",
    "    coo = mol.get('coords','not (waters or ions)')\n",
    "    mcoo = np.min(coo, axis=0)\n",
    "    Mcoo = np.max(coo, axis=0)\n",
    "    cooall = mol.get('coords','all')\n",
    "    mcooall = np.min(coo, axis=0)\n",
    "    Mcooall = np.max(coo, axis=0)\n",
    "    #top layer\n",
    "    M1z = Mcoo[2] + water_thickness/2. + np.max((coldist,buffer)) - buffer\n",
    "    m1z = Mwaterbox[2] - water_margin\n",
    "    M1 = [Mwaterbox[0],Mwaterbox[1],M1z]\n",
    "    m1 = [mwaterbox[0],mwaterbox[1],m1z]\n",
    "    \n",
    "    #bottom layer\n",
    "    M2z = mwaterbox[2] + water_margin\n",
    "    m2z = mcoo[2] - water_thickness/2.- np.max((coldist,buffer)) + buffer\n",
    "    M2 = [Mwaterbox[0],Mwaterbox[1],M2z]\n",
    "    m2 = [mwaterbox[0],mwaterbox[1],m2z]\n",
    "\n",
    "    smol = solvate(mol, minmax=np.vstack((m2,M1)),prefix=prefix,buffer=buffer)\n",
    "\n",
    "    smol, num_remove = removeAtomsInHull(smol, smol, 'name CA', 'segid \"'+prefix+'[0-9]+\"')\n",
    "    #wtsegids = set(smol.get('segid',sel='segid \"%s.*\"'% prefix))\n",
    "    #for segid in wtsegids:\n",
    "        #smol.remove('segid %s and same resid as ( z > %g and z < %g)' % (segid,M2[2],m1[2]),_logger=False)\n",
    "\n",
    "    return smol\n",
    "\n",
    "def add_dummy_atom(inputmol,property_dict):\n",
    "    mol = inputmol.copy()\n",
    "    dummymol1 = dummymol.copy()\n",
    "    for prop in property_dict:\n",
    "        dummymol1.set(prop,property_dict[prop])\n",
    "    mol.append(dummymol1,coldist=None)\n",
    "    return mol\n",
    "def add_center_dummy_atom(inputmol,coords,property_dict):\n",
    "    mol = inputmol.copy()\n",
    "    center = np.mean(coords,axis=0)\n",
    "    property_dict['coords'] = center\n",
    "    mol = add_dummy_atom(mol,property_dict)\n",
    "    return mol\n",
    "def remove_aromatic_insertions(inputmol,protsegids,coldist=1.5,outpdb=None):\n",
    "    mol = inputmol.copy()\n",
    "    atoms_data = [['TRP','CG CD1 CE1 NE1 CE2 CD2',5,'1'],\n",
    "                 ['TRP','CD2 CE2 CZ2 CH2 CZ3 CE3',6,'2'],\n",
    "                 ['PRO','N CA CB CG CD',5,''],\n",
    "                 ['HIS HSD HSE HSP HID HIE HIP',\n",
    "                  'CG CD1 CE1 CZ CE2 CD2 ND1 NE2',5,''],\n",
    "                 ['PHE TYR TYM',\n",
    "                  'CG CD1 CE1 CZ CE2 CD2',6,'']]\n",
    "    beta_backup = np.copy(mol.beta)\n",
    "    mol.set('beta',sequenceID((mol.resid, mol.insertion, mol.segid)))    \n",
    "    \n",
    "    for atom_data in atoms_data:\n",
    "        atom_step = atom_data[2]\n",
    "        suffix = atom_data[3]\n",
    "        sel = 'resname %s and name %s' % (atom_data[0],atom_data[1])\n",
    "        idxs = mol.get('index',sel=sel)\n",
    "        resnames = mol.resname[idxs]\n",
    "        resids = mol.resid[idxs]\n",
    "        segids = mol.segid[idxs]\n",
    "        coords = mol.coords[idxs,:,0]\n",
    "        atom_num = len(idxs)\n",
    "        if atom_num % atom_step != 0:\n",
    "            raise ValueError('Missing atoms.')\n",
    "        for i in range(0,atom_num,atom_step):\n",
    "            property_dict = {'resname':resnames[i]+suffix,'resid':resids[i],'segid':segids[i]}\n",
    "            mol = add_center_dummy_atom(mol,coords[i:i+atom_step],property_dict)\n",
    "            \n",
    "    if outpdb:\n",
    "        mol.write(outpdb)\n",
    "    var_list = tuple([coldist]+[dummy_sel for i in range(0,3)])\n",
    "    \n",
    "    dummy_atoms_idxs = mol.get('index',sel=dummy_sel)\n",
    "    dummy_atoms_resid = mol.resid[dummy_atoms_idxs]\n",
    "    dummy_atoms_segid = mol.segid[dummy_atoms_idxs]\n",
    "    removed_indexes = []\n",
    "    for idx,resid,segid in zip(dummy_atoms_idxs,dummy_atoms_resid,dummy_atoms_segid):\n",
    "        r_idx1 = mol.get('index', sel='not (%s) and same beta as ((exwithin %g of (index %d)) and not (resid %d and segid %s))'  % (dummy_sel,coldist,idx,resid,segid))\n",
    "        removed_indexes = removed_indexes + r_idx1.tolist()\n",
    "        \n",
    "    if len(removed_indexes) > 0:\n",
    "        removed_indexes_str = ' '.join(str(x) for x in removed_indexes)\n",
    "        mol.remove('index '+removed_indexes_str)\n",
    "    mol.remove(dummy_sel,_logger=False)\n",
    "    inv_idx1 = np.setdiff1d(np.arange(len(beta_backup)), np.array(removed_indexes), assume_unique=True)\n",
    "    mol.beta = beta_backup[inv_idx1]\n",
    "        \n",
    "    print('WARNING: removed '+str(len(removed_indexes))+' atoms within '+str(coldist)+' of a protein aromatic ring')\n",
    "    \n",
    "    return (mol,removed_indexes)\n",
    "\n",
    "def define_equilibration(const_sel):\n",
    "    simtime = 40\n",
    "    restr = AtomRestraint(const_sel, 2, [(0,\"0\"),(1,\"%dns\" % int(simtime*0.5)),(0,\"%dns\" % int(simtime*0.75))], \"xyz\")\n",
    "    md = Equilibration()\n",
    "    md.runtime = simtime\n",
    "    md.timeunits = 'ns'\n",
    "    md.temperature = 310\n",
    "    md.nvtsteps = 0\n",
    "    md.acemd.minimize = 5000\n",
    "    md.acemd.restart = 'off'\n",
    "    md.acemd.timestep = 2\n",
    "    md.restraints = restr\n",
    "    return md\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 5 column 1 (char 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-5acc511b5ef1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdecoded_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'utf-8-sig'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoded_d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \"\"\"\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 5 column 1 (char 4)"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import codecs\n",
    "\n",
    "url = 'http://gpcrdb.org/structure/'\n",
    "response = requests.get(url)\n",
    "decoded_data=codecs.decode(response.text.encode(), 'utf-8-sig')\n",
    "data = json.loads(decoded_d)\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 6IIU structure (1/1)\n",
      "Structure for 6IIU already present. Skipping...\n",
      "Getting toppar file for ligand PGO (1/223)\n",
      "toppar for ligand PGO already exists. Skipping...\n",
      "Getting toppar file for ligand SEP (2/223)\n",
      "toppar for ligand SEP already exists. Skipping...\n",
      "Getting toppar file for ligand 97Y (3/223)\n",
      "toppar for ligand 97Y already exists. Skipping...\n",
      "Getting toppar file for ligand 9XT (4/223)\n",
      "toppar for ligand 9XT already exists. Skipping...\n",
      "Getting toppar file for ligand ID3 (5/223)\n",
      "toppar for ligand ID3 already exists. Skipping...\n",
      "Getting toppar file for ligand NGI (6/223)\n",
      "toppar for ligand NGI already exists. Skipping...\n",
      "Getting toppar file for ligand NA (7/223)\n",
      "toppar for ligand NA already exists. Skipping...\n",
      "Getting toppar file for ligand 7Y9 (8/223)\n",
      "toppar for ligand 7Y9 already exists. Skipping...\n",
      "Getting toppar file for ligand SO4 (9/223)\n",
      "toppar for ligand SO4 already exists. Skipping...\n",
      "Getting toppar file for ligand ALC (10/223)\n",
      "toppar for ligand ALC already exists. Skipping...\n",
      "Getting toppar file for ligand MG (11/223)\n",
      "toppar for ligand MG already exists. Skipping...\n",
      "Getting toppar file for ligand P0G (12/223)\n",
      "toppar for ligand P0G already exists. Skipping...\n",
      "Getting toppar file for ligand YCM (13/223)\n",
      "toppar for ligand YCM already exists. Skipping...\n",
      "Getting toppar file for ligand 9JU (14/223)\n",
      "toppar for ligand 9JU already exists. Skipping...\n",
      "Getting toppar file for ligand CY8 (15/223)\n",
      "toppar for ligand CY8 already exists. Skipping...\n",
      "Getting toppar file for ligand TAR (16/223)\n",
      "toppar for ligand TAR already exists. Skipping...\n",
      "Getting toppar file for ligand ML2 (17/223)\n",
      "toppar for ligand ML2 already exists. Skipping...\n",
      "Getting toppar file for ligand TRS (18/223)\n",
      "toppar for ligand TRS already exists. Skipping...\n",
      "Getting toppar file for ligand SOG (19/223)\n",
      "toppar for ligand SOG already exists. Skipping...\n",
      "Getting toppar file for ligand DL2 (20/223)\n",
      "toppar for ligand DL2 already exists. Skipping...\n",
      "Getting toppar file for ligand 9DT (21/223)\n",
      "toppar for ligand 9DT already exists. Skipping...\n",
      "Getting toppar file for ligand 3C0 (22/223)\n",
      "toppar for ligand 3C0 already exists. Skipping...\n",
      "Getting toppar file for ligand H8G (23/223)\n",
      "toppar for ligand H8G already exists. Skipping...\n",
      "Getting toppar file for ligand PGE (24/223)\n",
      "toppar for ligand PGE already exists. Skipping...\n",
      "Getting toppar file for ligand NI (25/223)\n",
      "toppar for ligand NI already exists. Skipping...\n",
      "Getting toppar file for ligand IXO (26/223)\n",
      "toppar for ligand IXO already exists. Skipping...\n",
      "Getting toppar file for ligand TYS (27/223)\n",
      "toppar for ligand TYS already exists. Skipping...\n",
      "Getting toppar file for ligand 8ES (28/223)\n",
      "toppar for ligand 8ES already exists. Skipping...\n",
      "Getting toppar file for ligand P33 (29/223)\n",
      "toppar for ligand P33 already exists. Skipping...\n",
      "Getting toppar file for ligand FUC (30/223)\n",
      "toppar for ligand FUC already exists. Skipping...\n",
      "Getting toppar file for ligand HTG (31/223)\n",
      "toppar for ligand HTG already exists. Skipping...\n",
      "Getting toppar file for ligand KBY (32/223)\n",
      "toppar for ligand KBY already exists. Skipping...\n",
      "Getting toppar file for ligand 7LD (33/223)\n",
      "toppar for ligand 7LD already exists. Skipping...\n",
      "Getting toppar file for ligand SAR (34/223)\n",
      "toppar for ligand SAR already exists. Skipping...\n",
      "Getting toppar file for ligand EJ4 (35/223)\n",
      "toppar for ligand EJ4 already exists. Skipping...\n",
      "Getting toppar file for ligand PG4 (36/223)\n",
      "toppar for ligand PG4 already exists. Skipping...\n",
      "Getting toppar file for ligand UKA (37/223)\n",
      "toppar for ligand UKA already exists. Skipping...\n",
      "Getting toppar file for ligand A90 (38/223)\n",
      "toppar for ligand A90 already exists. Skipping...\n",
      "Getting toppar file for ligand LMT (39/223)\n",
      "toppar for ligand LMT already exists. Skipping...\n",
      "Getting toppar file for ligand TLA (40/223)\n",
      "toppar for ligand TLA already exists. Skipping...\n",
      "Getting toppar file for ligand 9DK (41/223)\n",
      "toppar for ligand 9DK already exists. Skipping...\n",
      "Getting toppar file for ligand AQD (42/223)\n",
      "toppar for ligand AQD already exists. Skipping...\n",
      "Getting toppar file for ligand DAL (43/223)\n",
      "toppar for ligand DAL already exists. Skipping...\n",
      "Getting toppar file for ligand A2G (44/223)\n",
      "toppar for ligand A2G already exists. Skipping...\n",
      "Getting toppar file for ligand 9DW (45/223)\n",
      "toppar for ligand 9DW already exists. Skipping...\n",
      "Getting toppar file for ligand A4X (46/223)\n",
      "toppar for ligand A4X already exists. Skipping...\n",
      "Getting toppar file for ligand ERM (47/223)\n",
      "toppar for ligand ERM already exists. Skipping...\n",
      "Getting toppar file for ligand 8TZ (48/223)\n",
      "toppar for ligand 8TZ already exists. Skipping...\n",
      "Getting toppar file for ligand H98 (49/223)\n",
      "toppar for ligand H98 already exists. Skipping...\n",
      "Getting toppar file for ligand EP5 (50/223)\n",
      "toppar for ligand EP5 already exists. Skipping...\n",
      "Getting toppar file for ligand 5MV (51/223)\n",
      "toppar for ligand 5MV already exists. Skipping...\n",
      "Getting toppar file for ligand OLC (52/223)\n",
      "toppar for ligand OLC already exists. Skipping...\n",
      "Getting toppar file for ligand 9ER (53/223)\n",
      "toppar for ligand 9ER already exists. Skipping...\n",
      "Getting toppar file for ligand 9DZ (54/223)\n",
      "toppar for ligand 9DZ already exists. Skipping...\n",
      "Getting toppar file for ligand 5FW (55/223)\n",
      "toppar for ligand 5FW already exists. Skipping...\n",
      "Getting toppar file for ligand BU1 (56/223)\n",
      "toppar for ligand BU1 already exists. Skipping...\n",
      "Getting toppar file for ligand 2CV (57/223)\n",
      "toppar for ligand 2CV already exists. Skipping...\n",
      "Getting toppar file for ligand BMA (58/223)\n",
      "toppar for ligand BMA already exists. Skipping...\n",
      "Getting toppar file for ligand PEG (59/223)\n",
      "toppar for ligand PEG already exists. Skipping...\n",
      "Getting toppar file for ligand 2CU (60/223)\n",
      "toppar for ligand 2CU already exists. Skipping...\n",
      "Getting toppar file for ligand SIN (61/223)\n",
      "toppar for ligand SIN already exists. Skipping...\n",
      "Getting toppar file for ligand 4E6 (62/223)\n",
      "toppar for ligand 4E6 already exists. Skipping...\n",
      "Getting toppar file for ligand DN5 (63/223)\n",
      "toppar for ligand DN5 already exists. Skipping...\n",
      "Getting toppar file for ligand F7N (64/223)\n",
      "toppar for ligand F7N already exists. Skipping...\n",
      "Getting toppar file for ligand ADN (65/223)\n",
      "toppar for ligand ADN already exists. Skipping...\n",
      "Getting toppar file for ligand GAW (66/223)\n",
      "toppar for ligand GAW already exists. Skipping...\n",
      "Getting toppar file for ligand STE (67/223)\n",
      "toppar for ligand STE already exists. Skipping...\n",
      "Getting toppar file for ligand NH2 (68/223)\n",
      "toppar for ligand NH2 already exists. Skipping...\n",
      "Getting toppar file for ligand DLB (69/223)\n",
      "toppar for ligand DLB already exists. Skipping...\n",
      "Getting toppar file for ligand T4E (70/223)\n",
      "toppar for ligand T4E already exists. Skipping...\n",
      "Getting toppar file for ligand 8EM (71/223)\n",
      "toppar for ligand 8EM already exists. Skipping...\n",
      "Getting toppar file for ligand P32 (72/223)\n",
      "toppar for ligand P32 already exists. Skipping...\n",
      "Getting toppar file for ligand NEC (73/223)\n",
      "toppar for ligand NEC already exists. Skipping...\n",
      "Getting toppar file for ligand DNK (74/223)\n",
      "toppar for ligand DNK already exists. Skipping...\n",
      "Getting toppar file for ligand 9EU (75/223)\n",
      "toppar for ligand 9EU already exists. Skipping...\n",
      "Getting toppar file for ligand EPE (76/223)\n",
      "toppar for ligand EPE already exists. Skipping...\n",
      "Getting toppar file for ligand ACE (77/223)\n",
      "toppar for ligand ACE already exists. Skipping...\n",
      "Getting toppar file for ligand ML5 (78/223)\n",
      "toppar for ligand ML5 already exists. Skipping...\n",
      "Getting toppar file for ligand NLE (79/223)\n",
      "toppar for ligand NLE already exists. Skipping...\n",
      "Getting toppar file for ligand L76 (80/223)\n",
      "toppar for ligand L76 already exists. Skipping...\n",
      "Getting toppar file for ligand 9EC (81/223)\n",
      "toppar for ligand 9EC already exists. Skipping...\n",
      "Getting toppar file for ligand PCA (82/223)\n",
      "toppar for ligand PCA already exists. Skipping...\n",
      "Getting toppar file for ligand D2U (83/223)\n",
      "toppar for ligand D2U already exists. Skipping...\n",
      "Getting toppar file for ligand MLI (84/223)\n",
      "toppar for ligand MLI already exists. Skipping...\n",
      "Getting toppar file for ligand JEV (85/223)\n",
      "toppar for ligand JEV already exists. Skipping...\n",
      "Getting toppar file for ligand K86 (86/223)\n",
      "toppar for ligand K86 already exists. Skipping...\n",
      "Getting toppar file for ligand HTO (87/223)\n",
      "toppar for ligand HTO already exists. Skipping...\n",
      "Getting toppar file for ligand 9DQ (88/223)\n",
      "toppar for ligand 9DQ already exists. Skipping...\n",
      "Getting toppar file for ligand ZOT (89/223)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toppar for ligand ZOT already exists. Skipping...\n",
      "Getting toppar file for ligand J9P (90/223)\n",
      "toppar for ligand J9P already exists. Skipping...\n",
      "Getting toppar file for ligand 200 (91/223)\n",
      "toppar for ligand 200 already exists. Skipping...\n",
      "Getting toppar file for ligand OLA (92/223)\n",
      "toppar for ligand OLA already exists. Skipping...\n",
      "Getting toppar file for ligand 8VL (93/223)\n",
      "toppar for ligand 8VL already exists. Skipping...\n",
      "Getting toppar file for ligand PE5 (94/223)\n",
      "toppar for ligand PE5 already exists. Skipping...\n",
      "Getting toppar file for ligand MEA (95/223)\n",
      "toppar for ligand MEA already exists. Skipping...\n",
      "Getting toppar file for ligand 8NU (96/223)\n",
      "toppar for ligand 8NU already exists. Skipping...\n",
      "Getting toppar file for ligand SG8 (97/223)\n",
      "toppar for ligand SG8 already exists. Skipping...\n",
      "Getting toppar file for ligand AWY (98/223)\n",
      "toppar for ligand AWY already exists. Skipping...\n",
      "Getting toppar file for ligand A6L (99/223)\n",
      "toppar for ligand A6L already exists. Skipping...\n",
      "Getting toppar file for ligand DI8 (100/223)\n",
      "toppar for ligand DI8 already exists. Skipping...\n",
      "Getting toppar file for ligand PLM (101/223)\n",
      "toppar for ligand PLM already exists. Skipping...\n",
      "Getting toppar file for ligand D8B (102/223)\n",
      "toppar for ligand D8B already exists. Skipping...\n",
      "Getting toppar file for ligand Y01 (103/223)\n",
      "toppar for ligand Y01 already exists. Skipping...\n",
      "Getting toppar file for ligand OIC (104/223)\n",
      "toppar for ligand OIC already exists. Skipping...\n",
      "Getting toppar file for ligand CVV (105/223)\n",
      "toppar for ligand CVV already exists. Skipping...\n",
      "Getting toppar file for ligand QUS (106/223)\n",
      "toppar for ligand QUS already exists. Skipping...\n",
      "Getting toppar file for ligand C8E (107/223)\n",
      "toppar for ligand C8E already exists. Skipping...\n",
      "Getting toppar file for ligand E2J (108/223)\n",
      "toppar for ligand E2J already exists. Skipping...\n",
      "Getting toppar file for ligand FSY (109/223)\n",
      "toppar for ligand FSY already exists. Skipping...\n",
      "Getting toppar file for ligand 1KS (110/223)\n",
      "toppar for ligand 1KS already exists. Skipping...\n",
      "Getting toppar file for ligand ETA (111/223)\n",
      "toppar for ligand ETA already exists. Skipping...\n",
      "Getting toppar file for ligand EFD (112/223)\n",
      "toppar for ligand EFD already exists. Skipping...\n",
      "Getting toppar file for ligand H8D (113/223)\n",
      "toppar for ligand H8D already exists. Skipping...\n",
      "Getting toppar file for ligand PO4 (114/223)\n",
      "toppar for ligand PO4 already exists. Skipping...\n",
      "Getting toppar file for ligand 8D0 (115/223)\n",
      "toppar for ligand 8D0 already exists. Skipping...\n",
      "Getting toppar file for ligand 8D1 (116/223)\n",
      "toppar for ligand 8D1 already exists. Skipping...\n",
      "Getting toppar file for ligand 82F (117/223)\n",
      "toppar for ligand 82F already exists. Skipping...\n",
      "Getting toppar file for ligand IOD (118/223)\n",
      "toppar for ligand IOD already exists. Skipping...\n",
      "Getting toppar file for ligand ACM (119/223)\n",
      "toppar for ligand ACM already exists. Skipping...\n",
      "Getting toppar file for ligand ORN (120/223)\n",
      "toppar for ligand ORN already exists. Skipping...\n",
      "Getting toppar file for ligand MK6 (121/223)\n",
      "toppar for ligand MK6 already exists. Skipping...\n",
      "Getting toppar file for ligand DGA (122/223)\n",
      "toppar for ligand DGA already exists. Skipping...\n",
      "Getting toppar file for ligand P6G (123/223)\n",
      "toppar for ligand P6G already exists. Skipping...\n",
      "Getting toppar file for ligand NO3 (124/223)\n",
      "toppar for ligand NO3 already exists. Skipping...\n",
      "Getting toppar file for ligand ZMA (125/223)\n",
      "toppar for ligand ZMA already exists. Skipping...\n",
      "Getting toppar file for ligand 6XQ (126/223)\n",
      "toppar for ligand 6XQ already exists. Skipping...\n",
      "Getting toppar file for ligand CL (127/223)\n",
      "toppar for ligand CL already exists. Skipping...\n",
      "Getting toppar file for ligand Y00 (128/223)\n",
      "toppar for ligand Y00 already exists. Skipping...\n",
      "Getting toppar file for ligand GLY (129/223)\n",
      "toppar for ligand GLY already exists. Skipping...\n",
      "Getting toppar file for ligand TEP (130/223)\n",
      "toppar for ligand TEP already exists. Skipping...\n",
      "Getting toppar file for ligand 7OS (131/223)\n",
      "toppar for ligand 7OS already exists. Skipping...\n",
      "Getting toppar file for ligand MES (132/223)\n",
      "toppar for ligand MES already exists. Skipping...\n",
      "Getting toppar file for ligand A8X (133/223)\n",
      "toppar for ligand A8X already exists. Skipping...\n",
      "Getting toppar file for ligand 7UR (134/223)\n",
      "toppar for ligand 7UR already exists. Skipping...\n",
      "Getting toppar file for ligand FVK (135/223)\n",
      "toppar for ligand FVK already exists. Skipping...\n",
      "Getting toppar file for ligand ZN (136/223)\n",
      "toppar for ligand ZN already exists. Skipping...\n",
      "Getting toppar file for ligand H8M (137/223)\n",
      "toppar for ligand H8M already exists. Skipping...\n",
      "Getting toppar file for ligand 68H (138/223)\n",
      "toppar for ligand 68H already exists. Skipping...\n",
      "Getting toppar file for ligand HG (139/223)\n",
      "toppar for ligand HG already exists. Skipping...\n",
      "Getting toppar file for ligand FT4 (140/223)\n",
      "toppar for ligand FT4 already exists. Skipping...\n",
      "Getting toppar file for ligand 1Q5 (141/223)\n",
      "toppar for ligand 1Q5 already exists. Skipping...\n",
      "Getting toppar file for ligand H8J (142/223)\n",
      "toppar for ligand H8J already exists. Skipping...\n",
      "Getting toppar file for ligand CFF (143/223)\n",
      "toppar for ligand CFF already exists. Skipping...\n",
      "Getting toppar file for ligand RET (144/223)\n",
      "toppar for ligand RET already exists. Skipping...\n",
      "Getting toppar file for ligand 12P (145/223)\n",
      "toppar for ligand 12P already exists. Skipping...\n",
      "Getting toppar file for ligand SNT (146/223)\n",
      "toppar for ligand SNT already exists. Skipping...\n",
      "Getting toppar file for ligand AZJ (147/223)\n",
      "toppar for ligand AZJ already exists. Skipping...\n",
      "Getting toppar file for ligand D10 (148/223)\n",
      "toppar for ligand D10 already exists. Skipping...\n",
      "Getting toppar file for ligand DOK (149/223)\n",
      "toppar for ligand DOK already exists. Skipping...\n",
      "Getting toppar file for ligand HRG (150/223)\n",
      "toppar for ligand HRG already exists. Skipping...\n",
      "Getting toppar file for ligand PEF (151/223)\n",
      "toppar for ligand PEF already exists. Skipping...\n",
      "Getting toppar file for ligand 79K (152/223)\n",
      "toppar for ligand 79K already exists. Skipping...\n",
      "Getting toppar file for ligand 836 (153/223)\n",
      "toppar for ligand 836 already exists. Skipping...\n",
      "Getting toppar file for ligand GBK (154/223)\n",
      "toppar for ligand GBK already exists. Skipping...\n",
      "Getting toppar file for ligand F9Q (155/223)\n",
      "toppar for ligand F9Q already exists. Skipping...\n",
      "Getting toppar file for ligand K87 (156/223)\n",
      "toppar for ligand K87 already exists. Skipping...\n",
      "Getting toppar file for ligand BGL (157/223)\n",
      "toppar for ligand BGL already exists. Skipping...\n",
      "Getting toppar file for ligand 9AO (158/223)\n",
      "toppar for ligand 9AO already exists. Skipping...\n",
      "Getting toppar file for ligand BOG (159/223)\n",
      "toppar for ligand BOG already exists. Skipping...\n",
      "Getting toppar file for ligand K5Y (160/223)\n",
      "toppar for ligand K5Y already exists. Skipping...\n",
      "Getting toppar file for ligand 8D3 (161/223)\n",
      "toppar for ligand 8D3 already exists. Skipping...\n",
      "Getting toppar file for ligand AC5 (162/223)\n",
      "toppar for ligand AC5 already exists. Skipping...\n",
      "Getting toppar file for ligand DNZ (163/223)\n",
      "toppar for ligand DNZ already exists. Skipping...\n",
      "Getting toppar file for ligand P2E (164/223)\n",
      "toppar for ligand P2E already exists. Skipping...\n",
      "Getting toppar file for ligand POV (165/223)\n",
      "toppar for ligand POV already exists. Skipping...\n",
      "Getting toppar file for ligand 8VS (166/223)\n",
      "toppar for ligand 8VS already exists. Skipping...\n",
      "Getting toppar file for ligand AIB (167/223)\n",
      "toppar for ligand AIB already exists. Skipping...\n",
      "Getting toppar file for ligand 7MA (168/223)\n",
      "toppar for ligand 7MA already exists. Skipping...\n",
      "Getting toppar file for ligand GOL (169/223)\n",
      "toppar for ligand GOL already exists. Skipping...\n",
      "Getting toppar file for ligand I32 (170/223)\n",
      "toppar for ligand I32 already exists. Skipping...\n",
      "Getting toppar file for ligand 1WV (171/223)\n",
      "toppar for ligand 1WV already exists. Skipping...\n",
      "Getting toppar file for ligand DLH (172/223)\n",
      "toppar for ligand DLH already exists. Skipping...\n",
      "Getting toppar file for ligand 7AB (173/223)\n",
      "toppar for ligand 7AB already exists. Skipping...\n",
      "Getting toppar file for ligand 97V (174/223)\n",
      "toppar for ligand 97V already exists. Skipping...\n",
      "Getting toppar file for ligand CAU (175/223)\n",
      "toppar for ligand CAU already exists. Skipping...\n",
      "Getting toppar file for ligand NDG (176/223)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toppar for ligand NDG already exists. Skipping...\n",
      "Getting toppar file for ligand DI7 (177/223)\n",
      "toppar for ligand DI7 already exists. Skipping...\n",
      "Getting toppar file for ligand 8JN (178/223)\n",
      "toppar for ligand 8JN already exists. Skipping...\n",
      "Getting toppar file for ligand ZAL (179/223)\n",
      "toppar for ligand ZAL already exists. Skipping...\n",
      "Getting toppar file for ligand QNB (180/223)\n",
      "toppar for ligand QNB already exists. Skipping...\n",
      "Getting toppar file for ligand N9S (181/223)\n",
      "toppar for ligand N9S already exists. Skipping...\n",
      "Getting toppar file for ligand 89F (182/223)\n",
      "toppar for ligand 89F already exists. Skipping...\n",
      "Getting toppar file for ligand A8T (183/223)\n",
      "toppar for ligand A8T already exists. Skipping...\n",
      "Getting toppar file for ligand CSD (184/223)\n",
      "toppar for ligand CSD already exists. Skipping...\n",
      "Getting toppar file for ligand ACT (185/223)\n",
      "toppar for ligand ACT already exists. Skipping...\n",
      "Getting toppar file for ligand UNX (186/223)\n",
      "toppar for ligand UNX already exists. Skipping...\n",
      "Getting toppar file for ligand FMN (187/223)\n",
      "toppar for ligand FMN already exists. Skipping...\n",
      "Getting toppar file for ligand 8UN (188/223)\n",
      "toppar for ligand 8UN already exists. Skipping...\n",
      "Getting toppar file for ligand LPP (189/223)\n",
      "toppar for ligand LPP already exists. Skipping...\n",
      "Getting toppar file for ligand BNG (190/223)\n",
      "toppar for ligand BNG already exists. Skipping...\n",
      "Getting toppar file for ligand EDT (191/223)\n",
      "toppar for ligand EDT already exists. Skipping...\n",
      "Getting toppar file for ligand MAL (192/223)\n",
      "toppar for ligand MAL already exists. Skipping...\n",
      "Getting toppar file for ligand TPO (193/223)\n",
      "toppar for ligand TPO already exists. Skipping...\n",
      "Getting toppar file for ligand 8K8 (194/223)\n",
      "toppar for ligand 8K8 already exists. Skipping...\n",
      "Getting toppar file for ligand 9P2 (195/223)\n",
      "toppar for ligand 9P2 already exists. Skipping...\n",
      "Getting toppar file for ligand 0HK (196/223)\n",
      "toppar for ligand 0HK already exists. Skipping...\n",
      "Getting toppar file for ligand 73R (197/223)\n",
      "toppar for ligand 73R already exists. Skipping...\n",
      "Getting toppar file for ligand 9Y2 (198/223)\n",
      "toppar for ligand 9Y2 already exists. Skipping...\n",
      "Getting toppar file for ligand 9XW (199/223)\n",
      "toppar for ligand 9XW already exists. Skipping...\n",
      "Getting toppar file for ligand A4R (200/223)\n",
      "toppar for ligand A4R already exists. Skipping...\n",
      "Getting toppar file for ligand TRE (201/223)\n",
      "toppar for ligand TRE already exists. Skipping...\n",
      "Getting toppar file for ligand CLR (202/223)\n",
      "toppar for ligand CLR already exists. Skipping...\n",
      "Getting toppar file for ligand DO5 (203/223)\n",
      "toppar for ligand DO5 already exists. Skipping...\n",
      "Getting toppar file for ligand CIT (204/223)\n",
      "toppar for ligand CIT already exists. Skipping...\n",
      "Getting toppar file for ligand UNL (205/223)\n",
      "toppar for ligand UNL already exists. Skipping...\n",
      "Getting toppar file for ligand PC1 (206/223)\n",
      "toppar for ligand PC1 already exists. Skipping...\n",
      "Getting toppar file for ligand ITD (207/223)\n",
      "toppar for ligand ITD already exists. Skipping...\n",
      "Getting toppar file for ligand KCA (208/223)\n",
      "toppar for ligand KCA already exists. Skipping...\n",
      "Getting toppar file for ligand TWT (209/223)\n",
      "toppar for ligand TWT already exists. Skipping...\n",
      "Getting toppar file for ligand VT5 (210/223)\n",
      "toppar for ligand VT5 already exists. Skipping...\n",
      "Getting toppar file for ligand 9AF (211/223)\n",
      "toppar for ligand 9AF already exists. Skipping...\n",
      "Getting toppar file for ligand GBQ (212/223)\n",
      "toppar for ligand GBQ already exists. Skipping...\n",
      "Getting toppar file for ligand D7W (213/223)\n",
      "toppar for ligand D7W already exists. Skipping...\n",
      "Getting toppar file for ligand TCE (214/223)\n",
      "toppar for ligand TCE already exists. Skipping...\n",
      "Getting toppar file for ligand CO1 (215/223)\n",
      "toppar for ligand CO1 already exists. Skipping...\n",
      "Getting toppar file for ligand JEY (216/223)\n",
      "toppar for ligand JEY already exists. Skipping...\n",
      "Getting toppar file for ligand OLB (217/223)\n",
      "toppar for ligand OLB already exists. Skipping...\n",
      "Getting toppar file for ligand LDA (218/223)\n",
      "toppar for ligand LDA already exists. Skipping...\n",
      "Getting toppar file for ligand NAG (219/223)\n",
      "toppar for ligand NAG already exists. Skipping...\n",
      "Getting toppar file for ligand ACY (220/223)\n",
      "toppar for ligand ACY already exists. Skipping...\n",
      "Getting toppar file for ligand 1PE (221/223)\n",
      "toppar for ligand 1PE already exists. Skipping...\n",
      "Getting toppar file for ligand MAN (222/223)\n",
      "toppar for ligand MAN already exists. Skipping...\n",
      "Getting toppar file for ligand SCN (223/223)\n",
      "toppar for ligand SCN already exists. Skipping...\n"
     ]
    }
   ],
   "source": [
    "#################################################\n",
    "## Part 1: Download data and prepare dictionaries\n",
    "#################################################\n",
    "\n",
    "if not bool(pdb_set):\n",
    "    #Get not yet simulated PDB codes from GPCRdb\n",
    "    pdb_set = get_GPCRdb_nonsimulated()\n",
    "\n",
    "# Download and store structures from GPCRdb\n",
    "pdb_set = download_GPCRdb_structures(pdb_set, basepath)\n",
    "\n",
    "#Create or moidfy the ligands dictionary\n",
    "(ligandsdict, ligandsset) = ligand_dictionary(pdb_set, ligandsdict_path)\n",
    "\n",
    "# Download ligand structures\n",
    "extract_ligands(ligandsdict, basepath)\n",
    "\n",
    "# Get topology-parameter files for ligandsf\n",
    "get_lig_toppar(ligandsset, basepath, username, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "start building model for receptor 6IIU (1/1)\n",
      "Build model for 6IIU already exists. Skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-03 12:27:53,566 - moleculekit.molecule - INFO - Removed 1314 atoms. 2351 atoms remaining in the molecule.\n",
      "2020-06-03 12:27:53,624 - moleculekit.molecule - INFO - Removed 39 atoms. 2584 atoms remaining in the molecule.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A8X\n",
      "OLC\n",
      "no OLC\n",
      "GOL\n",
      "no GOL\n",
      "CLR\n",
      "ZN\n",
      "no ZN\n"
     ]
    }
   ],
   "source": [
    "###########################\n",
    "## Part 2: Build the models \n",
    "###########################\n",
    "\n",
    "# Iterate by GPCRdb structures to simulate\n",
    "pdbs_number = len(pdb_set)\n",
    "i = 0\n",
    "for pdbcode in pdb_set:\n",
    "    try:\n",
    "        #Starting simulation\n",
    "        start_time = time.time()\n",
    "        i += 1\n",
    "        print('\\nstart building model for receptor %s (%d/%d)' % (pdbcode, i, pdbs_number))\n",
    "        #try:\n",
    "        # Skip if there is already a model build for this\n",
    "        if os.path.exists(resultspath+'build/'+pdbcode+'/structure.pdb'):\n",
    "            print('Build model for '+pdbcode+' already exists. Skipping...')\n",
    "            #continue\n",
    "\n",
    "        # Load GPCRdb and OPM versions of GPCR with pdbcode\n",
    "        simdir = basepath + 'data_sim/'+pdbcode+'/'\n",
    "        gpcrdb_mol = Molecule(glob(simdir + '*.pdb'))\n",
    "        opm_mol, thickness = opm(pdbcode)\n",
    "\n",
    "        # Remove unnecessary ligand molecules: mostly crystalization detergents or ligands from removed parts of the protein\n",
    "        accepted_ligandsdict = json_dict(basepath+\"accepted_ligands.json\") \n",
    "        gpcrdb_mol = remove_artifacts(pdbcode, gpcrdb_mol, ligandsdict, accepted_ligandsdict)\n",
    "\n",
    "        # Ismael's function to add labels (segid) for 'ligand' and 'protein' parts of the system\n",
    "        #And many things more I do not really understand\n",
    "        gpcrdb_mol_fixed,receptor_segids_gpcrdb = fix_and_prepare_input(gpcrdb_mol)\n",
    "        opm_mol_fixed,receptor_segids_opm = fix_and_prepare_input(opm_mol)\n",
    "\n",
    "        # Paths and previous variables\n",
    "        modelname = pdbcode # Example name\n",
    "        opm_modelname = pdbcode + '_opm'\n",
    "\n",
    "        # Assigning new chain to protein segment of the protein to align (opm and gpcrdb)\n",
    "        opm_receptorsel = 'segid '+' '.join(receptor_segids_opm)\n",
    "        opm_mol_fixed.set('chain',new_pdb_chain,sel=opm_receptorsel)\n",
    "        gpcrdb_receptorsel = 'segid '+' '.join(receptor_segids_gpcrdb)\n",
    "        gpcrdb_mol_fixed.set('chain',new_pdb_chain,sel=gpcrdb_receptorsel)\n",
    "\n",
    "        # Align structrues using sequences, and take first one\n",
    "        alignment_results = sequenceStructureAlignment(gpcrdb_mol_fixed, opm_mol_fixed, maxalignments = 1)\n",
    "        mol_aligned = alignment_results[0] \n",
    "\n",
    "        #Center to receptor XY\n",
    "        center = np.mean(mol_aligned.get('coords',sel=gpcrdb_receptorsel),axis=0)\n",
    "        mol_aligned.moveBy([-center[0],-center[1],0])\n",
    "\n",
    "        #Prepare protein: asign titration states, flipping side chains of HIS, ASN and GLN; rotate some sidechains, optimize waters, etc.\n",
    "        prepared_mol, table = proteinPrepare(mol_aligned, \n",
    "                                        returnDetails = True,  \n",
    "                                        hydrophobicThickness=thickness,\n",
    "                                        )\n",
    "\n",
    "        #Add membrane\n",
    "        print('Adding membrane...')\n",
    "        membranemol = Molecule(membranepdb)\n",
    "        mol_membraned, membrane_resnames, membrane_segids, xreps, yreps = add_membrane(mol_aligned, membranemol,receptor_segids_gpcrdb,membrane_distance)\n",
    "\n",
    "        #Solvate\n",
    "        print('Solvating...')\n",
    "        mol_solvated = solvate_pdbmol(mol_membraned,membrane_segids,water_thickness,water_margin,buffer=buffer,coldist=coldist,prefix='WT')\n",
    "\n",
    "        # Make list of Ligand stringfiles (Parameters and topology)\n",
    "        streams = []\n",
    "        for ligcode in ligandsdict[pdbcode]:\n",
    "            streams.append(basepath + 'Ligands/'+ ligcode+ '/toppar.str')\n",
    "\n",
    "        # Assignign terminology for cap atoms of protein chain, depending if it is the receptor protein or not\n",
    "        caps_receptor = ['first ACE', 'last CT3']\n",
    "        caps_not_receptor_protein = ['first NTER', 'last CTER']\n",
    "        caps = { segid : caps_receptor for segid in receptor_segids_gpcrdb }\n",
    "\n",
    "        #Pre-build model\n",
    "        print('Pre-build...')\n",
    "        prebuildmol = charmm.build(mol_solvated, \n",
    "                                   topo=topos, \n",
    "                                   param=params,\n",
    "                                   stream=streams,\n",
    "                                   caps=caps,\n",
    "                                   outdir=resultspath+'/pre-build/'+modelname,\n",
    "                                   ionize=False)\n",
    "\n",
    "        # Save prebuild model topologies in files, and  store prebuild model in molecule object\n",
    "        prebuild_psffile = prebuildmol.topoloc\n",
    "        prebuild_pdbfile = os.path.splitext(prebuildmol.topoloc)[0]+'.pdb'\n",
    "        prebuildmol = Molecule(prebuild_pdbfile)\n",
    "        _recoverProtonations(prebuildmol)\n",
    "\n",
    "        # Checking of aromatic insertions (takes quite a lot fo time)\n",
    "        print('Checking aromatic insertions...')\n",
    "        mol_removed,removed_indexes = remove_aromatic_insertions(mol_solvated,receptor_segids_gpcrdb, outpdb=resultspath+'/pre-build/'+modelname+'/aromatic_check.pdb')\n",
    "\n",
    "        # Checking of water/lipid ratio\n",
    "        lipid_num = len(set(mol_removed.get('resid',sel='segid '+membrane_lipid_segid)))\n",
    "        solv_num = len(mol_removed.get('index',sel='resname TIP3 and name OH2'))\n",
    "        if float(solv_num) / lipid_num < 35:\n",
    "            raise ValueError('Water/lipid ratio lower than 35.')\n",
    "\n",
    "        #Renumber residues\n",
    "        print('Renumbering...')\n",
    "        mol_renumbered = renumber_resid_vmd(mol_removed,'segid '+' '.join(membrane_segids),by=2)\n",
    "\n",
    "        # Ionizing system\n",
    "        print('Ionizing...')\n",
    "        molbuilt = charmm.build(mol_removed,\n",
    "                                topo=topos,\n",
    "                                stream=streams,                        \n",
    "                                param=params,\n",
    "                                outdir=resultspath+'/ionize/'+modelname,\n",
    "                                saltconc=0.15,\n",
    "                                caps=caps)\n",
    "        build_psffile = molbuilt.topoloc\n",
    "        build_pdbfile = os.path.splitext(molbuilt.topoloc)[0]+'.pdb'\n",
    "        molbuilt = Molecule(build_pdbfile)\n",
    "        _recoverProtonations(molbuilt)\n",
    "\n",
    "        #Building system\n",
    "        print('Building...')\n",
    "        molbuilt = renumber_resid_vmd(molbuilt,'segid \"WT.*\" or segid I',by=2)\n",
    "        molbuilt = charmm.build(molbuilt, \n",
    "                                topo=topos, \n",
    "                                stream=streams,                        \n",
    "                                param=params,\n",
    "                                outdir=resultspath+'/build/'+modelname,\n",
    "                                caps=caps,ionize=False)\n",
    "\n",
    "        # Preparing scripts to run equillibration\n",
    "        equildir = resultspath+'/equil/'+modelname+'/'\n",
    "        if not os.path.exists(equildir):\n",
    "            os.makedirs(equildir)\n",
    "\n",
    "        const_sel = 'segid '+' '.join(receptor_segids_gpcrdb)+' and name C CA N O or not (segid ' + \\\n",
    "                      ' '.join(receptor_segids_gpcrdb)+' or resname '+' '.join(membrane_resnames) + \\\n",
    "                      ' or water or ions ) and noh or segid ION WAT and noh'\n",
    "        md = define_equilibration(const_sel)\n",
    "        md.write(resultspath+'build/'+modelname,equildir)\n",
    "\n",
    "        #Substitute run.sh generated by HTMD by a different one, adapted to the specified path of ACEMD\n",
    "        with open(equildir + 'run.sh', 'w') as f:\n",
    "            f.write('#!/bin/bash\\n%s >log.txt 2>&1' % acemd_path)\n",
    "\n",
    "        print('End of %s after %s seconds\\n' % (modelname, time.time() - start_time))\n",
    "    except Exception as e:\n",
    "        print(\"model \"+pdbcode+\"could not be build because \",e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-29 09:33:05,154 - jobqueues.slurmqueue - INFO - Queueing /gpcr/users/daranda/doctorat/GPCR_simulations/simulation_output//equil/5TE5/\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "## Part 3: Equillibration\n",
    "#########################\n",
    "\n",
    "#Launch equilibration\n",
    "try:\n",
    "    sqs\n",
    "except NameError:\n",
    "    sqs = {}\n",
    "\n",
    "for pdbcode in pdb_set:\n",
    "    modelname = pdbcode\n",
    "    pdbfile = '%s/build/%s/structure.pdb' % (resultspath, pdbcode)\n",
    "    if modelname in sqs:\n",
    "        print('Skipping '+modelname+': it has already been submitted.')\n",
    "        continue\n",
    "\n",
    "    sq = SlurmQueue()\n",
    "    sq.jobname = 'eql_'+pdbcode\n",
    "    sq.datadir = None\n",
    "    sq.partition = 'gpcr_gpu'\n",
    "    sq.ngpu = 1\n",
    "    sq.ncpu = 1\n",
    "    sq.nodelist = 'balin'\n",
    "    \n",
    "    #sq.exclude = 'excluded_node'\n",
    "    \n",
    "    # directory to copy input and store output of equilibration (initial working directory for run_equil.sh).\n",
    "    # equildir directory has to be in the computation server, or in a shared folder for the computation folder.\n",
    "    equildir = resultspath + '/equil/'+modelname+'/'\n",
    "    # copy equil folder in build to equildir\n",
    "    #copytree(resultspath+'/build/'+modelname+'/equil',equildir)\n",
    "    sq.submit(equildir)\n",
    "    sqs[modelname] = sq\n",
    "sqs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#run me to check how many simulations are still running NOT WORKING\n",
    "sum([sqs[modelname].inprogress() for modelname in sqs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset tracking for all\n",
    "sqs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING!!!: run me to KILL simulations that are still running\n",
    "for modelname in sqs:\n",
    "    sqs[modelname].stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Equilibration commands and parameters\n",
    "\n",
    "#run me to check how many simulations are still running\n",
    "sum([sqs[modelname].inprogress() for modelname in sqs])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "## Part 4: Production\n",
    "#####################\n",
    "\n",
    "#run me to define production protocol\n",
    "def define_production():\n",
    "    md = Production()\n",
    "    md.runtime = 500\n",
    "    md.timeunits = 'ns'\n",
    "    md.temperature = 310\n",
    "    md.acemd.restart = 'off'\n",
    "    md.acemd.bincoordinates = 'output.coor'\n",
    "    md.acemd.tclforces = 'off'\n",
    "    md.acemd.extendedsystem  = 'output.xsc'\n",
    "    md.acemd.binvelocities = 'output.vel'\n",
    "    md.acemd.restartfreq = str(25000)\n",
    "    md.acemd.berendsenpressure = 'off'\n",
    "    md.acemd.TCL = (md.acemd.TCL[0],\"\")\n",
    "    return md\n",
    "md = define_production()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
